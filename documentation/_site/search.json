[
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Welcome to the PythonCK tutorials! These step-by-step guides will help you understand the core concepts and learn how to use the library effectively.\n\n\n\n\n\n\n\n\nLet’s import the necessary modules:\n\n\n\n\n\n\n\n\n\nTensor coordinates are the foundation of how we address multi-dimensional data:\n\n\n\n\n\n\n\n\n\nTensor descriptors provide metadata about tensor layout and properties:\n\n\n\n\n\n\n\n\n\nBuffer views provide low-level control over memory access patterns:\n\n\n\n\n\n\n\n\n\nLearn how data is organized and processed in tiles:\n\n\n\n\n\n\n\n\n\nExplore how tensor adaptors enable complex transformations:\n\n\n\n\n\n\n\n\n\nNow that you’ve learned the basics, explore specific concepts in detail:\n\nTensor Adaptor - Deep dive into tensor transformations\nTile Operations - Advanced tiling strategies\nBuffer Management - Memory access optimization\n\n\n\n\nTry modifying the examples above! Change the tensor dimensions, tile sizes, or transformation types to see how the system behaves. All code runs directly in your browser, so feel free to experiment.\n\n\n\nHere are some common usage patterns you’ll encounter:\n\nCreating multi-dimensional coordinates for indexing\nSetting up tile distributions for parallel processing\nApplying tensor adaptors for data transformations\nManaging buffer views for memory optimization\n\nEach concept builds on the previous ones, creating a powerful framework for GPU kernel development.",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#setup",
    "href": "tutorials/index.html#setup",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Let’s import the necessary modules:",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#tutorial-1-understanding-tensor-coordinates",
    "href": "tutorials/index.html#tutorial-1-understanding-tensor-coordinates",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Tensor coordinates are the foundation of how we address multi-dimensional data:",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#tutorial-2-working-with-tensor-descriptors",
    "href": "tutorials/index.html#tutorial-2-working-with-tensor-descriptors",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Tensor descriptors provide metadata about tensor layout and properties:",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#tutorial-3-buffer-views-and-memory-access",
    "href": "tutorials/index.html#tutorial-3-buffer-views-and-memory-access",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Buffer views provide low-level control over memory access patterns:",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#tutorial-4-tile-based-operations",
    "href": "tutorials/index.html#tutorial-4-tile-based-operations",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Learn how data is organized and processed in tiles:",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#tutorial-5-advanced-tensor-transformations",
    "href": "tutorials/index.html#tutorial-5-advanced-tensor-transformations",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Explore how tensor adaptors enable complex transformations:",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#next-steps",
    "href": "tutorials/index.html#next-steps",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Now that you’ve learned the basics, explore specific concepts in detail:\n\nTensor Adaptor - Deep dive into tensor transformations\nTile Operations - Advanced tiling strategies\nBuffer Management - Memory access optimization",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#interactive-experimentation",
    "href": "tutorials/index.html#interactive-experimentation",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Try modifying the examples above! Change the tensor dimensions, tile sizes, or transformation types to see how the system behaves. All code runs directly in your browser, so feel free to experiment.",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "tutorials/index.html#common-patterns",
    "href": "tutorials/index.html#common-patterns",
    "title": "Getting Started with PythonCK",
    "section": "",
    "text": "Here are some common usage patterns you’ll encounter:\n\nCreating multi-dimensional coordinates for indexing\nSetting up tile distributions for parallel processing\nApplying tensor adaptors for data transformations\nManaging buffer views for memory optimization\n\nEach concept builds on the previous ones, creating a powerful framework for GPU kernel development.",
    "crumbs": [
      "Getting Started",
      "Getting Started with PythonCK"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate.html#what-is-a-tensorcoordinate",
    "href": "concepts/tensor-coordinate.html#what-is-a-tensorcoordinate",
    "title": "Tensor Coordinates",
    "section": "What is a TensorCoordinate?",
    "text": "What is a TensorCoordinate?\nA TensorCoordinate is the end product of the tensor transformation pipeline:\nInput Index → Transforms → TensorCoordinate (Index + Offset)\nKey characteristics: - Stores the final index: The transformed multi-dimensional coordinate - Stores the linear offset: The final memory location after all transformations - Extends TensorAdaptorCoordinate: Inherits transformation tracking but focuses on the final result - Always has a single bottom dimension: The linear offset is stored in hidden dimension [0]",
    "crumbs": [
      "Foundation",
      "Tensor Coordinates"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate.html#why-tensorcoordinate-matters",
    "href": "concepts/tensor-coordinate.html#why-tensorcoordinate-matters",
    "title": "Tensor Coordinates",
    "section": "Why TensorCoordinate Matters",
    "text": "Why TensorCoordinate Matters\nAfter complex transformations (embedding, merging, unmerging, etc.), you need: 1. The final index: Where you are in the logical tensor space 2. The linear offset: Where to actually access memory\nTensorCoordinate provides both pieces of information in a single, convenient container.",
    "crumbs": [
      "Foundation",
      "Tensor Coordinates"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate.html#core-components",
    "href": "concepts/tensor-coordinate.html#core-components",
    "title": "Tensor Coordinates",
    "section": "Core Components",
    "text": "Core Components\n\nMultiIndex\nA MultiIndex represents a multi-dimensional index with a specific number of dimensions:\n\n\n\n\n\n\n\n\nTensorCoordinate\nA TensorCoordinate represents coordinates in a tensor space with transformations:",
    "crumbs": [
      "Foundation",
      "Tensor Coordinates"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate.html#key-operations",
    "href": "concepts/tensor-coordinate.html#key-operations",
    "title": "Tensor Coordinates",
    "section": "Key Operations",
    "text": "Key Operations\n\nIndex Manipulation\n\n\n\n\n\n\n\n\nCoordinate Transformations",
    "crumbs": [
      "Foundation",
      "Tensor Coordinates"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate.html#relationship-to-other-concepts",
    "href": "concepts/tensor-coordinate.html#relationship-to-other-concepts",
    "title": "Tensor Coordinates",
    "section": "Relationship to Other Concepts",
    "text": "Relationship to Other Concepts\nTensor coordinates are used throughout PythonCK:\n\nBuffer Views use coordinates to access memory locations\nTensor Descriptors transform coordinates through layout changes\n\nTile Distributions map coordinates between different spaces\nSweep Operations iterate through coordinate ranges",
    "crumbs": [
      "Foundation",
      "Tensor Coordinates"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate.html#next-steps",
    "href": "concepts/tensor-coordinate.html#next-steps",
    "title": "Tensor Coordinates",
    "section": "Next Steps",
    "text": "Next Steps\n\nLearn about Tensor Adaptors - The transformation engines that execute descriptors\nExplore Tensor Adaptor Coordinates - Result containers for transformed indices\nUnderstand Advanced Coordinate Operations - Functions that require descriptors\n\nThe coordinate system provides the mathematical foundation that enables all the advanced tensor operations in PythonCK.\n\nTensorCoordinate: Index + Offset Storage\nA TensorCoordinate stores the final result of tensor transformations - both the logical index and the linear memory offset:\n\n\n\n\n\n\n\n\nKey Methods\n\n\n\n\n\n\n\n\nComparison with TensorAdaptorCoordinate",
    "crumbs": [
      "Foundation",
      "Tensor Coordinates"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#core-concept",
    "href": "concepts/tensor-adaptor-coordinate.html#core-concept",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🎯 Core Concept",
    "text": "🎯 Core Concept\nA Tensor Adaptor Coordinate stores the results of coordinate transformations:\nInput Index → Tensor Adaptor → Tensor Adaptor Coordinate → Final Tensor Coordinate\nThe adaptor coordinate contains: - Top Index: The original input coordinates - Bottom Index: The transformed output coordinates\n- Hidden Index: Internal storage for the transformation results",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#creating-tensor-adaptor-coordinates",
    "href": "concepts/tensor-adaptor-coordinate.html#creating-tensor-adaptor-coordinates",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🔧 Creating Tensor Adaptor Coordinates",
    "text": "🔧 Creating Tensor Adaptor Coordinates\n\nFrom Tensor Adaptors\n\n\n\n\n\n\n\n\nManual Creation (Advanced)",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#understanding-the-three-level-structure",
    "href": "concepts/tensor-adaptor-coordinate.html#understanding-the-three-level-structure",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🔍 Understanding the Three-Level Structure",
    "text": "🔍 Understanding the Three-Level Structure\n\nTop Index (Input Coordinates)\n\n\n\n\n\n\n\n\nBottom Index (Transformed Coordinates)\n\n\n\n\n\n\n\n\nHidden Index (Internal Storage)",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#coordinate-access-patterns",
    "href": "concepts/tensor-adaptor-coordinate.html#coordinate-access-patterns",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🔄 Coordinate Access Patterns",
    "text": "🔄 Coordinate Access Patterns\n\nGetting Specific Indices\n\n\n\n\n\n\n\n\nIndex Manipulation",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#relationship-to-other-components",
    "href": "concepts/tensor-adaptor-coordinate.html#relationship-to-other-components",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🔗 Relationship to Other Components",
    "text": "🔗 Relationship to Other Components\n\nHow Adaptor Coordinates Become Tensor Coordinates\n\n\n\n\n\n\n\n\nIntegration with Descriptors",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#advanced-operations",
    "href": "concepts/tensor-adaptor-coordinate.html#advanced-operations",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🎯 Advanced Operations",
    "text": "🎯 Advanced Operations\n\nMulti-Transform Adaptor Coordinates\n\n\n\n\n\n\n\n\nCoordinate Validation",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#why-this-matters",
    "href": "concepts/tensor-adaptor-coordinate.html#why-this-matters",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🔍 Why This Matters",
    "text": "🔍 Why This Matters\nUnderstanding Tensor Adaptor Coordinates is crucial because:\n\nThey store transformation results - All coordinate transformations produce adaptor coordinates\nThey enable complex layouts - Multiple transforms can be chained and stored\nThey bridge adaptors and coordinates - They’re the intermediate step between transformation and final result\nThey support validation - They can be checked for validity before use",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#integration-with-real-applications",
    "href": "concepts/tensor-adaptor-coordinate.html#integration-with-real-applications",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "🎯 Integration with Real Applications",
    "text": "🎯 Integration with Real Applications\nAdaptor coordinates are used throughout PythonCK:\n\nTile Distributions create adaptor coordinates for thread mapping\nTensor Views use adaptor coordinates for coordinate transformations\nSweep Operations work with adaptor coordinates for navigation\nMemory Access relies on adaptor coordinates for address calculations",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor-coordinate.html#next-steps",
    "href": "concepts/tensor-adaptor-coordinate.html#next-steps",
    "title": "Tensor Adaptor Coordinate: The Result Container",
    "section": "✅ Next Steps",
    "text": "✅ Next Steps\nNow that you understand adaptor coordinates, you can explore: - Advanced Coordinate Operations - Functions that work with adaptor coordinates - Tile Distribution - How adaptor coordinates enable parallel processing - Tensor Views - How adaptor coordinates integrate with tensor access\n\nTensor Adaptor Coordinates are the result containers that store the transformed indices and offsets. They serve as the bridge between transformation engines and final memory-mapped coordinates, enabling complex coordinate operations throughout PythonCK.",
    "crumbs": [
      "Foundation",
      "Tensor Adaptor Coordinate: The Result Container"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#what-is-a-tensordescriptor",
    "href": "concepts/tensor-descriptor.html#what-is-a-tensordescriptor",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "What is a TensorDescriptor?",
    "text": "What is a TensorDescriptor?\n\nExtends TensorAdaptor: Inherits all the transformation logic and hierarchy management from TensorAdaptor.\nAdds element space information: Knows the total number of elements, vectorization guarantees, and other memory layout details.\nDefines the full layout: Combines a sequence of transforms with memory size and access properties.",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#example-creating-a-tensordescriptor-with-the-constructor",
    "href": "concepts/tensor-descriptor.html#example-creating-a-tensordescriptor-with-the-constructor",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "Example: Creating a TensorDescriptor with the Constructor",
    "text": "Example: Creating a TensorDescriptor with the Constructor\nYou can create a TensorDescriptor using its constructor, which extends TensorAdaptor with element space information:",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#differences-tensoradaptor-vs-tensordescriptor",
    "href": "concepts/tensor-descriptor.html#differences-tensoradaptor-vs-tensordescriptor",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "Differences: TensorAdaptor vs TensorDescriptor",
    "text": "Differences: TensorAdaptor vs TensorDescriptor\n\n\n\n\n\n\n\n\nFeature\nTensorAdaptor\nTensorDescriptor\n\n\n\n\nCoordinate transforms\nYes\nYes\n\n\nHidden dimension mgmt\nYes\nYes\n\n\nMemory size info\nNo\nYes\n\n\nVectorization info\nNo\nYes\n\n\nUsed for…\nGeneral transforms\nFull tensor layout",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#helper-functions-for-descriptors",
    "href": "concepts/tensor-descriptor.html#helper-functions-for-descriptors",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "Helper Functions for Descriptors",
    "text": "Helper Functions for Descriptors\nPythonCK provides several helper functions to quickly create common tensor layouts:\n\nmake_naive_tensor_descriptor: Create a descriptor for a standard (strided) tensor layout with custom strides.\nmake_naive_tensor_descriptor_packed: Create a descriptor for a packed (contiguous) layout.\nmake_naive_tensor_descriptor_aligned: Create a descriptor with alignment constraints.\ntransform_tensor_descriptor: Apply additional transforms to an existing descriptor.\n\nThese functions let you easily define the most common tensor layouts, or build up more complex ones by chaining transforms.\n\nNext: See Tensor Coordinates for how descriptors and adaptors are used to create and manipulate actual tensor indices.",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#core-concept",
    "href": "concepts/tensor-descriptor.html#core-concept",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🎯 Core Concept",
    "text": "🎯 Core Concept\nA Tensor Descriptor is a chain of transformations that convert between coordinate spaces:\nUpper Index → Transform Chain → Lower Index → Memory Address",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#basic-descriptor-creation",
    "href": "concepts/tensor-descriptor.html#basic-descriptor-creation",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🔧 Basic Descriptor Creation",
    "text": "🔧 Basic Descriptor Creation",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#transform-deep-dive-to_upper-vs-to_lower",
    "href": "concepts/tensor-descriptor.html#transform-deep-dive-to_upper-vs-to_lower",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🔀 Transform Deep Dive: to_upper vs to_lower",
    "text": "🔀 Transform Deep Dive: to_upper vs to_lower\nEach transform has two operations: - to_upper: Lower coordinate → Upper coordinate (backward transform) - to_lower: Upper coordinate → Lower coordinate (forward transform)\n\n1. EmbedTransform: Strided Layout\n\n\n\n\n\n\n\n\n2. UnmergeTransform: Packed Layout\n\n\n\n\n\n\n\n\n3. MergeTransform: Dimension Merging\n\n\n\n\n\n\n\n\n4. ReplicateTransform: Broadcasting",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#transform-chains",
    "href": "concepts/tensor-descriptor.html#transform-chains",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🔗 Transform Chains",
    "text": "🔗 Transform Chains\nReal descriptors combine multiple transforms. TensorDescriptor internally manages these transform chains, and you can use helper functions to create common patterns:",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#symbolic-transform-analysis",
    "href": "concepts/tensor-descriptor.html#symbolic-transform-analysis",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🧮 Symbolic Transform Analysis",
    "text": "🧮 Symbolic Transform Analysis\nFor complex analysis, descriptors support symbolic mathematics:",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#why-this-matters",
    "href": "concepts/tensor-descriptor.html#why-this-matters",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🔍 Why This Matters",
    "text": "🔍 Why This Matters\nUnderstanding these transforms is CRITICAL because:\n\nmove_tensor_coordinate uses descriptor transforms to validate moves\nTensor views rely on descriptors for coordinate mapping\nTile distributions use descriptors to define data layout\nSweep operations traverse coordinates through descriptor transformations",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#interactive-applications",
    "href": "concepts/tensor-descriptor.html#interactive-applications",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "🎯 Interactive Applications",
    "text": "🎯 Interactive Applications\nExplore these concepts in our interactive apps: - Tensor Transform App - Visualize all transform types - Main App - See how descriptors integrate with distributions",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tensor-descriptor.html#next-steps",
    "href": "concepts/tensor-descriptor.html#next-steps",
    "title": "TensorDescriptor: The Complete Layout Description",
    "section": "✅ Next Steps",
    "text": "✅ Next Steps\nNow that you understand descriptors, you can move to: - Tensor Coordinates - Final memory-mapped coordinates with offsets - Tensor Adaptors - The transformation engines that execute descriptors - Advanced Coordinate Operations - Functions that require descriptors\n\nDescriptors are the mathematical foundation that makes everything else possible. Master these transforms!",
    "crumbs": [
      "Foundation",
      "TensorDescriptor: The Complete Layout Description"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html",
    "href": "concepts/tile-distribution.html",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "",
    "text": "Tile Distribution is the runtime coordinator that transforms the mathematical tile distribution encoding into actual parallel processing components. It creates the adaptors and descriptors needed to map (P,Y) coordinates to final tensor coordinates (X).",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#what-is-tile-distribution",
    "href": "concepts/tile-distribution.html#what-is-tile-distribution",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "",
    "text": "Tile Distribution is the runtime coordinator that transforms the mathematical tile distribution encoding into actual parallel processing components. It creates the adaptors and descriptors needed to map (P,Y) coordinates to final tensor coordinates (X).",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#creating-tile-distribution-from-encoding",
    "href": "concepts/tile-distribution.html#creating-tile-distribution-from-encoding",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🔧 Creating Tile Distribution from Encoding",
    "text": "🔧 Creating Tile Distribution from Encoding\nLet’s build the complete RMSNorm tile distribution step by step:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#internal-components-adaptors-and-descriptors",
    "href": "concepts/tile-distribution.html#internal-components-adaptors-and-descriptors",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🔗 Internal Components: Adaptors and Descriptors",
    "text": "🔗 Internal Components: Adaptors and Descriptors\nThe tile distribution contains two key components:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#partition-index-thread-identification",
    "href": "concepts/tile-distribution.html#partition-index-thread-identification",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🧵 Partition Index: Thread Identification",
    "text": "🧵 Partition Index: Thread Identification\nThe distribution determines which thread you are via partition indices:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#distributed-spans-spatial-distribution",
    "href": "concepts/tile-distribution.html#distributed-spans-spatial-distribution",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "📏 Distributed Spans: Spatial Distribution",
    "text": "📏 Distributed Spans: Spatial Distribution\nSpans define how computation is distributed across space:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#y-dimension-processing",
    "href": "concepts/tile-distribution.html#y-dimension-processing",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🎯 Y Dimension Processing",
    "text": "🎯 Y Dimension Processing\nY coordinates determine which data elements each thread processes:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#creating-tensor-descriptor-from-adaptor",
    "href": "concepts/tile-distribution.html#creating-tensor-descriptor-from-adaptor",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🏗️ Creating Tensor Descriptor from Adaptor",
    "text": "🏗️ Creating Tensor Descriptor from Adaptor\nTransform adaptors into descriptors for tensor operations:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#advanced-distribution-operations",
    "href": "concepts/tile-distribution.html#advanced-distribution-operations",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🧪 Advanced Distribution Operations",
    "text": "🧪 Advanced Distribution Operations\nExplore advanced coordinate mapping functionality:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#real-world-usage-patterns",
    "href": "concepts/tile-distribution.html#real-world-usage-patterns",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🚀 Real-World Usage Patterns",
    "text": "🚀 Real-World Usage Patterns\nUnderstanding how tile distribution works in practice:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#factory-functions-summary",
    "href": "concepts/tile-distribution.html#factory-functions-summary",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🏭 Factory Functions Summary",
    "text": "🏭 Factory Functions Summary\nComplete reference for tile distribution creation:",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tile-distribution.html#key-takeaways",
    "href": "concepts/tile-distribution.html#key-takeaways",
    "title": "Tile Distribution: Parallel Processing Coordination",
    "section": "🎓 Key Takeaways",
    "text": "🎓 Key Takeaways\n\nRuntime Bridge: Tile distribution transforms mathematical encoding into runtime components\nDual Components: Contains both PS_YS→XS adaptor and YS→D descriptor for complete functionality\nThread Coordination: Partition indices identify threads and map them to tensor regions\nSpatial Locality: Distributed spans ensure efficient memory access patterns\nY Processing: Y coordinates define per-thread work and enable vectorized operations\nIntegration Ready: Provides the foundation for tile windows, sweep operations, and tensor views\n\nThe tile distribution serves as the runtime coordinator that makes parallel tensor computation possible with optimal efficiency!\nNext: Static Distributed Tensors show how to use tile distributions for actual tensor operations.",
    "crumbs": [
      "Distribution",
      "Tile Distribution: Parallel Processing Coordination"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#coordinate-creation-from-descriptors-and-adaptors",
    "href": "concepts/tensor-coordinate-advanced.html#coordinate-creation-from-descriptors-and-adaptors",
    "title": "Advanced Coordinate Operations",
    "section": "🏗️ Coordinate Creation from Descriptors and Adaptors",
    "text": "🏗️ Coordinate Creation from Descriptors and Adaptors\n\nmake_tensor_coordinate: Descriptor-Based Creation\nCreates coordinates from tensor descriptors:\n\n\n\n\n\n\n\n\nmake_tensor_adaptor_coordinate: Adaptor-Based Creation\nCreates coordinates from tensor adaptors (more general than descriptors):\n\n\n\n\n\n\n\n\nKey Differences: Descriptor vs Adaptor Creation\nmake_tensor_coordinate: - Takes TensorDescriptor - Always creates TensorCoordinate - Bottom dimension is single offset - Simpler, tensor-specific\nmake_tensor_adaptor_coordinate: - Takes TensorAdaptor - Creates TensorAdaptorCoordinate - Can have multiple bottom dimensions - More general, flexible\nRelationship: - make_tensor_coordinate() calls make_tensor_adaptor_coordinate() internally - then converts result to TensorCoordinate",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#why-descriptors-are-required",
    "href": "concepts/tensor-coordinate-advanced.html#why-descriptors-are-required",
    "title": "Advanced Coordinate Operations",
    "section": "🚨 Why Descriptors Are Required",
    "text": "🚨 Why Descriptors Are Required\nMany coordinate operations need to: - Validate if a coordinate is within bounds after transformation - Move coordinates through transform chains - Convert between different coordinate spaces - Check if operations are valid in the current descriptor context",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#move_tensor_coordinate-descriptor-aware-movement",
    "href": "concepts/tensor-coordinate-advanced.html#move_tensor_coordinate-descriptor-aware-movement",
    "title": "Advanced Coordinate Operations",
    "section": "🔄 move_tensor_coordinate: Descriptor-Aware Movement",
    "text": "🔄 move_tensor_coordinate: Descriptor-Aware Movement\nThe most important function that requires descriptors:",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#coordinate-validation-with-descriptors",
    "href": "concepts/tensor-coordinate-advanced.html#coordinate-validation-with-descriptors",
    "title": "Advanced Coordinate Operations",
    "section": "🔍 Coordinate Validation with Descriptors",
    "text": "🔍 Coordinate Validation with Descriptors",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#complex-transform-navigation",
    "href": "concepts/tensor-coordinate-advanced.html#complex-transform-navigation",
    "title": "Advanced Coordinate Operations",
    "section": "🎯 Complex Transform Navigation",
    "text": "🎯 Complex Transform Navigation\nWorking with multi-transform adaptors:",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#linear-offset-calculations",
    "href": "concepts/tensor-coordinate-advanced.html#linear-offset-calculations",
    "title": "Advanced Coordinate Operations",
    "section": "🧮 Linear Offset Calculations",
    "text": "🧮 Linear Offset Calculations\nUnderstanding how descriptors convert to linear memory offsets:",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#integration-with-tensor-views",
    "href": "concepts/tensor-coordinate-advanced.html#integration-with-tensor-views",
    "title": "Advanced Coordinate Operations",
    "section": "🔗 Integration with Tensor Views",
    "text": "🔗 Integration with Tensor Views\nHow advanced coordinates work with tensor views:",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#interactive-coordinate-debugging",
    "href": "concepts/tensor-coordinate-advanced.html#interactive-coordinate-debugging",
    "title": "Advanced Coordinate Operations",
    "section": "🎮 Interactive Coordinate Debugging",
    "text": "🎮 Interactive Coordinate Debugging\nAdvanced debugging techniques:",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#why-these-operations-matter",
    "href": "concepts/tensor-coordinate-advanced.html#why-these-operations-matter",
    "title": "Advanced Coordinate Operations",
    "section": "🔍 Why These Operations Matter",
    "text": "🔍 Why These Operations Matter\nThese advanced coordinate operations are essential for:\n\nTile Windows - Moving through tensor regions requires descriptor-aware navigation\nSweep Operations - Iterating over distributed data needs validated coordinate movement\n\nTensor Views - Accessing tensor elements through complex layouts\nDistribution Systems - Converting between thread coordinates and tensor coordinates",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#interactive-applications",
    "href": "concepts/tensor-coordinate-advanced.html#interactive-applications",
    "title": "Advanced Coordinate Operations",
    "section": "🎯 Interactive Applications",
    "text": "🎯 Interactive Applications\nTest these concepts in our apps: - Tensor Transform App - Visualize coordinate transformations - Main App - See coordinates in action with distributions",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#next-steps",
    "href": "concepts/tensor-coordinate-advanced.html#next-steps",
    "title": "Advanced Coordinate Operations",
    "section": "✅ Next Steps",
    "text": "✅ Next Steps\nNow you can understand: - Tile Distribution - How coordinates map to parallel processing - Advanced Operations - Complex coordinate-based operations",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tensor-coordinate-advanced.html#coordinate-movement",
    "href": "concepts/tensor-coordinate-advanced.html#coordinate-movement",
    "title": "Advanced Coordinate Operations",
    "section": "Coordinate Movement",
    "text": "Coordinate Movement\nCoordinate movement is essential for iterating through tensor spaces, especially when transformations are involved. Movement requires knowledge of the descriptor or adaptor, since the transformation chain determines how steps in the top space map to changes in the hidden and bottom spaces.\nExample:\n\n\n\n\n\n\n\nNote: Movement is only meaningful after you understand how descriptors and adaptors define the mapping between top, hidden, and bottom spaces.\n\n\nThese operations bridge the gap between mathematical transforms and practical tensor manipulation!",
    "crumbs": [
      "Advanced Indexing",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html",
    "href": "concepts/tile-distribution-encoding.html",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "",
    "text": "Tile Distribution Encoding is a mathematical framework that describes how tensor data is distributed across parallel processing elements (threads, warps, blocks). It represents the distribution pattern as a graph structure where:\n\nNODES: R, H₀, H₁, … Hₙ dimension sequences\n\nEDGES: P and Y mappings that create connections\nINCIDENCE MATRIX: Major/Minor indices define the edge structure",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#what-is-tile-distribution-encoding",
    "href": "concepts/tile-distribution-encoding.html#what-is-tile-distribution-encoding",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "",
    "text": "Tile Distribution Encoding is a mathematical framework that describes how tensor data is distributed across parallel processing elements (threads, warps, blocks). It represents the distribution pattern as a graph structure where:\n\nNODES: R, H₀, H₁, … Hₙ dimension sequences\n\nEDGES: P and Y mappings that create connections\nINCIDENCE MATRIX: Major/Minor indices define the edge structure",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#graph-structure-concept",
    "href": "concepts/tile-distribution-encoding.html#graph-structure-concept",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🕸️ Graph Structure Concept",
    "text": "🕸️ Graph Structure Concept\nThe encoding creates a mathematical graph that systematically maps processing elements (P) to tensor coordinates (Y). This graph structure enables efficient parallel tensor processing by establishing clear relationships between threads and data elements.\n\n\n\nGraph Structure Overview\n\n\nThe graph consists of:\n\nNODES: R sequences (replication), H₀ sequences (dimension 0), H₁ sequences (dimension 1), … Hₙ sequences\n\nEDGES: P→RH mappings and Y→RH mappings that define connectivity\nINCIDENCE MATRIX: Major/minor indices that specify exactly which nodes connect\n\n\n\n\nCoordinate Transform Process\n\n\n\nMajor/Minor Indexing System\nThe graph connectivity uses a systematic indexing where: - 0 = R space (replication sequences) - 1 = H₀ space (first hierarchical dimension) - 2 = H₁ space (second hierarchical dimension) - n+1 = Hₙ space (nth hierarchical dimension)\nBoth P (processing elements) and Y (tensor coordinates) map to this RH space through major/minor index pairs that define precise graph connectivity:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#creating-the-encoding",
    "href": "concepts/tile-distribution-encoding.html#creating-the-encoding",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🔧 Creating the Encoding",
    "text": "🔧 Creating the Encoding\nThe encoding combines all graph structure information:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#encoding-detail-information",
    "href": "concepts/tile-distribution-encoding.html#encoding-detail-information",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "📊 Encoding Detail Information",
    "text": "📊 Encoding Detail Information\nThe encoding automatically computes detailed mapping information:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#understanding-the-prh-and-yrh-mappings",
    "href": "concepts/tile-distribution-encoding.html#understanding-the-prh-and-yrh-mappings",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🎯 Understanding the P→RH and Y→RH Mappings",
    "text": "🎯 Understanding the P→RH and Y→RH Mappings\nThe major/minor system creates a precise incidence matrix:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#real-world-interpretation",
    "href": "concepts/tile-distribution-encoding.html#real-world-interpretation",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🚀 Real-World Interpretation",
    "text": "🚀 Real-World Interpretation\nUnderstanding what the RMSNorm encoding means in practice:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#spans-distributed-computation-patterns",
    "href": "concepts/tile-distribution-encoding.html#spans-distributed-computation-patterns",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🎨 Spans: Distributed Computation Patterns",
    "text": "🎨 Spans: Distributed Computation Patterns\nSpans represent how computation is distributed spatially:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#factory-functions",
    "href": "concepts/tile-distribution-encoding.html#factory-functions",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🏗️ Factory Functions",
    "text": "🏗️ Factory Functions\nKey functions for creating encoding structures:",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "concepts/tile-distribution-encoding.html#key-takeaways",
    "href": "concepts/tile-distribution-encoding.html#key-takeaways",
    "title": "Tile Distribution Encoding: Mathematical Graph Structure",
    "section": "🎓 Key Takeaways",
    "text": "🎓 Key Takeaways\n\nGraph Structure: Tile distribution encoding represents parallel computation as a graph with R/H nodes and P/Y edges\nIncidence Matrix: Major/minor indices create precise mappings between processing elements and data\nHierarchical Organization: R (replication) → H (hierarchical tiles) → spans → Y (element indexing)\nEfficiency: The encoding ensures optimal work distribution across parallel processing elements\nFoundation: This mathematical structure enables all higher-level tile distribution operations\n\nThe tile distribution encoding serves as the mathematical foundation for all parallel tensor operations in the Composable Kernels framework!",
    "crumbs": [
      "Distribution",
      "Tile Distribution Encoding: Mathematical Graph Structure"
    ]
  },
  {
    "objectID": "index.html#recommended-learning-path",
    "href": "index.html#recommended-learning-path",
    "title": "Composable-Kernels Python Documentation",
    "section": "🎓 Recommended Learning Path",
    "text": "🎓 Recommended Learning Path\nNew to PythonCK? Follow our structured learning path to understand all concepts:\n\n📚 Complete Learning Path\nA step-by-step guide that builds from basic concepts to advanced GPU thread coordination, culminating in understanding the complete tile_distr_thread_mapping.py example.",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#learning-by-topic",
    "href": "index.html#learning-by-topic",
    "title": "Composable-Kernels Python Documentation",
    "section": "📖 Learning by Topic",
    "text": "📖 Learning by Topic\n\n1. Foundation Concepts\n\nBuffer Views - Memory buffer abstraction\nTensor Coordinates - Multi-dimensional indexing\nTensor Descriptors - Layout transformations\nTensor Views - Unified tensor access\n\n\n\n2. Distribution Concepts\n\nTile Distribution Encoding - How data is distributed\nTile Distribution - Parallel processing coordination\nStatic Distributed Tensors - Thread-local data\n\n\n\n3. Advanced Operations\n\nTile Windows - Windowed tensor access\nSweep Operations - Iterating over distributed data\nThread Mapping - Understanding the complete pipeline",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#package-structure",
    "href": "index.html#package-structure",
    "title": "Composable-Kernels Python Documentation",
    "section": "📦 Package Structure",
    "text": "📦 Package Structure\npytensor/                    # Core tensor operations\n├── buffer_view.py          # Memory abstraction\n├── tensor_coordinate.py    # Multi-dimensional indexing\n├── tensor_descriptor.py    # Layout transformations  \n├── tensor_view.py          # Unified access interface\n├── tile_distribution.py    # Data distribution\n├── tile_window.py          # Windowed access\n├── sweep_tile.py           # Coordinated iteration\n└── ...\n\ntensor_transforms/          # Analysis tools\n├── parser.py              # Descriptor parsing\n├── analyzer.py            # Transformation analysis\n└── ...\n\ntile_distribution/          # Visualization tools\n├── parser.py              # C++ encoding parsing\n├── visualizer.py          # Interactive visualization\n└── ...",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#key-concepts",
    "href": "index.html#key-concepts",
    "title": "Composable-Kernels Python Documentation",
    "section": "🔑 Key Concepts",
    "text": "🔑 Key Concepts\nPythonCK implements several interconnected concepts:\n\nTensors are multi-dimensional arrays with flexible layouts\nCoordinates provide multi-dimensional indexing with transformations\nDistributions define how data is spread across parallel processing elements\nTiles represent chunks of data processed by individual threads/warps\nSweeps iterate over distributed data in a coordinated manner\n\nThe ultimate goal is understanding how GPU threads coordinate to process large tensors efficiently, as demonstrated in the complete example at tile_distr_thread_mapping.py.",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#quick-start",
    "href": "index.html#quick-start",
    "title": "Composable-Kernels Python Documentation",
    "section": "🚀 Quick Start",
    "text": "🚀 Quick Start\nJump right in with interactive examples:",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#interactive-applications",
    "href": "index.html#interactive-applications",
    "title": "Composable-Kernels Python Documentation",
    "section": "🎮 Interactive Applications",
    "text": "🎮 Interactive Applications\nExplore PythonCK concepts through three interactive web applications:\n\n📊 Tile Distribution Visualizer\nInteractive visualization of tile distribution structures and GPU memory layouts. Perfect for understanding how data is distributed across parallel processing elements.\n\n\n🔄 Tensor Transform Visualizer\nExplore tensor descriptor transformations with visual graphs and mathematical formulas. See how data layouts change through various transformations.\n\n\n🧵 Thread Visualization App\nVisualize GPU thread coordinate mapping and access patterns. Understand how individual threads access distributed tensor data.",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#learning-paths",
    "href": "index.html#learning-paths",
    "title": "Composable-Kernels Python Documentation",
    "section": "🎯 Learning Paths",
    "text": "🎯 Learning Paths\nChoose your learning approach:\n\n🎓 Structured Path - Follow the complete 10-step progression\n🔍 Concept-Driven - Explore individual concepts as needed\n💻 Code-First - Jump into the API documentation\n🎮 Interactive - Try hands-on tutorials",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "index.html#interactive-features",
    "href": "index.html#interactive-features",
    "title": "Composable-Kernels Python Documentation",
    "section": "✨ Interactive Features",
    "text": "✨ Interactive Features\nThis documentation includes:\n\n🏃 Live Code Execution - Run Python code directly in your browser\n📱 Responsive Design - Works on desktop and mobile\n🌓 Dark/Light Mode - Toggle between themes\n🔍 Full-Text Search - Find what you need quickly\n📋 Copy Code - One-click code copying\n🔗 Deep Linking - Share links to specific sections\n\n\nReady to dive deeper? Start with our Complete Learning Path or jump to any concept that interests you.",
    "crumbs": [
      "Getting Started",
      "Composable-Kernels Python Documentation"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor.html#what-does-a-tensoradaptor-do",
    "href": "concepts/tensor-adaptor.html#what-does-a-tensoradaptor-do",
    "title": "TensorAdaptor: The Transformation Engine",
    "section": "What does a TensorAdaptor do?",
    "text": "What does a TensorAdaptor do?\nA TensorAdaptor manages the transformation pipeline from top coordinates (user-facing, logical indices) to bottom coordinates (memory layout, physical indices).\n\nCoordinate transformation: Provides calculate_bottom_index() method to transform from top-level indices to bottom-level (memory) indices.\nTransform chain management: Internally manages a sequence of transforms but does not allow adding/removing transforms after creation.\nHidden dimension tracking: Maintains the mapping between transform inputs/outputs through hidden dimension IDs.\n\n\nKey Methods\n\ncalculate_bottom_index(idx_top): Transform top coordinates to bottom coordinates\nget_num_of_transform(): Get the number of transforms in the chain\nget_num_of_top_dimension(): Get number of top (user-facing) dimensions\nget_num_of_bottom_dimension(): Get number of bottom (memory) dimensions\nget_num_of_hidden_dimension(): Get total number of hidden dimensions",
    "crumbs": [
      "Foundation",
      "TensorAdaptor: The Transformation Engine"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor.html#example-usage",
    "href": "concepts/tensor-adaptor.html#example-usage",
    "title": "TensorAdaptor: The Transformation Engine",
    "section": "Example Usage",
    "text": "Example Usage\nHere is how you create a TensorAdaptor that merges two dimensions into one (e.g., for a 2D-to-1D mapping):\n\n\n\n\n\n\nHere’s a more complex example with an embed transform:",
    "crumbs": [
      "Foundation",
      "TensorAdaptor: The Transformation Engine"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor.html#coordinate-transformation",
    "href": "concepts/tensor-adaptor.html#coordinate-transformation",
    "title": "TensorAdaptor: The Transformation Engine",
    "section": "Coordinate Transformation",
    "text": "Coordinate Transformation\nHere’s how to use a TensorAdaptor to transform coordinates from top to bottom:",
    "crumbs": [
      "Foundation",
      "TensorAdaptor: The Transformation Engine"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor.html#tensoradaptor-vs-tensordescriptor",
    "href": "concepts/tensor-adaptor.html#tensoradaptor-vs-tensordescriptor",
    "title": "TensorAdaptor: The Transformation Engine",
    "section": "TensorAdaptor vs TensorDescriptor",
    "text": "TensorAdaptor vs TensorDescriptor\n\n\n\n\n\n\n\nTensorAdaptor\nTensorDescriptor\n\n\n\n\nManages coordinate transformations\nExtends TensorAdaptor with element space info\n\n\nHas calculate_bottom_index()\nAdds calculate_offset(), get_lengths()\n\n\nTracks hidden dimension mappings\nAdds element space size and vector guarantees\n\n\nUsed as building block\nUsed for complete tensor layout description\n\n\nNo element space concept\nKnows total number of elements",
    "crumbs": [
      "Foundation",
      "TensorAdaptor: The Transformation Engine"
    ]
  },
  {
    "objectID": "concepts/tensor-adaptor.html#when-to-use-tensoradaptor",
    "href": "concepts/tensor-adaptor.html#when-to-use-tensoradaptor",
    "title": "TensorAdaptor: The Transformation Engine",
    "section": "When to Use TensorAdaptor",
    "text": "When to Use TensorAdaptor\n\nBuilding coordinate transformation pipelines: When you need to chain multiple transforms\nCustom tensor layouts: When standard layouts don’t meet your needs\n\nAs components in larger systems: TensorDescriptor internally uses TensorAdaptor\nResearch and experimentation: When exploring new transformation patterns\n\nTensorAdaptor provides the foundation for coordinate transformations, while TensorDescriptor builds upon it to provide complete tensor layout descriptions for practical use.\nNext: TensorDescriptor — Learn how TensorDescriptor extends TensorAdaptor with element space information.",
    "crumbs": [
      "Foundation",
      "TensorAdaptor: The Transformation Engine"
    ]
  },
  {
    "objectID": "concepts/learning-path.html#ultimate-goal-understanding-tile_distr_thread_mapping.py",
    "href": "concepts/learning-path.html#ultimate-goal-understanding-tile_distr_thread_mapping.py",
    "title": "PythonCK Learning Path",
    "section": "🎯 Ultimate Goal: Understanding tile_distr_thread_mapping.py",
    "text": "🎯 Ultimate Goal: Understanding tile_distr_thread_mapping.py\nThe final example demonstrates complete GPU thread coordination - how threads cooperatively process tensor data using tile windows, sweep operations, and distribution strategies.",
    "crumbs": [
      "Reference",
      "PythonCK Learning Path"
    ]
  },
  {
    "objectID": "concepts/learning-path.html#reorganized-learning-path",
    "href": "concepts/learning-path.html#reorganized-learning-path",
    "title": "PythonCK Learning Path",
    "section": "📚 Reorganized Learning Path",
    "text": "📚 Reorganized Learning Path\n\nPhase 1: Foundation (Memory & Basic Indexing)\n\nBuffer Views - Memory abstraction layer\nTensor Transforms - The building blocks for coordinate transformations\nTensor Descriptors - Layout configuration and transformations\nTensor Coordinates - Final memory-mapped coordinates with offsets\nTensor Adaptors - The transformation engines that execute descriptors\nTensor Adaptor Coordinates - Result containers for transformed indices/offsets\n\n\n\nPhase 2: Advanced Indexing (Requires Descriptors)\n\nAdvanced Coordinate Operations - move_tensor_coordinate and transform-dependent operations\nTensor Views - Unified access interface\n\n\n\nPhase 3: Distribution (Parallel Processing)\n\nTile Distribution Encoding - Mathematical encoding framework\nTile Distribution Deep Dive - make_static_tile_distribution, adaptors, descriptors\nStatic Distributed Tensors - Thread-local data management\n\n\n\nPhase 4: Advanced Operations (GPU Coordination)\n\nTile Windows Deep Dive - precompute, load, descriptor integration\nSweep Operations - Coordinated iteration patterns\nComplete Thread Mapping - Understanding the full pipeline",
    "crumbs": [
      "Reference",
      "PythonCK Learning Path"
    ]
  },
  {
    "objectID": "concepts/learning-path.html#key-restructuring-changes",
    "href": "concepts/learning-path.html#key-restructuring-changes",
    "title": "PythonCK Learning Path",
    "section": "🔄 Key Restructuring Changes",
    "text": "🔄 Key Restructuring Changes\n\nLogical Learning Order\n\nBefore: Basic Coordinates → Descriptors → Advanced Coordinates (❌ Mixed concepts)\nAfter: Transforms → Descriptors → Coordinates → Adaptors → Adaptor Coordinates (✅ Clear flow)\n\n\n\nConceptual Flow\n\nTensor Transforms: The building blocks for coordinate transformations (Embed, Unmerge, Merge, Replicate)\nTensorDescriptor: Configuration/metadata for transformations (what to do)\nTensorCoordinate: Final memory-mapped coordinates with offsets (what users work with)\nTensorAdaptor: Transformation engine that executes descriptors (how to do it)\nTensorAdaptorCoordinate: Result containers for transformed indices/offsets (intermediate results)\n\n\n\nDependency-Aware Ordering\n\nBefore: Coordinates → Descriptors (❌ Wrong dependency order)\nAfter: Descriptors → Coordinates → Adaptors → Adaptor Coordinates (✅ Correct)\n\n\n\nFocused Pages\n\nBefore: Long pages with multiple concepts\nAfter: One concept per page with deep explanations\n\n\n\nTransform Examples\n\nComplete to_upper/to_lower examples for all transforms\nVisual demonstrations of coordinate transformations\n\n\n\nDeep Integration Examples\n\nHow precompute uses both tensor and distribution descriptors\nComplete breakdown of make_static_tile_distribution\nLinks to interactive apps",
    "crumbs": [
      "Reference",
      "PythonCK Learning Path"
    ]
  },
  {
    "objectID": "concepts/learning-path.html#learning-strategy",
    "href": "concepts/learning-path.html#learning-strategy",
    "title": "PythonCK Learning Path",
    "section": "🎓 Learning Strategy",
    "text": "🎓 Learning Strategy\n\nFollow the order strictly - later concepts build on earlier ones\nRun all examples - hands-on understanding is crucial\nExperiment with parameters - modify examples to see effects\nUse the apps - tensor_transform_app and app for visualization",
    "crumbs": [
      "Reference",
      "PythonCK Learning Path"
    ]
  },
  {
    "objectID": "concepts/learning-path.html#interactive-applications",
    "href": "concepts/learning-path.html#interactive-applications",
    "title": "PythonCK Learning Path",
    "section": "🔗 Interactive Applications",
    "text": "🔗 Interactive Applications\n\nTensor Transform App - Visualize descriptor transformations\nMain App - Explore tile distributions and thread mapping\nThread Mapping Example - Complete GPU coordination",
    "crumbs": [
      "Reference",
      "PythonCK Learning Path"
    ]
  },
  {
    "objectID": "concepts/learning-path.html#page-structure",
    "href": "concepts/learning-path.html#page-structure",
    "title": "PythonCK Learning Path",
    "section": "📖 Page Structure",
    "text": "📖 Page Structure\nEach concept page now includes: - ✅ Prerequisites - What you need to understand first - ✅ Core Concept - Focused explanation - ✅ Interactive Examples - Hands-on code - ✅ Transform Examples - to_upper/to_lower for applicable concepts - ✅ Integration Points - How it connects to other concepts - ✅ Next Steps - What to learn next\n\nReady to start? Begin with Buffer Views - the foundation of memory abstraction, then learn Tensor Transforms - the building blocks for all coordinate operations.",
    "crumbs": [
      "Reference",
      "PythonCK Learning Path"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html",
    "href": "concepts/tensor-view.html",
    "title": "Tensor Views: Unified Memory Access",
    "section": "",
    "text": "A TensorView combines a BufferView (memory access) with a TensorDescriptor (layout) to provide unified, coordinate-based access to tensor data. It’s the bridge between mathematical tensor operations and actual memory manipulation.",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#what-is-a-tensorview",
    "href": "concepts/tensor-view.html#what-is-a-tensorview",
    "title": "Tensor Views: Unified Memory Access",
    "section": "",
    "text": "A TensorView combines a BufferView (memory access) with a TensorDescriptor (layout) to provide unified, coordinate-based access to tensor data. It’s the bridge between mathematical tensor operations and actual memory manipulation.",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#core-architecture",
    "href": "concepts/tensor-view.html#core-architecture",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🏗️ Core Architecture",
    "text": "🏗️ Core Architecture\nTensorView = BufferView + TensorDescriptor + Memory Operations",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#element-access-methods",
    "href": "concepts/tensor-view.html#element-access-methods",
    "title": "Tensor Views: Unified Memory Access",
    "section": "📍 Element Access Methods",
    "text": "📍 Element Access Methods\nTensorView provides multiple ways to access elements:\n\n1. Coordinate-Based Access\n\n\n\n\n\n\n\n\n2. Array-Style Indexing\n\n\n\n\n\n\n\n\n3. Vectorized Operations",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#memory-operations",
    "href": "concepts/tensor-view.html#memory-operations",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🔧 Memory Operations",
    "text": "🔧 Memory Operations\nTensorView supports different memory operations for updates:",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#factory-functions",
    "href": "concepts/tensor-view.html#factory-functions",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🏭 Factory Functions",
    "text": "🏭 Factory Functions\nMultiple factory functions for different use cases:\n\nNaive Tensor View (Strided)\n\n\n\n\n\n\n\n\nPacked Tensor View",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#integration-with-coordinates",
    "href": "concepts/tensor-view.html#integration-with-coordinates",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🔄 Integration with Coordinates",
    "text": "🔄 Integration with Coordinates\nTensorView works seamlessly with TensorCoordinate:",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#linear-offset-parameter",
    "href": "concepts/tensor-view.html#linear-offset-parameter",
    "title": "Tensor Views: Unified Memory Access",
    "section": "📏 Linear Offset Parameter",
    "text": "📏 Linear Offset Parameter\nTensorView supports linear offsets for efficient memory access:",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#different-address-spaces",
    "href": "concepts/tensor-view.html#different-address-spaces",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🎨 Different Address Spaces",
    "text": "🎨 Different Address Spaces\nTensorView supports different memory address spaces:",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#real-world-example-matrix-operations",
    "href": "concepts/tensor-view.html#real-world-example-matrix-operations",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🔍 Real-World Example: Matrix Operations",
    "text": "🔍 Real-World Example: Matrix Operations",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#advanced-features",
    "href": "concepts/tensor-view.html#advanced-features",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🔧 Advanced Features",
    "text": "🔧 Advanced Features\n\nOut-of-Bounds Checking",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#why-tensorview-matters",
    "href": "concepts/tensor-view.html#why-tensorview-matters",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🎯 Why TensorView Matters",
    "text": "🎯 Why TensorView Matters\nTensorView is essential because it:\n\n🔗 Unifies Access: Single interface for coordinate and linear access\n🎛️ Abstracts Memory: Works with different address spaces transparently\n\n⚡ Optimizes Performance: Vectorized operations and efficient indexing\n🛡️ Provides Safety: Bounds checking and type safety\n🧩 Enables Composition: Integrates seamlessly with descriptors and coordinates",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#integration-with-other-components",
    "href": "concepts/tensor-view.html#integration-with-other-components",
    "title": "Tensor Views: Unified Memory Access",
    "section": "🔗 Integration with Other Components",
    "text": "🔗 Integration with Other Components\n\nBufferView: Provides the underlying memory access interface\nTensorDescriptor: Defines the tensor layout and transformations\nTensorCoordinate: Enables coordinate-based navigation and indexing\nTransform System: Works with complex tensor layouts and access patterns",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-view.html#next-steps",
    "href": "concepts/tensor-view.html#next-steps",
    "title": "Tensor Views: Unified Memory Access",
    "section": "✅ Next Steps",
    "text": "✅ Next Steps\nNow you understand tensor views! You can explore:\n\nBuffer Views - The memory access foundation\nTensor Descriptors - Layout and transformation system\nTensor Coordinates - Navigation and indexing\n\n\nTensorView bridges the gap between mathematical tensor concepts and efficient memory access! 🌉",
    "crumbs": [
      "Advanced Indexing",
      "Tensor Views: Unified Memory Access"
    ]
  },
  {
    "objectID": "concepts/tensor-transforms.html#core-concept",
    "href": "concepts/tensor-transforms.html#core-concept",
    "title": "Tensor Transforms: The Building Blocks",
    "section": "🎯 Core Concept",
    "text": "🎯 Core Concept\nA Tensor Transform is a mathematical operation that converts coordinates between two spaces:\nUpper Coordinates ←→ Transform ←→ Lower Coordinates\nEach transform has two operations: - to_lower: Upper coordinate → Lower coordinate (forward transform) - to_upper: Lower coordinate → Upper coordinate (backward transform)",
    "crumbs": [
      "Foundation",
      "Tensor Transforms: The Building Blocks"
    ]
  },
  {
    "objectID": "concepts/tensor-transforms.html#transform-types",
    "href": "concepts/tensor-transforms.html#transform-types",
    "title": "Tensor Transforms: The Building Blocks",
    "section": "🔧 Transform Types",
    "text": "🔧 Transform Types\n\n1. EmbedTransform: Strided Layout\nPurpose: Maps multi-dimensional coordinates to linear memory with custom strides.\n\n\n\n\n\n\n\nForward Transformation (to_lower)\n\n\n\n\n\n\n\n\nBackward Transformation (to_upper)\n\n\n\n\n\n\n\n\nVisual Example\n\n\n\n\n\n\n\n\n\n2. UnmergeTransform: Packed Layout\nPurpose: Unpacks a linear index into multi-dimensional coordinates.\n\n\n\n\n\n\n\nForward Transformation (to_lower)\n\n\n\n\n\n\n\n\nBackward Transformation (to_upper)\n\n\n\n\n\n\n\n\n\n3. MergeTransform: Dimension Merging\nPurpose: Merges multiple dimensions into a single dimension.\nKey Difference from EmbedTransform: - EmbedTransform: Maps multi-dimensional coordinates to linear memory with custom strides (preserves the original coordinate structure) - MergeTransform: Collapses multiple dimensions into a single dimension (changes the coordinate structure)\n\n\n\n\n\n\n\nForward Transformation (to_lower)\n\n\n\n\n\n\n\n\nBackward Transformation (to_upper)\n\n\n\n\n\n\n\n\n\n4. ReplicateTransform: Broadcasting\nPurpose: Broadcasts smaller dimensions to larger dimensions (replication).\n\n\n\n\n\n\n\nForward Transformation (to_lower)\n\n\n\n\n\n\n\n\nBackward Transformation (to_upper)",
    "crumbs": [
      "Foundation",
      "Tensor Transforms: The Building Blocks"
    ]
  },
  {
    "objectID": "concepts/tensor-transforms.html#transform-validation",
    "href": "concepts/tensor-transforms.html#transform-validation",
    "title": "Tensor Transforms: The Building Blocks",
    "section": "🔄 Transform Validation",
    "text": "🔄 Transform Validation\n\nBidirectional Verification",
    "crumbs": [
      "Foundation",
      "Tensor Transforms: The Building Blocks"
    ]
  },
  {
    "objectID": "concepts/tensor-transforms.html#integration-with-real-applications",
    "href": "concepts/tensor-transforms.html#integration-with-real-applications",
    "title": "Tensor Transforms: The Building Blocks",
    "section": "🎯 Integration with Real Applications",
    "text": "🎯 Integration with Real Applications\nTransforms are used throughout PythonCK:\n\nTensor Descriptors combine transforms to define tensor layouts\nTensor Adaptors execute transforms to perform coordinate conversions\nTile Distributions use transforms to map between coordinate spaces\nMemory Access relies on transforms for address calculations",
    "crumbs": [
      "Foundation",
      "Tensor Transforms: The Building Blocks"
    ]
  },
  {
    "objectID": "concepts/tensor-transforms.html#next-steps",
    "href": "concepts/tensor-transforms.html#next-steps",
    "title": "Tensor Transforms: The Building Blocks",
    "section": "✅ Next Steps",
    "text": "✅ Next Steps\nNow that you understand the individual transforms, you can explore: - Tensor Descriptors - How transforms are combined into layout definitions - Tensor Coordinates - How transforms create final memory-mapped coordinates - Tensor Adaptors - How transforms are executed as transformation engines\n\nTensor Transforms are the mathematical building blocks that make all coordinate operations possible. Master these four transform types to understand how PythonCK maps between different coordinate spaces.",
    "crumbs": [
      "Foundation",
      "Tensor Transforms: The Building Blocks"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#core-concepts",
    "href": "concepts/buffer-view.html#core-concepts",
    "title": "Buffer View",
    "section": "Core Concepts",
    "text": "Core Concepts\n\nMemory Address Spaces\n\n\n\n\n\n\n\n\nMemory Operations",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#creating-buffer-views",
    "href": "concepts/buffer-view.html#creating-buffer-views",
    "title": "Buffer View",
    "section": "Creating Buffer Views",
    "text": "Creating Buffer Views\n\nBasic Buffer View\n\n\n\n\n\n\n\n\nAccessing Buffer Elements",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#memory-operations-1",
    "href": "concepts/buffer-view.html#memory-operations-1",
    "title": "Buffer View",
    "section": "Memory Operations",
    "text": "Memory Operations\n\nSET Operation\n\n\n\n\n\n\n\n\nADD Operation",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#advanced-buffer-operations",
    "href": "concepts/buffer-view.html#advanced-buffer-operations",
    "title": "Buffer View",
    "section": "Advanced Buffer Operations",
    "text": "Advanced Buffer Operations\n\nBuffer Views with Strides\n\n\n\n\n\n\n\n\nBuffer Reshaping",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#buffer-view-integration",
    "href": "concepts/buffer-view.html#buffer-view-integration",
    "title": "Buffer View",
    "section": "Buffer View Integration",
    "text": "Buffer View Integration\nBuffer views serve as the foundation for all tensor operations in PythonCK. They provide the memory abstraction that higher-level components like tensor views and tile windows build upon.",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#relationship-to-other-concepts",
    "href": "concepts/buffer-view.html#relationship-to-other-concepts",
    "title": "Buffer View",
    "section": "Relationship to Other Concepts",
    "text": "Relationship to Other Concepts\nBuffer views are the foundation for:\n\nTensor Views - Combine buffers with tensor descriptors for structured access\nTile Windows - Provide windowed access to buffer regions\nStatic Distributed Tensors - Thread-local buffer management\nMemory Operations - All tensor operations ultimately access memory through buffer views",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "concepts/buffer-view.html#next-steps",
    "href": "concepts/buffer-view.html#next-steps",
    "title": "Buffer View",
    "section": "Next Steps",
    "text": "Next Steps\n\nLearn about Tensor Coordinates for multi-dimensional indexing\nExplore Tensor Views to see how buffers combine with descriptors\nUnderstand Static Distributed Tensors for parallel buffer management\n\nBuffer views provide the essential memory abstraction that enables all higher-level tensor operations in PythonCK.",
    "crumbs": [
      "Foundation",
      "Buffer View"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API Reference",
    "section": "",
    "text": "Complete reference documentation for all PythonCK modules and classes.\n\n\n\n\nThe main tensor operations module containing all core functionality.\n\ntensor_coordinate - Multi-dimensional coordinate handling\ntensor_descriptor - Tensor layout and metadata\ntensor_adaptor - Tensor transformations and adaptations\ntensor_view - Views and slicing operations\nbuffer_view - Low-level memory access patterns\n\n\n\n\n\n\ntile_distribution - Data distribution across tiles\ntile_distribution_encoding - Encoding schemes for tile distribution\ntile_window - Windowed access to tile data\ntile_window_linear - Linear tile window operations\ntile_window_utils - Utility functions for tile windows\n\n\n\n\n\nshuffle_tile - Data shuffling and rearrangement\nsweep_tile - Iterative tile processing\nstore_tile - Tile storage operations\nupdate_tile - In-place tile updates\ntile_scatter_gather - Scatter/gather operations\n\n\n\n\n\nstatic_distributed_tensor - Compile-time optimized tensors\nspace_filling_curve - Advanced memory access patterns\nstatic_encoding_pattern - Static encoding strategies\n\n\n\n\n\n\nHigher-level transformation utilities and examples.\n\nanalyzer - Tensor operation analysis\nparser - Parsing tensor expressions\nexamples - Common transformation patterns\n\n\n\n\nAdvanced tile distribution strategies and visualization.\n\nparser - Tile distribution parsing\nvisualizer - Tile distribution visualization\nexamples - Tile distribution examples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClass\nPurpose\nKey Methods\n\n\n\n\nTensorCoordinate\nMulti-dimensional indexing\n__init__(), get_element_count()\n\n\nTensorDescriptor\nTensor metadata\ncalculate_offset(), get_strides()\n\n\nTensorAdaptor\nTensor transformations\ntransform_coordinate(), get_output_shape()\n\n\nBufferView\nMemory access patterns\ngenerate_access_sequence()\n\n\nTileDistribution\nTile-based processing\nget_tile_coordinates(), get_num_tiles()\n\n\nTileWindow\nWindowed tile access\nget_window_data(), slide_window()\n\n\n\n\nFor detailed documentation of each module, click on the links above. Each page includes:\n\nClass definitions with full method signatures\nUsage examples with runnable code\nParameter descriptions and return values\nRelated concepts and cross-references",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#core-tensor-operations",
    "href": "api/index.html#core-tensor-operations",
    "title": "API Reference",
    "section": "",
    "text": "The main tensor operations module containing all core functionality.\n\ntensor_coordinate - Multi-dimensional coordinate handling\ntensor_descriptor - Tensor layout and metadata\ntensor_adaptor - Tensor transformations and adaptations\ntensor_view - Views and slicing operations\nbuffer_view - Low-level memory access patterns",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#tile-operations",
    "href": "api/index.html#tile-operations",
    "title": "API Reference",
    "section": "",
    "text": "tile_distribution - Data distribution across tiles\ntile_distribution_encoding - Encoding schemes for tile distribution\ntile_window - Windowed access to tile data\ntile_window_linear - Linear tile window operations\ntile_window_utils - Utility functions for tile windows",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#specialized-tile-operations",
    "href": "api/index.html#specialized-tile-operations",
    "title": "API Reference",
    "section": "",
    "text": "shuffle_tile - Data shuffling and rearrangement\nsweep_tile - Iterative tile processing\nstore_tile - Tile storage operations\nupdate_tile - In-place tile updates\ntile_scatter_gather - Scatter/gather operations",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#advanced-features",
    "href": "api/index.html#advanced-features",
    "title": "API Reference",
    "section": "",
    "text": "static_distributed_tensor - Compile-time optimized tensors\nspace_filling_curve - Advanced memory access patterns\nstatic_encoding_pattern - Static encoding strategies",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#utilities",
    "href": "api/index.html#utilities",
    "title": "API Reference",
    "section": "",
    "text": "Higher-level transformation utilities and examples.\n\nanalyzer - Tensor operation analysis\nparser - Parsing tensor expressions\nexamples - Common transformation patterns\n\n\n\n\nAdvanced tile distribution strategies and visualization.\n\nparser - Tile distribution parsing\nvisualizer - Tile distribution visualization\nexamples - Tile distribution examples",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  },
  {
    "objectID": "api/index.html#quick-reference",
    "href": "api/index.html#quick-reference",
    "title": "API Reference",
    "section": "",
    "text": "Class\nPurpose\nKey Methods\n\n\n\n\nTensorCoordinate\nMulti-dimensional indexing\n__init__(), get_element_count()\n\n\nTensorDescriptor\nTensor metadata\ncalculate_offset(), get_strides()\n\n\nTensorAdaptor\nTensor transformations\ntransform_coordinate(), get_output_shape()\n\n\nBufferView\nMemory access patterns\ngenerate_access_sequence()\n\n\nTileDistribution\nTile-based processing\nget_tile_coordinates(), get_num_tiles()\n\n\nTileWindow\nWindowed tile access\nget_window_data(), slide_window()\n\n\n\n\nFor detailed documentation of each module, click on the links above. Each page includes:\n\nClass definitions with full method signatures\nUsage examples with runnable code\nParameter descriptions and return values\nRelated concepts and cross-references",
    "crumbs": [
      "API Reference",
      "API Reference"
    ]
  }
]