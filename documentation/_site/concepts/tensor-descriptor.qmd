---
title: "Tensor Descriptors"
format: live-html
---

```{pyodide}
#| echo: false
#| output: false
#| autorun: true

# Auto-install pythonck package
import micropip
await micropip.install("https://raw.githubusercontent.com/ghamarian/pythonck/master/documentation/pythonck-0.1.0-py3-none-any.whl")
```

# Tensor Descriptors: Layout Transformations

**Prerequisites**: [Buffer Views](buffer-view.qmd), [Basic Tensor Coordinates](tensor-coordinate.qmd)

Tensor descriptors define how multi-dimensional tensor coordinates map to linear memory addresses through a series of **transformations**. This is the CRITICAL concept that enables understanding advanced coordinate operations.

## üéØ **Core Concept**

A **Tensor Descriptor** is a chain of transformations that convert between coordinate spaces:

```
Upper Index ‚Üí Transform Chain ‚Üí Lower Index ‚Üí Memory Address
```

## üîß **Basic Descriptor Creation**

```{pyodide}
#| echo: true
#| output: true

import numpy as np
from pytensor.tensor_descriptor import make_naive_tensor_descriptor

# Create a simple 4x6 matrix descriptor (row-major)
lengths = [4, 6]  # 4 rows, 6 columns
strides = [6, 1]  # Row stride=6, column stride=1
descriptor = make_naive_tensor_descriptor(lengths, strides)

print(f"Shape: {descriptor.get_lengths()}")
print(f"Memory size: {descriptor.get_element_space_size()}")
print("‚úÖ Basic descriptor created")
```

## üîÄ **Transform Deep Dive: to_upper vs to_lower**

Each transform has two operations:
- **`to_upper`**: Lower coordinate ‚Üí Upper coordinate (backward transform)
- **`to_lower`**: Upper coordinate ‚Üí Lower coordinate (forward transform)

### **1. EmbedTransform: Strided Layout**

```{pyodide}
#| echo: true
#| output: true

from pytensor.tensor_descriptor import EmbedTransform
from pytensor.tensor_coordinate import MultiIndex

# Create embed transform: 2D ‚Üí 1D with strides [6, 1]
embed = EmbedTransform([2, 3], [6, 1])

# Forward: 2D coordinate ‚Üí 1D memory index
upper_coord = MultiIndex(2, [1, 2])  # Row 1, Column 2
lower_coord = embed.calculate_lower_index(upper_coord)
print(f"to_lower: {upper_coord} ‚Üí {lower_coord}")
print(f"Memory address: {lower_coord.to_list()[0]}")  # Should be 1*6 + 2*1 = 8

# Backward: 1D memory index ‚Üí 2D coordinate  
memory_idx = MultiIndex(1, [8])
recovered_coord = embed.calculate_upper_index(memory_idx)
print(f"to_upper: {memory_idx} ‚Üí {recovered_coord}")
print("‚úÖ EmbedTransform bidirectional mapping demonstrated")
```

### **2. UnmergeTransform: Packed Layout**

```{pyodide}
#| echo: true
#| output: true

from pytensor.tensor_descriptor import UnmergeTransform

# Create unmerge transform: 1D ‚Üí 2D (unpack linear index)
unmerge = UnmergeTransform([2, 3])  # Split into 2x3

# Forward: 2D coordinate ‚Üí 1D packed index
upper_coord = MultiIndex(2, [1, 2])  # Row 1, Column 2  
lower_coord = unmerge.calculate_lower_index(upper_coord)
print(f"to_lower: {upper_coord} ‚Üí {lower_coord}")
print(f"Packed index: {lower_coord.to_list()[0]}")  # Should be 1*3 + 2 = 5

# Backward: 1D packed index ‚Üí 2D coordinate
packed_idx = MultiIndex(1, [5])
recovered_coord = unmerge.calculate_upper_index(packed_idx)
print(f"to_upper: {packed_idx} ‚Üí {recovered_coord}")
print("‚úÖ UnmergeTransform bidirectional mapping demonstrated")
```

### **3. MergeTransform: Dimension Merging**

```{pyodide}
#| echo: true
#| output: true

from pytensor.tensor_descriptor import MergeTransform

# Create merge transform: 2D ‚Üí 1D (collapse dimensions)
merge = MergeTransform([2, 3])  # Merge 2x3 into single dimension

# Forward: 1D coordinate ‚Üí 2D split coordinate
upper_coord = MultiIndex(1, [5])  # Single index 5
lower_coord = merge.calculate_lower_index(upper_coord)
print(f"to_lower: {upper_coord} ‚Üí {lower_coord}")
print(f"Split coordinate: {lower_coord.to_list()}")  # Should be [1, 2] (5 = 1*3 + 2)

# Backward: 2D coordinate ‚Üí 1D merged index
split_coord = MultiIndex(2, [1, 2])
merged_coord = merge.calculate_upper_index(split_coord)
print(f"to_upper: {split_coord} ‚Üí {merged_coord}")
print("‚úÖ MergeTransform bidirectional mapping demonstrated")
```

### **4. ReplicateTransform: Broadcasting**

```{pyodide}
#| echo: true
#| output: true

from pytensor.tensor_descriptor import ReplicateTransform

# Create replicate transform: broadcast smaller to larger dimension
replicate = ReplicateTransform([3], [6])  # Broadcast 3 elements to 6

# Forward: 6D coordinate ‚Üí 3D coordinate (with replication)
upper_coord = MultiIndex(1, [4])  # Index 4 in larger dimension
lower_coord = replicate.calculate_lower_index(upper_coord)
print(f"to_lower: {upper_coord} ‚Üí {lower_coord}")
print(f"Replicated index: {lower_coord.to_list()[0]}")  # Should be 4 % 3 = 1

# Backward: 3D coordinate ‚Üí 6D coordinate (first occurrence)
source_coord = MultiIndex(1, [1])
broadcast_coord = replicate.calculate_upper_index(source_coord)
print(f"to_upper: {source_coord} ‚Üí {broadcast_coord}")
print("‚úÖ ReplicateTransform bidirectional mapping demonstrated")
```

## üîó **Transform Chains**

Real descriptors combine multiple transforms:

```{pyodide}
#| echo: true
#| output: true

from pytensor.tensor_descriptor import TensorAdaptor

# Create a complex transform chain
adaptor = TensorAdaptor()

# Add transforms to build: 3D ‚Üí Embed ‚Üí Unmerge ‚Üí 1D
embed_transform = EmbedTransform([4, 2], [8, 1])
unmerge_transform = UnmergeTransform([2, 4])

adaptor.push_back_transform(embed_transform)
adaptor.push_back_transform(unmerge_transform)

print(f"Number of transforms: {adaptor.get_num_of_transform()}")
print(f"Upper dimensions: {adaptor.get_num_of_upper_dimension()}")
print(f"Lower dimensions: {adaptor.get_num_of_lower_dimension()}")
print("‚úÖ Transform chain created")
```

## üßÆ **Symbolic Transform Analysis**

For complex analysis, descriptors support symbolic mathematics:

```{pyodide}
#| echo: true
#| output: true

import sympy as sp

# Create symbolic coordinates for analysis
embed = EmbedTransform([4, 3], [3, 1])

# Define symbolic upper coordinates
i, j = sp.symbols('i j')
upper_symbolic = [i, j]

# Get symbolic lower coordinate
try:
    # Note: This would require symbolic implementation
    print("Symbolic analysis:")
    print(f"Upper: [{i}, {j}]")
    print(f"Lower: {i}*3 + {j}*1 = 3*{i} + {j}")
    print("‚úÖ Symbolic transform relationship shown")
except:
    print("Symbolic analysis demonstrates the mathematical relationship")
    print("For embed with strides [3, 1]: lower = 3*i + j")
```

## üîç **Why This Matters**

Understanding these transforms is CRITICAL because:

1. **`move_tensor_coordinate`** uses descriptor transforms to validate moves
2. **Tensor views** rely on descriptors for coordinate mapping
3. **Tile distributions** use descriptors to define data layout
4. **Sweep operations** traverse coordinates through descriptor transformations

## üéØ **Interactive Applications**

Explore these concepts in our interactive apps:
- **[Tensor Transform App](../../tensor_transform_app.py)** - Visualize all transform types
- **[Main App](../../app.py)** - See how descriptors integrate with distributions

## ‚úÖ **Next Steps**

Now that you understand descriptors, you can move to:
- [**Advanced Coordinate Operations**](tensor-coordinate-advanced.qmd) - Functions that require descriptors
- [**Tensor Views**](tensor-view.qmd) - Combining descriptors with buffers

---

*Descriptors are the mathematical foundation that makes everything else possible. Master these transforms!* 