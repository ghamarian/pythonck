---
title: "TensorAdaptor: The Transformation Engine"
format: live-html
---

```{pyodide}
#| echo: false
#| output: false
#| autorun: true

# Auto-install pythonck package
import micropip
await micropip.install("https://raw.githubusercontent.com/ghamarian/pythonck/master/documentation/pythonck-0.1.0-py3-none-any.whl")
```

A **TensorAdaptor** is the core engine in PythonCK for managing coordinate transformations between different index spaces. It is responsible for:

- **Chaining multiple transforms** (like Embed, Merge, Unmerge, Replicate, etc.) to map between user-facing (top) coordinates and memory (bottom) coordinates.
- **Tracking the hierarchy of hidden dimensions** that arise from intermediate transformation steps.
- **Providing a unified interface** for forward and backward coordinate mapping, supporting both simple and highly complex tensor layouts.

## What does a TensorAdaptor do?

A TensorAdaptor manages the transformation pipeline from **top coordinates** (user-facing, logical indices) to **bottom coordinates** (memory layout, physical indices).

- **Coordinate transformation**: Provides `calculate_bottom_index()` method to transform from top-level indices to bottom-level (memory) indices.
- **Transform chain management**: Internally manages a sequence of transforms but does not allow adding/removing transforms after creation.
- **Hidden dimension tracking**: Maintains the mapping between transform inputs/outputs through hidden dimension IDs.

### Key Methods

- `calculate_bottom_index(idx_top)`: Transform top coordinates to bottom coordinates
- `get_num_of_transform()`: Get the number of transforms in the chain
- `get_num_of_top_dimension()`: Get number of top (user-facing) dimensions
- `get_num_of_bottom_dimension()`: Get number of bottom (memory) dimensions
- `get_num_of_hidden_dimension()`: Get total number of hidden dimensions

## Example Usage

Here is how you create a TensorAdaptor that merges two dimensions into one (e.g., for a 2D-to-1D mapping):

```{pyodide}
from pytensor.tensor_descriptor import MergeTransform, TensorAdaptor
from pytensor.tensor_coordinate import MultiIndex

# Use contiguous hidden IDs: 0, 1 for input, 2 for output
merge_transform = MergeTransform([2, 3])
adaptor = TensorAdaptor(
    transforms=[merge_transform],
    lower_dimension_hidden_idss=[[0, 1]],  # Two input dimensions
    upper_dimension_hidden_idss=[[2]],     # One output dimension
    bottom_dimension_hidden_ids=[2],       # Bottom is the merged dimension
    top_dimension_hidden_ids=[0, 1]        # Top dimensions are the original 2D
)

print(f"TensorAdaptor created:")
print(f"  Number of transforms: {adaptor.get_num_of_transform()}")
print(f"  Top dimensions: {adaptor.get_num_of_top_dimension()}")
print(f"  Bottom dimensions: {adaptor.get_num_of_bottom_dimension()}")
print(f"  Hidden dimensions: {adaptor.get_num_of_hidden_dimension()}")
print("✅ TensorAdaptor created")
```

Here's a more complex example with an embed transform:

```{pyodide}
from pytensor.tensor_descriptor import EmbedTransform

# Create an embed transform for 2D strided layout
embed_transform = EmbedTransform([4, 3], [3, 1])  # 4x3 with strides [3, 1]

# Use contiguous hidden IDs: 0, 1 for the 2D input, 2 for the linear output
embed_adaptor = TensorAdaptor(
    transforms=[embed_transform],
    lower_dimension_hidden_idss=[[2]],     # One linear output dimension
    upper_dimension_hidden_idss=[[0, 1]],  # Two input dimensions
    bottom_dimension_hidden_ids=[2],       # Bottom is the linear dimension
    top_dimension_hidden_ids=[0, 1]        # Top dimensions are the 2D input
)

print(f"Embed TensorAdaptor created:")
print(f"  Number of transforms: {embed_adaptor.get_num_of_transform()}")
print(f"  Top dimensions: {embed_adaptor.get_num_of_top_dimension()}")
print(f"  Bottom dimensions: {embed_adaptor.get_num_of_bottom_dimension()}")
print("✅ Embed adaptor created")
```

## Coordinate Transformation

Here's how to use a TensorAdaptor to transform coordinates from top to bottom:

```{pyodide}
# Test coordinate transformation with the merge adaptor
test_coord = MultiIndex(2, [1, 2])  # 2D coordinate [1, 2]
bottom_coord = adaptor.calculate_bottom_index(test_coord)

print(f"Coordinate transformation:")
print(f"  Input (top): {test_coord.to_list()}")
print(f"  Output (bottom): {bottom_coord.to_list()}")
print(f"  Calculation: 1 * 3 + 2 = 5 (row-major merge)")
print("✅ Coordinate transformation demonstrated")
```

## TensorAdaptor vs TensorDescriptor

| **TensorAdaptor** | **TensorDescriptor** |
|-------------------|----------------------|
| Manages coordinate transformations | Extends TensorAdaptor with element space info |
| Has `calculate_bottom_index()` | Adds `calculate_offset()`, `get_lengths()` |
| Tracks hidden dimension mappings | Adds element space size and vector guarantees |
| Used as building block | Used for complete tensor layout description |
| No element space concept | Knows total number of elements |

## When to Use TensorAdaptor

- **Building coordinate transformation pipelines**: When you need to chain multiple transforms
- **Custom tensor layouts**: When standard layouts don't meet your needs  
- **As components in larger systems**: TensorDescriptor internally uses TensorAdaptor
- **Research and experimentation**: When exploring new transformation patterns

TensorAdaptor provides the foundation for coordinate transformations, while TensorDescriptor builds upon it to provide complete tensor layout descriptions for practical use.

Next: [TensorDescriptor](tensor-descriptor.qmd) — Learn how TensorDescriptor extends TensorAdaptor with element space information. 