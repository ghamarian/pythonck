---
title: "Buffer View"
format: live-html
---

```{pyodide}
#| echo: false
#| output: false
#| autorun: true

# Auto-install pythonck package
import micropip
await micropip.install("https://raw.githubusercontent.com/ghamarian/pythonck/master/documentation/pythonck-0.1.0-py3-none-any.whl")
```

# Buffer View

Buffer views provide a unified abstraction for accessing memory across different address spaces and with various access patterns. They form the lowest level of the PythonCK memory hierarchy.

## Core Concepts

### Memory Address Spaces

```{pyodide}
#| echo: true
#| output: true

from pytensor.buffer_view import AddressSpace

# Different memory spaces available
print("Available address spaces:")
for space in AddressSpace:
    print(f"  {space.name}: {space.value}")
```

### Memory Operations

```{pyodide}
#| echo: true
#| output: true

from pytensor.buffer_view import MemoryOperation

# Different memory operations supported
print("Available memory operations:")
for op in MemoryOperation:
    print(f"  {op.name}: {op.value}")
```

## Creating Buffer Views

### Basic Buffer View

```{pyodide}
#| echo: true
#| output: true

import numpy as np
from pytensor.buffer_view import make_buffer_view, AddressSpace

# Create sample data
data = np.array([[1, 2, 3, 4],
                 [5, 6, 7, 8],
                 [9, 10, 11, 12]], dtype=np.float32)

print(f"Original data shape: {data.shape}")
print(f"Original data:\n{data}")

# Create a buffer view
buffer = make_buffer_view(
    data=data,
    address_space=AddressSpace.GLOBAL
)

print(f"\nBuffer view created:")
print(f"  Address space: {buffer.address_space}")
print(f"  Data type: {buffer.data.dtype}")
print(f"  Shape: {buffer.data.shape}")
```

### Accessing Buffer Elements

```{pyodide}
#| echo: true
#| output: true

# Access individual elements
print("Element access:")
print(f"  buffer[0, 0] = {buffer.data[0, 0]}")
print(f"  buffer[1, 2] = {buffer.data[1, 2]}")
print(f"  buffer[2, 3] = {buffer.data[2, 3]}")

# Access entire rows
print(f"\nRow access:")
print(f"  Row 0: {buffer.data[0, :]}")
print(f"  Row 1: {buffer.data[1, :]}")
```

## Memory Operations

### SET Operation

```{pyodide}
#| echo: true
#| output: true

from pytensor.buffer_view import MemoryOperation

# Create a buffer for writing
write_data = np.zeros((2, 3), dtype=np.float32)
write_buffer = make_buffer_view(
    data=write_data,
    address_space=AddressSpace.GLOBAL,
    memory_operation=MemoryOperation.SET
)

print(f"Before SET operations:\n{write_buffer.data}")

# Simulate SET operations (direct assignment)
write_buffer.data[0, 0] = 100.0
write_buffer.data[1, 2] = 200.0

print(f"\nAfter SET operations:\n{write_buffer.data}")
```

### ADD Operation

```{pyodide}
#| echo: true
#| output: true

# Create a buffer for accumulation
accum_data = np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32)
accum_buffer = make_buffer_view(
    data=accum_data,
    address_space=AddressSpace.LDS,  # Local Data Share
    memory_operation=MemoryOperation.ADD
)

print(f"Before ADD operations:\n{accum_buffer.data}")

# Simulate ADD operations (accumulation)
accum_buffer.data[0, 0] += 10.0
accum_buffer.data[1, 1] += 20.0

print(f"\nAfter ADD operations:\n{accum_buffer.data}")
```

## Advanced Buffer Operations

### Buffer Views with Strides

```{pyodide}
#| echo: true
#| output: true

# Create a larger array and view it with different strides
large_data = np.arange(24, dtype=np.float32).reshape(4, 6)
print(f"Large data (4x6):\n{large_data}")

# Create a strided view (every other element)
strided_view = large_data[::2, ::2]  # Every 2nd row and column
strided_buffer = make_buffer_view(
    data=strided_view,
    address_space=AddressSpace.GLOBAL
)

print(f"\nStrided view (2x3):\n{strided_buffer.data}")
print(f"Strides: {strided_buffer.data.strides}")
```

### Buffer Reshaping

```{pyodide}
#| echo: true
#| output: true

# Reshape buffer data
original = np.arange(12, dtype=np.float32).reshape(3, 4)
print(f"Original shape {original.shape}:\n{original}")

# Create buffer and reshape
buffer = make_buffer_view(data=original)
reshaped = buffer.data.reshape(2, 6)

print(f"\nReshaped to {reshaped.shape}:\n{reshaped}")

# Note: Both views share the same underlying memory
original[0, 0] = 999
print(f"\nAfter modifying original[0,0]:\n{reshaped}")
```

## Buffer View Patterns

### Read-Only Buffers

```{pyodide}
#| echo: true
#| output: true

# Create read-only buffer for input data
input_data = np.array([1, 4, 9, 16, 25], dtype=np.float32)
readonly_buffer = make_buffer_view(
    data=input_data,
    address_space=AddressSpace.GLOBAL
)

print(f"Read-only buffer: {readonly_buffer.data}")
print(f"Can be used for input to computations")
```

### Write-Only Buffers

```{pyodide}
#| echo: true
#| output: true

# Create write-only buffer for output data
output_data = np.zeros(5, dtype=np.float32)
writeonly_buffer = make_buffer_view(
    data=output_data,
    address_space=AddressSpace.GLOBAL,
    memory_operation=MemoryOperation.SET
)

# Simulate computation writing to buffer
for i in range(len(writeonly_buffer.data)):
    writeonly_buffer.data[i] = (i + 1) ** 2

print(f"Write-only buffer after computation: {writeonly_buffer.data}")
```

## Relationship to Other Concepts

Buffer views are the foundation for:

- **Tensor Views** - Combine buffers with tensor descriptors for structured access
- **Tile Windows** - Provide windowed access to buffer regions
- **Static Distributed Tensors** - Thread-local buffer management
- **Memory Operations** - All tensor operations ultimately access memory through buffer views

## Next Steps

- Learn about [Tensor Coordinates](tensor-coordinate.qmd) for multi-dimensional indexing
- Explore [Tensor Views](tensor-view.qmd) to see how buffers combine with descriptors
- Understand [Static Distributed Tensors](static-distributed-tensor.qmd) for parallel buffer management

Buffer views provide the essential memory abstraction that enables all higher-level tensor operations in PythonCK. 