<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Thread Mapping - Connecting to Hardware – Tile Distribution Documentation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-038ebe7de1ad581fc619d66ba7f7845b.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-9cae0046c5fab5900eed4751693c39dd.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-038ebe7de1ad581fc619d66ba7f7845b.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-185961ed47a39db2ff9d8581d2d02664.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-1f647ac581ac6b74d75948daead8752e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-185961ed47a39db2ff9d8581d2d02664.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({ 
        startOnLoad: true,
        theme: 'default',
        themeVariables: {
            primaryColor: '#f0f7ff',
            primaryTextColor: '#1e293b',
            primaryBorderColor: '#2563eb',
            lineColor: '#6b7280',
            secondaryColor: '#fef3e2',
            tertiaryColor: '#f0fdf4',
            background: '#ffffff',
            mainBkg: '#f0f7ff',
            secondBkg: '#fef3e2',
            tertiaryBkg: '#f0fdf4',
            primaryTextColor: '#1e293b',
            fontSize: '16px'
        }
    });
});
</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">


<link rel="stylesheet" href="../global-font-override.css">
<link rel="stylesheet" href="../diagram-sizing-fixes.css">
</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../concepts/06_thread_mapping.html">Thread Mapping</a></li><li class="breadcrumb-item"><a href="../concepts/06_thread_mapping.html">Thread Mapping - Connecting to Hardware</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Tile Distribution Documentation</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tile Distribution Documentation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/00_introduction_motivation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction and Motivation - Why Tile Distribution Matters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/01_buffer_view.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Buffer Views - Raw Memory Access</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/01_tensor_view.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tensor Views - Multi-Dimensional Structure</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Transformation Engine</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_tensor_coordinates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Coordinates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_transforms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Individual Transforms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_adaptors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tensor Adaptors - Chaining Transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_descriptors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tensor Descriptors - Complete Tensor Specifications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_convolution_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolution Implementation with Tensor Descriptors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_coordinate_movement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Coordinate Operations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Distribution API</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/03_tile_distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tile Distribution - The Core API</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/03_tile_window.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tile Window - Data Access Gateway</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/03_sweep_tile.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sweep Tile - Elegant Iteration</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Coordinate Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/04_coordinate_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coordinate Systems - The Mathematical Foundation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Implementation Deep Dive</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/05_encoding_internals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Encoding Internals - The Internal Machinery</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/05_static_distributed_tensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Static Distributed Tensor - Thread-Local Data Containers</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Thread Mapping</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/06_thread_mapping.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Thread Mapping - Connecting to Hardware</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#interactive-exploration" id="toc-interactive-exploration" class="nav-link active" data-scroll-target="#interactive-exploration">🎮 <strong>Interactive Exploration</strong></a></li>
  <li><a href="#thread-identification-and-partition-indices" id="toc-thread-identification-and-partition-indices" class="nav-link" data-scroll-target="#thread-identification-and-partition-indices">Thread Identification and Partition Indices</a>
  <ul class="collapse">
  <li><a href="#hardware-thread-identification" id="toc-hardware-thread-identification" class="nav-link" data-scroll-target="#hardware-thread-identification">Hardware Thread Identification</a></li>
  <li><a href="#c-thread-mapping-in-ck" id="toc-c-thread-mapping-in-ck" class="nav-link" data-scroll-target="#c-thread-mapping-in-ck">C++ Thread Mapping in CK</a></li>
  <li><a href="#thread-hierarchy-structure" id="toc-thread-hierarchy-structure" class="nav-link" data-scroll-target="#thread-hierarchy-structure">Thread Hierarchy Structure</a></li>
  <li><a href="#thread-id-mapping" id="toc-thread-id-mapping" class="nav-link" data-scroll-target="#thread-id-mapping">Thread ID Mapping</a></li>
  </ul></li>
  <li><a href="#thread-to-data-mapping" id="toc-thread-to-data-mapping" class="nav-link" data-scroll-target="#thread-to-data-mapping">Thread-to-Data Mapping</a>
  <ul class="collapse">
  <li><a href="#data-distribution-pattern" id="toc-data-distribution-pattern" class="nav-link" data-scroll-target="#data-distribution-pattern">Data Distribution Pattern</a></li>
  <li><a href="#thread-work-assignment" id="toc-thread-work-assignment" class="nav-link" data-scroll-target="#thread-work-assignment">Thread Work Assignment</a></li>
  </ul></li>
  <li><a href="#thread-cooperation-patterns" id="toc-thread-cooperation-patterns" class="nav-link" data-scroll-target="#thread-cooperation-patterns">Thread Cooperation Patterns</a>
  <ul class="collapse">
  <li><a href="#warp-level-cooperation" id="toc-warp-level-cooperation" class="nav-link" data-scroll-target="#warp-level-cooperation">Warp-Level Cooperation</a></li>
  <li><a href="#block-level-cooperation" id="toc-block-level-cooperation" class="nav-link" data-scroll-target="#block-level-cooperation">Block-Level Cooperation</a></li>
  <li><a href="#vector-level-processing" id="toc-vector-level-processing" class="nav-link" data-scroll-target="#vector-level-processing">Vector-Level Processing</a></li>
  </ul></li>
  <li><a href="#memory-access-patterns" id="toc-memory-access-patterns" class="nav-link" data-scroll-target="#memory-access-patterns">Memory Access Patterns</a>
  <ul class="collapse">
  <li><a href="#c-implementation-of-memory-access" id="toc-c-implementation-of-memory-access" class="nav-link" data-scroll-target="#c-implementation-of-memory-access">C++ Implementation of Memory Access</a></li>
  <li><a href="#memory-access-optimization-techniques" id="toc-memory-access-optimization-techniques" class="nav-link" data-scroll-target="#memory-access-optimization-techniques">Memory Access Optimization Techniques</a></li>
  <li><a href="#coalesced-memory-access" id="toc-coalesced-memory-access" class="nav-link" data-scroll-target="#coalesced-memory-access">Coalesced Memory Access</a></li>
  <li><a href="#memory-efficiency-benefits" id="toc-memory-efficiency-benefits" class="nav-link" data-scroll-target="#memory-efficiency-benefits">Memory Efficiency Benefits</a></li>
  </ul></li>
  <li><a href="#practical-thread-mapping-example" id="toc-practical-thread-mapping-example" class="nav-link" data-scroll-target="#practical-thread-mapping-example">Practical Thread Mapping Example</a>
  <ul class="collapse">
  <li><a href="#complete-c-kernel-example" id="toc-complete-c-kernel-example" class="nav-link" data-scroll-target="#complete-c-kernel-example">Complete C++ Kernel Example</a></li>
  <li><a href="#key-thread-mapping-concepts-in-action" id="toc-key-thread-mapping-concepts-in-action" class="nav-link" data-scroll-target="#key-thread-mapping-concepts-in-action">Key Thread Mapping Concepts in Action</a></li>
  </ul></li>
  <li><a href="#practical-thread-mapping-example-1" id="toc-practical-thread-mapping-example-1" class="nav-link" data-scroll-target="#practical-thread-mapping-example-1">Practical Thread Mapping Example</a></li>
  <li><a href="#testing-your-understanding" id="toc-testing-your-understanding" class="nav-link" data-scroll-target="#testing-your-understanding">Testing Your Understanding</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../concepts/06_thread_mapping.html">Thread Mapping</a></li><li class="breadcrumb-item"><a href="../concepts/06_thread_mapping.html">Thread Mapping - Connecting to Hardware</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Thread Mapping - Connecting to Hardware</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div>
<div id="pyodide-1" class="exercise-cell">

</div>
<script type="pyodide-1-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOnRydWUsImVjaG8iOmZhbHNlLCJlZGl0IjpmYWxzZSwiZXZhbCI6dHJ1ZSwib3V0cHV0IjpmYWxzZX0sImNvZGUiOiJcbiMgQXV0by1pbnN0YWxsIHB5dGhvbmNrIHBhY2thZ2VcbmltcG9ydCBtaWNyb3BpcFxuYXdhaXQgbWljcm9waXAuaW5zdGFsbChcImh0dHBzOi8vcmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbS9naGFtYXJpYW4vcHl0aG9uY2svbWFzdGVyL2RvY3VtZW50YXRpb24vcHl0aG9uY2stMC4xLjAtcHkzLW5vbmUtYW55LndobFwiKVxuXG4jIFNldHVwIHB5dGVuc29yIHBhdGggZm9yIHB5b2RpZGUgZW52aXJvbm1lbnRcbmltcG9ydCBzeXNcbmltcG9ydCBvc1xuaW1wb3J0IG51bXB5IGFzIG5wXG5cbiMgQWRkIHRoZSBwcm9qZWN0IHJvb3QgdG8gcGF0aCBzbyB3ZSBjYW4gaW1wb3J0IHB5dGVuc29yXG5zeXMucGF0aC5pbnNlcnQoMCwgJy9ob21lL2FnaGFtYXJpL2dpdGh1Yi9jb21wb3NhYmxlX2tlcm5lbC92aXN1YWxpc2F0aW9uJylcblxuIyBJbXBvcnQgdGhlIGFjdHVhbCBDSyBtb2R1bGVzXG5mcm9tIHB5dGVuc29yLnRpbGVfZGlzdHJpYnV0aW9uX2VuY29kaW5nIGltcG9ydCBUaWxlRGlzdHJpYnV0aW9uRW5jb2RpbmdcbmZyb20gcHl0ZW5zb3IudGlsZV9kaXN0cmlidXRpb24gaW1wb3J0IG1ha2Vfc3RhdGljX3RpbGVfZGlzdHJpYnV0aW9uXG5mcm9tIHB5dGVuc29yLnN0YXRpY19kaXN0cmlidXRlZF90ZW5zb3IgaW1wb3J0IG1ha2Vfc3RhdGljX2Rpc3RyaWJ1dGVkX3RlbnNvclxuZnJvbSBweXRlbnNvci50ZW5zb3JfdmlldyBpbXBvcnQgbWFrZV9uYWl2ZV90ZW5zb3Jfdmlld19wYWNrZWRcbmZyb20gcHl0ZW5zb3IudGlsZV93aW5kb3cgaW1wb3J0IG1ha2VfdGlsZV93aW5kb3dcbmZyb20gcHl0ZW5zb3IucGFydGl0aW9uX3NpbXVsYXRpb24gaW1wb3J0IHNldF9nbG9iYWxfdGhyZWFkX3Bvc2l0aW9uIn0=
</script>
</div>
<p>The final piece of the puzzle: how threads get their unique IDs and how that maps to specific data, connecting our mathematical abstractions to physical hardware.</p>
<p>Up to this point, we’ve learned about encodings, transformations, and distributed tensors. But there’s one crucial question remaining: <strong>How do actual GPU threads know which data to process?</strong></p>
<p>This is where thread mapping comes in - the bridge between our mathematical abstractions and the physical hardware that executes our code.</p>
<section id="interactive-exploration" class="level2">
<h2 class="anchored" data-anchor-id="interactive-exploration">🎮 <strong>Interactive Exploration</strong></h2>
<p>Explore thread mapping concepts interactively:</p>
<p><strong><a href="../../thread_visualization_app.py">🧵 Thread Visualization App</a></strong> - Visualize GPU thread coordinate mapping and access patterns. Understand how individual threads access distributed tensor data.</p>
</section>
<section id="thread-identification-and-partition-indices" class="level2">
<h2 class="anchored" data-anchor-id="thread-identification-and-partition-indices">Thread Identification and Partition Indices</h2>
<p>Before threads can process data, they need to know who they are and what work they’re responsible for.</p>
<section id="hardware-thread-identification" class="level3">
<h3 class="anchored" data-anchor-id="hardware-thread-identification">Hardware Thread Identification</h3>
<p>In GPU hardware, threads are organized hierarchically:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">// CUDA/HIP thread identification</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> get_thread_coordinates<span class="op">()</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Grid-level coordinates (which block)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> block_x <span class="op">=</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> block_y <span class="op">=</span> blockIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> block_z <span class="op">=</span> blockIdx<span class="op">.</span>z<span class="op">;</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Block-level coordinates (which thread in block)</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> thread_x <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> thread_y <span class="op">=</span> threadIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> thread_z <span class="op">=</span> threadIdx<span class="op">.</span>z<span class="op">;</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Warp identification</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> warp_id <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">/</span> <span class="dv">32</span><span class="op">;</span>  <span class="co">// 32 threads per warp</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> lane_id <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">%</span> <span class="dv">32</span><span class="op">;</span>  <span class="co">// Position within warp</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Global thread ID calculation</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> global_thread_id <span class="op">=</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="c-thread-mapping-in-ck" class="level3">
<h3 class="anchored" data-anchor-id="c-thread-mapping-in-ck">C++ Thread Mapping in CK</h3>
<p>Composable Kernel abstracts thread identification into partition indices:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From tile_partition.hpp</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> ThreadLayout<span class="op">&gt;</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">struct</span> tile_partition</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    CK_TILE_DEVICE <span class="at">static</span> <span class="kw">constexpr</span> <span class="dt">index_t</span> get_thread_idx<span class="op">()</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    CK_TILE_DEVICE <span class="at">static</span> <span class="kw">constexpr</span> <span class="dt">index_t</span> get_block_idx<span class="op">()</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Convert to multi-dimensional partition index</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">template</span> <span class="op">&lt;</span><span class="dt">index_t</span> NumDim<span class="op">&gt;</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    CK_TILE_DEVICE <span class="at">static</span> <span class="kw">constexpr</span> <span class="kw">auto</span> get_partition_index<span class="op">()</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="kw">constexpr</span> <span class="kw">auto</span> thread_layout <span class="op">=</span> ThreadLayout<span class="op">{};</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Convert linear thread ID to multi-dimensional index</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> thread_layout<span class="op">.</span><span class="kw">template</span> get_index<span class="op">&lt;</span>NumDim<span class="op">&gt;(</span>get_thread_idx<span class="op">());</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="op">};</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="mermaid">
graph TB
    subgraph "GPU Device"
        subgraph "Thread Block"
            subgraph "Warp 0"
                T0["Thread 0<br>lane_id=0"]
                T1["Thread 1<br>lane_id=1"]
                T2["..."]
                T31["Thread 31<br>lane_id=31"]
            end
            
            subgraph "Warp 1"
                T32["Thread 32<br>lane_id=0"]
                T33["Thread 33<br>lane_id=1"]
                T34["..."]
                T63["Thread 63<br>lane_id=31"]
            end
            
            W2["Warp 2"]
            W3["..."]
            W7["Warp 7"]
        end
    end
    
    subgraph "Thread Identification"
        TID["Thread ID = blockIdx.x * blockDim.x + threadIdx.x"]
        WID["Warp ID = threadIdx.x / 32"]
        LID["Lane ID = threadIdx.x % 32"]
    end
    
    subgraph "P-space Mapping"
        P["P-coordinates<br>NDimP=1: [thread_id]<br>NDimP=2: [warp_id, lane_id]"]
    end
    
    T0 --&gt; TID
    TID --&gt; WID
    TID --&gt; LID
    WID --&gt; P
    LID --&gt; P
    
    style T0 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style T32 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style P fill:#fff3e0,stroke:#f57c00,stroke-width:3px
</div>
<div>
<div id="pyodide-2" class="exercise-cell">

</div>
<script type="pyodide-2-contents">
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
</script>
</div>
</section>
<section id="thread-hierarchy-structure" class="level3">
<h3 class="anchored" data-anchor-id="thread-hierarchy-structure">Thread Hierarchy Structure</h3>
<p>The hardware organizes threads in a specific hierarchy:</p>
<p><strong>🔹 Block Level</strong>: Groups of warps working together - <code>{warp_per_block_m}×{warp_per_block_n}</code> warps per block - Shared memory and synchronization scope - Block-level coordination possible</p>
<p><strong>🔹 Warp Level</strong>: Groups of threads executing in lockstep - <code>{thread_per_warp_m}×{thread_per_warp_n}</code> threads per warp - SIMD execution (all threads execute same instruction) - Warp-level primitives (shuffle, vote, etc.)</p>
<p><strong>🔹 Thread Level</strong>: Individual execution units - <code>{vector_m}×{vector_n}</code> elements per thread - Independent register space - Vector operations on multiple elements</p>
</section>
<section id="thread-id-mapping" class="level3">
<h3 class="anchored" data-anchor-id="thread-id-mapping">Thread ID Mapping</h3>
<p>Each thread gets a unique ID that maps to its position in the hierarchy:</p>
<div>
<div id="pyodide-3" class="exercise-cell">

</div>
<script type="pyodide-3-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOmZhbHNlLCJlZGl0Ijp0cnVlLCJldmFsIjp0cnVlfSwiY29kZSI6InByaW50KFwi8J+TiiBFeGFtcGxlIFRocmVhZCBJRCBNYXBwaW5nczpcIilcbnByaW50KFwiPVwiICogNTApXG5cbiMgU2hvdyBleGFtcGxlIHRocmVhZCBtYXBwaW5nc1xudGhyZWFkX2NvdW50ID0gMFxuZm9yIHdhcnBfbSBpbiByYW5nZShtaW4oMiwgd2FycF9wZXJfYmxvY2tfbSkpOlxuICAgIGZvciB3YXJwX24gaW4gcmFuZ2UobWluKDIsIHdhcnBfcGVyX2Jsb2NrX24pKTpcbiAgICAgICAgZm9yIHRocmVhZF9tIGluIHJhbmdlKG1pbigyLCB0aHJlYWRfcGVyX3dhcnBfbSkpOlxuICAgICAgICAgICAgZm9yIHRocmVhZF9uIGluIHJhbmdlKG1pbigyLCB0aHJlYWRfcGVyX3dhcnBfbikpOlxuICAgICAgICAgICAgICAgICMgQ2FsY3VsYXRlIGdsb2JhbCB0aHJlYWQgSURcbiAgICAgICAgICAgICAgICBnbG9iYWxfdGhyZWFkX2lkID0gKHdhcnBfbSAqIHdhcnBfcGVyX2Jsb2NrX24gKiB0aHJlYWRfcGVyX3dhcnBfbSAqIHRocmVhZF9wZXJfd2FycF9uICtcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICB3YXJwX24gKiB0aHJlYWRfcGVyX3dhcnBfbSAqIHRocmVhZF9wZXJfd2FycF9uICtcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICB0aHJlYWRfbSAqIHRocmVhZF9wZXJfd2FycF9uICsgdGhyZWFkX24pXG4gICAgICAgICAgICAgICAgXG4gICAgICAgICAgICAgICAgcHJpbnQoZlwiICBUaHJlYWQge2dsb2JhbF90aHJlYWRfaWR9OiBXYXJwW3t3YXJwX219LHt3YXJwX259XSBUaHJlYWRbe3RocmVhZF9tfSx7dGhyZWFkX259XVwiKVxuICAgICAgICAgICAgICAgIFxuICAgICAgICAgICAgICAgIHRocmVhZF9jb3VudCArPSAxXG4gICAgICAgICAgICAgICAgaWYgdGhyZWFkX2NvdW50ID49IDg6ICAjIFNob3cgZmlyc3QgOCB0aHJlYWRzXG4gICAgICAgICAgICAgICAgICAgIHByaW50KFwiICAuLi4gKHNob3dpbmcgZmlyc3QgOCB0aHJlYWRzKVwiKVxuICAgICAgICAgICAgICAgICAgICBicmVha1xuICAgICAgICAgICAgaWYgdGhyZWFkX2NvdW50ID49IDg6XG4gICAgICAgICAgICAgICAgYnJlYWtcbiAgICAgICAgaWYgdGhyZWFkX2NvdW50ID49IDg6XG4gICAgICAgICAgICBicmVha1xuICAgIGlmIHRocmVhZF9jb3VudCA+PSA4OlxuICAgICAgICBicmVhayJ9
</script>
</div>
</section>
</section>
<section id="thread-to-data-mapping" class="level2">
<h2 class="anchored" data-anchor-id="thread-to-data-mapping">Thread-to-Data Mapping</h2>
<p>Once threads know their IDs, they need to map those IDs to specific data elements.</p>
<div class="mermaid">
graph TB
    subgraph "Thread to Data Mapping"
        subgraph "Thread Grid"
            T00["Thread[0,0]<br>Warp 0"]
            T01["Thread[0,1]<br>Warp 0"]
            T10["Thread[1,0]<br>Warp 1"]
            T11["Thread[1,1]<br>Warp 1"]
        end
        
        subgraph "Data Tiles"
            D00["Data[0:4, 0:4]<br>16 elements"]
            D01["Data[0:4, 4:8]<br>16 elements"]
            D10["Data[4:8, 0:4]<br>16 elements"]
            D11["Data[4:8, 4:8]<br>16 elements"]
        end
        
        subgraph "Memory Access"
            MA["Coalesced Access<br>Adjacent threads → Adjacent memory"]
        end
    end
    
    T00 --&gt; D00
    T01 --&gt; D01
    T10 --&gt; D10
    T11 --&gt; D11
    
    D00 --&gt; MA
    D01 --&gt; MA
    
    style T00 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style D00 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style MA fill:#fff3e0,stroke:#f57c00,stroke-width:2px
</div>
<section id="data-distribution-pattern" class="level3">
<h3 class="anchored" data-anchor-id="data-distribution-pattern">Data Distribution Pattern</h3>
<p>The RMSNorm operation distributes tensor data across threads in a structured pattern:</p>
<div>
<div id="pyodide-4" class="exercise-cell">

</div>
<script type="pyodide-4-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOmZhbHNlLCJlZGl0Ijp0cnVlLCJldmFsIjp0cnVlfSwiY29kZSI6InByaW50KFwi8J+OryBSTVNOb3JtIERhdGEgRGlzdHJpYnV0aW9uIFBhdHRlcm5cIilcbnByaW50KFwiPVwiICogNTApXG5cbiMgQ2FsY3VsYXRlIHRvdGFsIHRlbnNvciBzaXplIHByb2Nlc3NlZCBieSB0aGlzIHRpbGUgZGlzdHJpYnV0aW9uXG50b3RhbF9tID0gcmVwZWF0X20gKiB3YXJwX3Blcl9ibG9ja19tICogdGhyZWFkX3Blcl93YXJwX20gKiB2ZWN0b3JfbVxudG90YWxfbiA9IHJlcGVhdF9uICogd2FycF9wZXJfYmxvY2tfbiAqIHRocmVhZF9wZXJfd2FycF9uICogdmVjdG9yX25cblxucHJpbnQoZlwi8J+TiiBUZW5zb3IgT3JnYW5pemF0aW9uOlwiKVxucHJpbnQoZlwiICBUb3RhbCB0ZW5zb3Igc2l6ZSAoTcOXTik6IHt0b3RhbF9tfcOXe3RvdGFsX259XCIpXG5wcmludChmXCIgIEVsZW1lbnRzIHBlciB0aHJlYWQ6IHt2ZWN0b3JfbX3Dl3t2ZWN0b3Jfbn0gPSB7dmVjdG9yX20gKiB2ZWN0b3Jfbn1cIilcblxucHJpbnQoZlwiXFxu8J+TiyBIaWVyYXJjaGljYWwgRGF0YSBEaXN0cmlidXRpb246XCIpXG5wcmludChmXCIgIPCflLkgQmxvY2sgTGV2ZWw6IHtyZXBlYXRfbX3Dl3tyZXBlYXRfbn0gaXRlcmF0aW9uc1wiKVxucHJpbnQoZlwiICDwn5S5IFdhcnAgTGV2ZWw6IHt3YXJwX3Blcl9ibG9ja19tfcOXe3dhcnBfcGVyX2Jsb2NrX259IHdhcnBzIHBlciBibG9ja1wiKVxucHJpbnQoZlwiICDwn5S5IFRocmVhZCBMZXZlbDoge3RocmVhZF9wZXJfd2FycF9tfcOXe3RocmVhZF9wZXJfd2FycF9ufSB0aHJlYWRzIHBlciB3YXJwXCIpXG5wcmludChmXCIgIPCflLkgVmVjdG9yIExldmVsOiB7dmVjdG9yX219w5d7dmVjdG9yX259IGVsZW1lbnRzIHBlciB0aHJlYWRcIikifQ==
</script>
</div>
</section>
<section id="thread-work-assignment" class="level3">
<h3 class="anchored" data-anchor-id="thread-work-assignment">Thread Work Assignment</h3>
<p>Each thread is assigned a specific rectangular region of the tensor:</p>
<div>
<div id="pyodide-5" class="exercise-cell">

</div>
<script type="pyodide-5-contents">
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
</script>
</div>
</section>
</section>
<section id="thread-cooperation-patterns" class="level2">
<h2 class="anchored" data-anchor-id="thread-cooperation-patterns">Thread Cooperation Patterns</h2>
<p>Threads don’t work in isolation - they cooperate at different levels to achieve optimal performance.</p>
<section id="warp-level-cooperation" class="level3">
<h3 class="anchored" data-anchor-id="warp-level-cooperation">Warp-Level Cooperation</h3>
<p>Threads within a warp execute in lockstep (SIMD):</p>
<p><strong>🤝 Warp-Level Cooperation</strong> - <strong>Warps per block</strong>: <code>{warp_per_block_m}×{warp_per_block_n}</code> - <strong>Threads per warp</strong>: <code>{thread_per_warp_m}×{thread_per_warp_n}</code> - <strong>Cooperation pattern</strong>: Threads within a warp process adjacent data - <strong>Synchronization</strong>: Warp-level SIMD execution</p>
</section>
<section id="block-level-cooperation" class="level3">
<h3 class="anchored" data-anchor-id="block-level-cooperation">Block-Level Cooperation</h3>
<p>Threads within a block can share data and synchronize:</p>
<p><strong>🏗️ Block-Level Cooperation</strong> - <strong>Shared memory</strong>: All threads in block can access shared memory - <strong>Synchronization</strong>: <code>__syncthreads()</code> barriers available - <strong>Data sharing</strong>: Threads can exchange intermediate results - <strong>Collective operations</strong>: Reduction, broadcast across block</p>
</section>
<section id="vector-level-processing" class="level3">
<h3 class="anchored" data-anchor-id="vector-level-processing">Vector-Level Processing</h3>
<p>Each thread processes multiple elements efficiently:</p>
<p><strong>⚡ Vector-Level Processing</strong> - <strong>Elements per thread</strong>: <code>{vector_m}×{vector_n}</code> elements - <strong>Memory coalescing</strong>: Adjacent threads access adjacent memory - <strong>Vectorization</strong>: Hardware can combine multiple operations - <strong>Register efficiency</strong>: Multiple elements in registers</p>
</section>
</section>
<section id="memory-access-patterns" class="level2">
<h2 class="anchored" data-anchor-id="memory-access-patterns">Memory Access Patterns</h2>
<p>The thread mapping directly affects memory access efficiency.</p>
<section id="c-implementation-of-memory-access" class="level3">
<h3 class="anchored" data-anchor-id="c-implementation-of-memory-access">C++ Implementation of Memory Access</h3>
<p>Here’s how CK implements efficient memory access patterns:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Coalesced memory access pattern</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> DataType<span class="op">,</span> <span class="dt">index_t</span> VectorSize<span class="op">&gt;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> coalesced_load<span class="op">(</span><span class="at">const</span> DataType<span class="op">*</span> <span class="ex">__restrict__</span> src<span class="op">,</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                               DataType<span class="op">*</span> <span class="ex">__restrict__</span> dst<span class="op">,</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                               <span class="dt">index_t</span> tid<span class="op">)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread loads VectorSize elements</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Adjacent threads access adjacent memory</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">constexpr</span> <span class="dt">index_t</span> stride <span class="op">=</span> blockDim<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Vectorized load for efficiency</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">using</span> <span class="dt">vector_t</span> <span class="op">=</span> <span class="dt">vector_type_t</span><span class="op">&lt;</span>DataType<span class="op">,</span> VectorSize<span class="op">&gt;;</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Calculate aligned address</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">vector_t</span><span class="op">*</span> src_vec <span class="op">=</span> <span class="kw">reinterpret_cast</span><span class="op">&lt;</span><span class="at">const</span> <span class="dt">vector_t</span><span class="op">*&gt;(</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        src <span class="op">+</span> tid <span class="op">*</span> VectorSize<span class="op">);</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Single vectorized load instruction</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="dt">vector_t</span> data <span class="op">=</span> <span class="op">*</span>src_vec<span class="op">;</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Store to registers</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">reinterpret_cast</span><span class="op">&lt;</span><span class="dt">vector_t</span><span class="op">*&gt;(</span>dst<span class="op">)[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> data<span class="op">;</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co">// CK's distributed tensor load implementation</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> DistributedTensor<span class="op">&gt;</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> load_tile_window<span class="op">(</span>DistributedTensor<span class="op">&amp;</span> dist_tensor<span class="op">,</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>                                <span class="at">const</span> <span class="kw">auto</span><span class="op">&amp;</span> tile_window<span class="op">)</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Get thread's partition index</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">constexpr</span> <span class="kw">auto</span> partition <span class="op">=</span> tile_partition<span class="op">::</span>get_partition_index<span class="op">();</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread loads its assigned data</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    tile_window<span class="op">.</span>load<span class="op">(</span>dist_tensor<span class="op">,</span> partition<span class="op">);</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Hardware automatically coalesces adjacent thread accesses</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="memory-access-optimization-techniques" class="level3">
<h3 class="anchored" data-anchor-id="memory-access-optimization-techniques">Memory Access Optimization Techniques</h3>
<p>CK uses several techniques to optimize memory access:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">// 1. Vector loads for maximum bandwidth</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="dt">index_t</span> N<span class="op">&gt;</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">using</span> <span class="dt">vector_load_t</span> <span class="op">=</span> <span class="dt">conditional_t</span><span class="op">&lt;</span>N <span class="op">==</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">float</span><span class="op">,</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                     <span class="dt">conditional_t</span><span class="op">&lt;</span>N <span class="op">==</span> <span class="dv">2</span><span class="op">,</span> float2<span class="op">,</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>                     <span class="dt">conditional_t</span><span class="op">&lt;</span>N <span class="op">==</span> <span class="dv">4</span><span class="op">,</span> float4<span class="op">,</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>                                           <span class="dt">float</span><span class="op">&gt;&gt;&gt;;</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">// 2. Swizzling to avoid bank conflicts</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="dt">index_t</span> BankSize <span class="op">=</span> <span class="dv">32</span><span class="op">&gt;</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">index_t</span> swizzle_offset<span class="op">(</span><span class="dt">index_t</span> tid<span class="op">,</span> <span class="dt">index_t</span> offset<span class="op">)</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Rotate access pattern to avoid conflicts</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">(</span>offset <span class="op">+</span> <span class="op">(</span>tid <span class="op">/</span> BankSize<span class="op">))</span> <span class="op">%</span> BankSize<span class="op">;</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">// 3. Prefetching for latency hiding</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> prefetch_next_tile<span class="op">(</span><span class="at">const</span> <span class="dt">float</span><span class="op">*</span> src<span class="op">,</span> <span class="dt">index_t</span> offset<span class="op">)</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Prefetch to L2 cache</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__builtin_prefetch</span><span class="op">(</span>src <span class="op">+</span> offset<span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="dv">3</span><span class="op">);</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="coalesced-memory-access" class="level3">
<h3 class="anchored" data-anchor-id="coalesced-memory-access">Coalesced Memory Access</h3>
<div>
<div id="pyodide-6" class="exercise-cell">

</div>
<script type="pyodide-6-contents">
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
</script>
</div>
</section>
<section id="memory-efficiency-benefits" class="level3">
<h3 class="anchored" data-anchor-id="memory-efficiency-benefits">Memory Efficiency Benefits</h3>
<p>The structured thread mapping provides several memory efficiency benefits:</p>
<p><strong>🎯 Memory Coalescing Benefits:</strong> - <strong>Adjacent access</strong>: Threads in same warp access adjacent memory locations - <strong>Cache efficiency</strong>: Related data loaded together into cache lines - <strong>Bandwidth utilization</strong>: Maximum memory bandwidth achieved - <strong>Reduced latency</strong>: Fewer memory transactions needed</p>
<p><strong>⚡ Performance Characteristics:</strong> - <strong>Predictable patterns</strong>: Access patterns known at compile time - <strong>Vectorization</strong>: Hardware can optimize vector operations - <strong>Reduced overhead</strong>: No complex address calculations at runtime - <strong>Scalability</strong>: Pattern scales efficiently with thread count</p>
</section>
</section>
<section id="practical-thread-mapping-example" class="level2">
<h2 class="anchored" data-anchor-id="practical-thread-mapping-example">Practical Thread Mapping Example</h2>
<section id="complete-c-kernel-example" class="level3">
<h3 class="anchored" data-anchor-id="complete-c-kernel-example">Complete C++ Kernel Example</h3>
<p>Here’s a complete example showing how thread mapping works in a real CK kernel:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">// RMSNorm kernel using CK's thread mapping</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> DataType<span class="op">,</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>          <span class="kw">typename</span> ComputeType<span class="op">,</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>          <span class="dt">index_t</span> BlockSize<span class="op">,</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>          <span class="dt">index_t</span> VectorSize<span class="op">&gt;</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> rmsnorm_kernel<span class="op">(</span><span class="at">const</span> DataType<span class="op">*</span> <span class="ex">__restrict__</span> x<span class="op">,</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                              DataType<span class="op">*</span> <span class="ex">__restrict__</span> y<span class="op">,</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>                              <span class="at">const</span> DataType<span class="op">*</span> <span class="ex">__restrict__</span> weight<span class="op">,</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>                              ComputeType epsilon<span class="op">,</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                              <span class="dt">index_t</span> hidden_size<span class="op">)</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 1. Thread identification</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">index_t</span> tid <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">index_t</span> bid <span class="op">=</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 2. Create tile distribution encoding</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">// This would be defined based on your specific RMSNorm pattern</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">using</span> Encoding <span class="op">=</span> tile_distribution_encoding<span class="op">&lt;</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        sequence<span class="op">&lt;&gt;,</span>                          <span class="co">// No replication</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        tuple<span class="op">&lt;</span>sequence<span class="op">&lt;</span><span class="dv">4</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;,</span> sequence<span class="op">&lt;</span><span class="dv">4</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;&gt;,</span> <span class="co">// H dimensions</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        tuple<span class="op">&lt;</span>sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;,</span> sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;&gt;,</span>     <span class="co">// P to RH major</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        tuple<span class="op">&lt;</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;,</span> sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;&gt;,</span>     <span class="co">// P to RH minor</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;,</span>                      <span class="co">// Y to RH major</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">0</span><span class="op">&gt;</span>                       <span class="co">// Y to RH minor</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="op">&gt;;</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">constexpr</span> <span class="kw">auto</span> tile_dist <span class="op">=</span> make_static_tile_distribution<span class="op">(</span>Encoding<span class="op">{});</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 3. Get thread's partition index from distribution</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="kw">auto</span> partition_idx <span class="op">=</span> tile_dist<span class="op">.</span>_get_partition_index<span class="op">();</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 4. Shared memory for reduction</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    __shared__ ComputeType shared_sum<span class="op">[</span>BlockSize<span class="op">];</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 5. Create tensor view and tile window</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> x_view <span class="op">=</span> make_naive_tensor_view<span class="op">&lt;</span>address_space_enum<span class="op">::</span>global<span class="op">&gt;(</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        x <span class="op">+</span> bid <span class="op">*</span> hidden_size<span class="op">,</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>hidden_size<span class="op">),</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>number<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    <span class="op">);</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> x_window <span class="op">=</span> make_tile_window<span class="op">(</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        x_view<span class="op">,</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>hidden_size<span class="op">),</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>number<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{}),</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        tile_dist<span class="op">);</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 6. Each thread processes its assigned elements</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    ComputeType thread_sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    static_for<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> VectorSize<span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}([&amp;](</span><span class="kw">auto</span> i<span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Access pattern would depend on your tile window setup</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="co">// This is conceptual - actual implementation varies</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        thread_sum <span class="op">+=</span> val <span class="op">*</span> val<span class="op">;</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    <span class="op">});</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 7. Warp-level reduction</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    thread_sum <span class="op">=</span> warp_reduce_sum<span class="op">&lt;</span>WarpSize<span class="op">&gt;(</span>thread_sum<span class="op">);</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 8. Block-level reduction</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>tid <span class="op">%</span> WarpSize <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        shared_sum<span class="op">[</span>tid <span class="op">/</span> WarpSize<span class="op">]</span> <span class="op">=</span> thread_sum<span class="op">;</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>    __syncthreads<span class="op">();</span></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 9. Final reduction by first warp</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>tid <span class="op">&lt;</span> BlockSize <span class="op">/</span> WarpSize<span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>        thread_sum <span class="op">=</span> shared_sum<span class="op">[</span>tid<span class="op">];</span></span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>        thread_sum <span class="op">=</span> warp_reduce_sum<span class="op">&lt;</span>BlockSize <span class="op">/</span> WarpSize<span class="op">&gt;(</span>thread_sum<span class="op">);</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 10. Compute RMS and normalize</span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>tid <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>        shared_sum<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> rsqrt<span class="op">(</span>thread_sum <span class="op">/</span> hidden_size <span class="op">+</span> epsilon<span class="op">);</span></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>    __syncthreads<span class="op">();</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> ComputeType rms_recip <span class="op">=</span> shared_sum<span class="op">[</span><span class="dv">0</span><span class="op">];</span></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 11. Write normalized output</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> y_window <span class="op">=</span> make_tile_window<span class="op">(</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>        make_tensor_view<span class="op">&lt;</span>address_space_enum<span class="op">::</span>global<span class="op">&gt;(</span>y <span class="op">+</span> bid <span class="op">*</span> hidden_size<span class="op">),</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        tile_dist<span class="op">);</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>    static_for<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> VectorSize<span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}([&amp;](</span><span class="kw">auto</span> i<span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>        <span class="kw">auto</span> idx <span class="op">=</span> tile_dist<span class="op">.</span>get_tensor_coordinate<span class="op">(</span>partition_idx<span class="op">,</span> i<span class="op">);</span></span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        ComputeType val <span class="op">=</span> <span class="kw">static_cast</span><span class="op">&lt;</span>ComputeType<span class="op">&gt;(</span>x_window<span class="op">.</span>get<span class="op">(</span>idx<span class="op">));</span></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        ComputeType w <span class="op">=</span> <span class="kw">static_cast</span><span class="op">&lt;</span>ComputeType<span class="op">&gt;(</span>weight<span class="op">[</span>idx<span class="op">[</span><span class="dv">1</span><span class="op">]]);</span></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>        y_window<span class="op">.</span>set<span class="op">(</span>idx<span class="op">,</span> <span class="kw">static_cast</span><span class="op">&lt;</span>DataType<span class="op">&gt;(</span>val <span class="op">*</span> rms_recip <span class="op">*</span> w<span class="op">));</span></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>    <span class="op">});</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="key-thread-mapping-concepts-in-action" class="level3">
<h3 class="anchored" data-anchor-id="key-thread-mapping-concepts-in-action">Key Thread Mapping Concepts in Action</h3>
<ol type="1">
<li><strong>Thread-to-Data Assignment</strong>: Each thread gets a unique <code>partition_idx</code></li>
<li><strong>Vectorized Access</strong>: Each thread processes <code>VectorSize</code> elements</li>
<li><strong>Warp Cooperation</strong>: Threads within a warp perform reductions</li>
<li><strong>Block Synchronization</strong>: All threads synchronize for final result</li>
<li><strong>Coalesced Memory</strong>: Adjacent threads access adjacent memory</li>
</ol>
</section>
</section>
<section id="practical-thread-mapping-example-1" class="level2">
<h2 class="anchored" data-anchor-id="practical-thread-mapping-example-1">Practical Thread Mapping Example</h2>
<p>Let’s see how thread mapping works in practice with a complete example:</p>
<div>
<div id="pyodide-7" class="exercise-cell">

</div>
<script type="pyodide-7-contents">
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
</script>
</div>
</section>
<section id="testing-your-understanding" class="level2">
<h2 class="anchored" data-anchor-id="testing-your-understanding">Testing Your Understanding</h2>
<p>Let’s verify your understanding of thread mapping concepts:</p>
<div>
<div id="pyodide-8" class="exercise-cell">

</div>
<script type="pyodide-8-contents">
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
</script>
</div>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<p>Thread mapping is the crucial bridge between mathematical abstractions and physical hardware execution:</p>
<p><strong>🎯 Thread Identification:</strong></p>
<ol type="1">
<li><strong>Hierarchical Organization</strong>: Threads organized in blocks → warps → threads → vectors
<ul>
<li>✅ Each level has specific cooperation capabilities</li>
<li>✅ Hardware provides efficient primitives at each level</li>
<li>✅ Thread IDs map directly to data regions</li>
<li>✅ Predictable and efficient execution patterns</li>
</ul></li>
<li><strong>Data Assignment</strong>: Each thread gets a specific rectangular region
<ul>
<li>✅ Work distributed evenly across threads</li>
<li>✅ Memory access patterns optimized for coalescing</li>
<li>✅ Vector operations maximize throughput</li>
<li>✅ Scalable across different hardware configurations</li>
</ul></li>
<li><strong>Cooperation Patterns</strong>: Threads cooperate at multiple levels
<ul>
<li>✅ Warp-level SIMD execution for efficiency</li>
<li>✅ Block-level shared memory and synchronization</li>
<li>✅ Vector-level processing for maximum throughput</li>
<li>✅ Hierarchical coordination for complex operations</li>
</ul></li>
</ol>
<p><strong>🚀 Performance Benefits:</strong></p>
<ul>
<li><strong>Memory Coalescing</strong>: Adjacent threads access adjacent memory for optimal bandwidth</li>
<li><strong>Cache Efficiency</strong>: Related data loaded together, reducing memory latency</li>
<li><strong>Vectorization</strong>: Hardware can optimize multiple operations per thread</li>
<li><strong>Predictable Patterns</strong>: Compile-time optimization of access patterns</li>
</ul>
<p><strong>💡 Why This Matters:</strong></p>
<p>Thread mapping connects all the previous concepts (encodings, transformations, distributions) to actual hardware execution. It’s the final piece that makes tile distribution practical for real-world GPU programming.</p>
<p>The RMSNorm example shows how a real operation uses these concepts to achieve optimal performance on modern GPU hardware. Every thread knows exactly what data to process, how to access it efficiently, and how to cooperate with other threads - all determined by the mathematical encoding we started with!</p>
<p>This completes the journey from basic memory concepts to hardware-optimized execution. You now understand the complete tile distribution system from mathematical foundations to practical implementation.</p>


<!-- -->

<script type="pyodide-data">
eyJvcHRpb25zIjp7ImVudiI6eyJQTE9UTFlfUkVOREVSRVIiOiJwbG90bHlfbWltZXR5cGUifSwiaW5kZXhVUkwiOiJodHRwczovL2Nkbi5qc2RlbGl2ci5uZXQvcHlvZGlkZS92MC4yNy4wL2Z1bGwvIn0sInBhY2thZ2VzIjp7InBrZ3MiOlsicHlvZGlkZV9odHRwIiwibWljcm9waXAiLCJpcHl0aG9uIiwibnVtcHkiLCJwYW5kYXMiLCJzeW1weSIsIm1pY3JvcGlwIl19fQ==
</script>
<script type="ojs-module-contents">
{"contents":[{"cellName":"pyodide-8","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_8 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-8-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-8-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_8 = pyodideOjs.process(_pyodide_editor_8, {});\n"},{"cellName":"pyodide-7","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_7 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-7-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-7-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_7 = pyodideOjs.process(_pyodide_editor_7, {});\n"},{"cellName":"pyodide-6","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_6 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-6-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-6-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_6 = pyodideOjs.process(_pyodide_editor_6, {});\n"},{"cellName":"pyodide-5","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_5 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-5-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-5-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_5 = pyodideOjs.process(_pyodide_editor_5, {});\n"},{"cellName":"pyodide-4","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_4 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-4-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-4-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_4 = pyodideOjs.process(_pyodide_editor_4, {});\n"},{"cellName":"pyodide-3","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_3 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-3-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-3-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_3 = pyodideOjs.process(_pyodide_editor_3, {});\n"},{"cellName":"pyodide-2","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_2 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-2-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-2-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_2 = pyodideOjs.process(_pyodide_editor_2, {});\n"},{"cellName":"pyodide-1","inline":false,"methodName":"interpret","source":"_pyodide_value_1 = {\n  const { highlightPython, b64Decode} = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-1-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  // Default evaluation configuration\n  const options = Object.assign({\n    id: \"pyodide-1-contents\",\n    echo: true,\n    output: true\n  }, block.attr);\n\n  // Evaluate the provided Python code\n  const result = pyodideOjs.process({code: block.code, options}, {});\n\n  // Early yield while we wait for the first evaluation and render\n  if (options.output && !(\"1\" in pyodideOjs.renderedOjs)) {\n    const container = document.createElement(\"div\");\n    const spinner = document.createElement(\"div\");\n\n    if (options.echo) {\n      // Show output as highlighted source\n      const preElem = document.createElement(\"pre\");\n      container.className = \"sourceCode\";\n      preElem.className = \"sourceCode python\";\n      preElem.appendChild(highlightPython(block.code));\n      spinner.className = \"spinner-grow spinner-grow-sm m-2 position-absolute top-0 end-0\";\n      preElem.appendChild(spinner);\n      container.appendChild(preElem);\n    } else {\n      spinner.className = \"spinner-border spinner-border-sm\";\n      container.appendChild(spinner);\n    }\n\n    yield container;\n  }\n\n  pyodideOjs.renderedOjs[\"1\"] = true;\n  yield await result;\n}\n"},{"cellName":"pyodide-prelude","inline":false,"methodName":"interpretQuiet","source":"pyodideOjs = {\n  const {\n    PyodideEvaluator,\n    PyodideEnvironmentManager,\n    setupPython,\n    startPyodideWorker,\n    b64Decode,\n    collapsePath,\n  } = window._exercise_ojs_runtime;\n\n  const statusContainer = document.getElementById(\"exercise-loading-status\");\n  const indicatorContainer = document.getElementById(\"exercise-loading-indicator\");\n  indicatorContainer.classList.remove(\"d-none\");\n\n  let statusText = document.createElement(\"div\")\n  statusText.classList = \"exercise-loading-details\";\n  statusText = statusContainer.appendChild(statusText);\n  statusText.textContent = `Initialise`;\n\n  // Hoist indicator out from final slide when running under reveal\n  const revealStatus = document.querySelector(\".reveal .exercise-loading-indicator\");\n  if (revealStatus) {\n    revealStatus.remove();\n    document.querySelector(\".reveal > .slides\").appendChild(revealStatus);\n  }\n\n  // Make any reveal slides with live cells scrollable\n  document.querySelectorAll(\".reveal .exercise-cell\").forEach((el) => {\n    el.closest('section.slide').classList.add(\"scrollable\");\n  })\n\n  // Pyodide supplemental data and options\n  const dataContent = document.querySelector(`script[type=\\\"pyodide-data\\\"]`).textContent;\n  const data = JSON.parse(b64Decode(dataContent));\n\n  // Grab list of resources to be downloaded\n  const filesContent = document.querySelector(`script[type=\\\"vfs-file\\\"]`).textContent;\n  const files = JSON.parse(b64Decode(filesContent));\n\n  let pyodidePromise = (async () => {\n    statusText.textContent = `Downloading Pyodide`;\n    const pyodide = await startPyodideWorker(data.options);\n\n    statusText.textContent = `Downloading package: micropip`;\n    await pyodide.loadPackage(\"micropip\");\n    const micropip = await pyodide.pyimport(\"micropip\");\n    await data.packages.pkgs.map((pkg) => () => {\n      statusText.textContent = `Downloading package: ${pkg}`;\n      return micropip.install(pkg);\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n    await micropip.destroy();\n\n    // Download and install resources\n    await files.map((file) => async () => {\n      const name = file.substring(file.lastIndexOf('/') + 1);\n      statusText.textContent = `Downloading resource: ${name}`;\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`Can't download \\`${file}\\`. Error ${response.status}: \"${response.statusText}\".`);\n      }\n      const data = await response.arrayBuffer();\n\n      // Store URLs in the cwd without any subdirectory structure\n      if (file.includes(\"://\")) {\n        file = name;\n      }\n\n      // Collapse higher directory structure\n      file = collapsePath(file);\n\n      // Create directory tree, ignoring \"directory exists\" VFS errors\n      const parts = file.split('/').slice(0, -1);\n      let path = '';\n      while (parts.length > 0) {\n        path += parts.shift() + '/';\n        try {\n          await pyodide.FS.mkdir(path);\n        } catch (e) {\n          if (e.name !== \"ErrnoError\") throw e;\n          if (e.errno !== 20) {\n            const errorTextPtr = await pyodide._module._strerror(e.errno);\n            const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n            throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n          }\n        }\n      }\n\n      // Write this file to the VFS\n      try {\n        return await pyodide.FS.writeFile(file, new Uint8Array(data));\n      } catch (e) {\n        if (e.name !== \"ErrnoError\") throw e;\n        const errorTextPtr = await pyodide._module._strerror(e.errno);\n        const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n        throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n      }\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n\n    statusText.textContent = `Pyodide environment setup`;\n    await setupPython(pyodide);\n\n    statusText.remove();\n    if (statusContainer.children.length == 0) {\n      statusContainer.parentNode.remove();\n    }\n    return pyodide;\n  })().catch((err) => {\n    statusText.style.color = \"var(--exercise-editor-hl-er, #AD0000)\";\n    statusText.textContent = err.message;\n    //indicatorContainer.querySelector(\".spinner-grow\").classList.add(\"d-none\");\n    throw err;\n  });\n\n  // Keep track of initial OJS block render\n  const renderedOjs = {};\n\n  const process = async (context, inputs) => {\n    const pyodide = await pyodidePromise;\n    const evaluator = new PyodideEvaluator(pyodide, context);\n    await evaluator.process(inputs);\n    return evaluator.container;\n  }\n\n  return {\n    pyodidePromise,\n    renderedOjs,\n    process,\n  };\n}\n"}]}
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../concepts";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Thread Mapping - Connecting to Hardware"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">  live-html:</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">    mermaid:</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">      theme: default</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">#| autorun: true</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Auto-install pythonck package</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> micropip</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="cf">await</span> micropip.install(<span class="st">"https://raw.githubusercontent.com/ghamarian/pythonck/master/documentation/pythonck-0.1.0-py3-none-any.whl"</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup pytensor path for pyodide environment</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the project root to path so we can import pytensor</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>sys.path.insert(<span class="dv">0</span>, <span class="st">'/home/aghamari/github/composable_kernel/visualisation'</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Import the actual CK modules</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tile_distribution_encoding <span class="im">import</span> TileDistributionEncoding</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tile_distribution <span class="im">import</span> make_static_tile_distribution</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.static_distributed_tensor <span class="im">import</span> make_static_distributed_tensor</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tensor_view <span class="im">import</span> make_naive_tensor_view_packed</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tile_window <span class="im">import</span> make_tile_window</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.partition_simulation <span class="im">import</span> set_global_thread_position</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>The final piece of the puzzle: how threads get their unique IDs and how that maps to specific data, connecting our mathematical abstractions to physical hardware.</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>Up to this point, we've learned about encodings, transformations, and distributed tensors. But there's one crucial question remaining: **How do actual GPU threads know which data to process?**</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>This is where thread mapping comes in - the bridge between our mathematical abstractions and the physical hardware that executes our code.</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## 🎮 **Interactive Exploration**</span></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>Explore thread mapping concepts interactively:</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>**[🧵 Thread Visualization App](../../thread_visualization_app.py)** - Visualize GPU thread coordinate mapping and access patterns. Understand how individual threads access distributed tensor data.</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a><span class="fu">## Thread Identification and Partition Indices</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>Before threads can process data, they need to know who they are and what work they're responsible for.</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hardware Thread Identification</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>In GPU hardware, threads are organized hierarchically:</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="co">// CUDA/HIP thread identification</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> get_thread_coordinates<span class="op">()</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Grid-level coordinates (which block)</span></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> block_x <span class="op">=</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> block_y <span class="op">=</span> blockIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> block_z <span class="op">=</span> blockIdx<span class="op">.</span>z<span class="op">;</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Block-level coordinates (which thread in block)</span></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> thread_x <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> thread_y <span class="op">=</span> threadIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> thread_z <span class="op">=</span> threadIdx<span class="op">.</span>z<span class="op">;</span></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Warp identification</span></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> warp_id <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">/</span> <span class="dv">32</span><span class="op">;</span>  <span class="co">// 32 threads per warp</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> lane_id <span class="op">=</span> threadIdx<span class="op">.</span>x <span class="op">%</span> <span class="dv">32</span><span class="op">;</span>  <span class="co">// Position within warp</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Global thread ID calculation</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> global_thread_id <span class="op">=</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a><span class="fu">### C++ Thread Mapping in CK</span></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>Composable Kernel abstracts thread identification into partition indices:</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a><span class="co">// From tile_partition.hpp</span></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> ThreadLayout<span class="op">&gt;</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a><span class="kw">struct</span> tile_partition</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>    CK_TILE_DEVICE <span class="at">static</span> <span class="kw">constexpr</span> <span class="dt">index_t</span> get_thread_idx<span class="op">()</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>    CK_TILE_DEVICE <span class="at">static</span> <span class="kw">constexpr</span> <span class="dt">index_t</span> get_block_idx<span class="op">()</span></span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Convert to multi-dimensional partition index</span></span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>    <span class="kw">template</span> <span class="op">&lt;</span><span class="dt">index_t</span> NumDim<span class="op">&gt;</span></span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>    CK_TILE_DEVICE <span class="at">static</span> <span class="kw">constexpr</span> <span class="kw">auto</span> get_partition_index<span class="op">()</span></span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>    <span class="op">{</span></span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>        <span class="kw">constexpr</span> <span class="kw">auto</span> thread_layout <span class="op">=</span> ThreadLayout<span class="op">{};</span></span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Convert linear thread ID to multi-dimensional index</span></span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> thread_layout<span class="op">.</span><span class="kw">template</span> get_index<span class="op">&lt;</span>NumDim<span class="op">&gt;(</span>get_thread_idx<span class="op">());</span></span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a><span class="op">};</span></span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;div class="mermaid"&gt;</span></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="in">graph TB</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a><span class="in">    subgraph "GPU Device"</span></span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Thread Block"</span></span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a><span class="in">            subgraph "Warp 0"</span></span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a><span class="in">                T0["Thread 0&lt;br/&gt;lane_id=0"]</span></span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a><span class="in">                T1["Thread 1&lt;br/&gt;lane_id=1"]</span></span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a><span class="in">                T2["..."]</span></span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a><span class="in">                T31["Thread 31&lt;br/&gt;lane_id=31"]</span></span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a><span class="in">            end</span></span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a><span class="in">            subgraph "Warp 1"</span></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a><span class="in">                T32["Thread 32&lt;br/&gt;lane_id=0"]</span></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a><span class="in">                T33["Thread 33&lt;br/&gt;lane_id=1"]</span></span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a><span class="in">                T34["..."]</span></span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a><span class="in">                T63["Thread 63&lt;br/&gt;lane_id=31"]</span></span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a><span class="in">            end</span></span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a><span class="in">            </span></span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a><span class="in">            W2["Warp 2"]</span></span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a><span class="in">            W3["..."]</span></span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a><span class="in">            W7["Warp 7"]</span></span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a><span class="in">    end</span></span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a><span class="in">    subgraph "Thread Identification"</span></span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a><span class="in">        TID["Thread ID = blockIdx.x * blockDim.x + threadIdx.x"]</span></span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a><span class="in">        WID["Warp ID = threadIdx.x / 32"]</span></span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a><span class="in">        LID["Lane ID = threadIdx.x % 32"]</span></span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a><span class="in">    end</span></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a><span class="in">    subgraph "P-space Mapping"</span></span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a><span class="in">        P["P-coordinates&lt;br/&gt;NDimP=1: [thread_id]&lt;br/&gt;NDimP=2: [warp_id, lane_id]"]</span></span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a><span class="in">    end</span></span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a><span class="in">    T0 --&gt; TID</span></span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a><span class="in">    TID --&gt; WID</span></span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a><span class="in">    TID --&gt; LID</span></span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a><span class="in">    WID --&gt; P</span></span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a><span class="in">    LID --&gt; P</span></span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a><span class="in">    style T0 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px</span></span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a><span class="in">    style T32 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px</span></span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a><span class="in">    style P fill:#fff3e0,stroke:#f57c00,stroke-width:3px</span></span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/div&gt;</span></span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🎯 GPU Thread Hierarchy"</span>)</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSNorm example - real-world layer normalization parameters</span></span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a>repeat_m, warp_per_block_m, thread_per_warp_m, vector_m <span class="op">=</span> <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span></span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a>repeat_n, warp_per_block_n, thread_per_warp_n, vector_n <span class="op">=</span> <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span></span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a><span class="co"># Create RMSNorm tile distribution encoding</span></span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a>encoding <span class="op">=</span> TileDistributionEncoding(</span>
<span id="cb6-170"><a href="#cb6-170" aria-hidden="true" tabindex="-1"></a>    rs_lengths<span class="op">=</span>[],                                           <span class="co"># No replication</span></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a>    hs_lengthss<span class="op">=</span>[[repeat_m, warp_per_block_m, thread_per_warp_m, vector_m],  <span class="co"># M dimension hierarchy</span></span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a>                 [repeat_n, warp_per_block_n, thread_per_warp_n, vector_n]], <span class="co"># N dimension hierarchy</span></span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a>    ps_to_rhss_major<span class="op">=</span>[[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">2</span>]],                     <span class="co"># P→RH major mapping</span></span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a>    ps_to_rhss_minor<span class="op">=</span>[[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>]],                     <span class="co"># P→RH minor mapping</span></span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a>    ys_to_rhs_major<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>],                          <span class="co"># Y→RH major mapping</span></span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a>    ys_to_rhs_minor<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">3</span>]                           <span class="co"># Y→RH minor mapping</span></span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"📋 RMSNorm Configuration (Real-World Example):"</span>)</span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Repeat (M, N): (</span><span class="sc">{</span>repeat_m<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>repeat_n<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Warps per block (M, N): (</span><span class="sc">{</span>warp_per_block_m<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>warp_per_block_n<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Threads per warp (M, N): (</span><span class="sc">{</span>thread_per_warp_m<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>thread_per_warp_n<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Vector size (M, N): (</span><span class="sc">{</span>vector_m<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>vector_n<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate thread organization</span></span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a>threads_per_block <span class="op">=</span> warp_per_block_m <span class="op">*</span> warp_per_block_n <span class="op">*</span> thread_per_warp_m <span class="op">*</span> thread_per_warp_n</span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a>warps_per_block <span class="op">=</span> warp_per_block_m <span class="op">*</span> warp_per_block_n</span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">📊 Thread Organization:"</span>)</span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Threads per block: </span><span class="sc">{</span>threads_per_block<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Warps per block: </span><span class="sc">{</span>warps_per_block<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  P dimensions: </span><span class="sc">{</span>encoding<span class="sc">.</span>ndim_p<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Y dimensions: </span><span class="sc">{</span>encoding<span class="sc">.</span>ndim_y<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a><span class="fu">### Thread Hierarchy Structure</span></span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a>The hardware organizes threads in a specific hierarchy:</span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a>**🔹 Block Level**: Groups of warps working together</span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`{warp_per_block_m}×{warp_per_block_n}`</span> warps per block</span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Shared memory and synchronization scope</span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Block-level coordination possible</span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a>**🔹 Warp Level**: Groups of threads executing in lockstep</span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`{thread_per_warp_m}×{thread_per_warp_n}`</span> threads per warp</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>SIMD execution (all threads execute same instruction)</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Warp-level primitives (shuffle, vote, etc.)</span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a>**🔹 Thread Level**: Individual execution units</span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`{vector_m}×{vector_n}`</span> elements per thread</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Independent register space</span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Vector operations on multiple elements</span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a><span class="fu">### Thread ID Mapping</span></span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a>Each thread gets a unique ID that maps to its position in the hierarchy:</span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"📊 Example Thread ID Mappings:"</span>)</span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a><span class="co"># Show example thread mappings</span></span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a>thread_count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> warp_m <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, warp_per_block_m)):</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> warp_n <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, warp_per_block_n)):</span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> thread_m <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, thread_per_warp_m)):</span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> thread_n <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, thread_per_warp_n)):</span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate global thread ID</span></span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a>                global_thread_id <span class="op">=</span> (warp_m <span class="op">*</span> warp_per_block_n <span class="op">*</span> thread_per_warp_m <span class="op">*</span> thread_per_warp_n <span class="op">+</span></span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a>                                  warp_n <span class="op">*</span> thread_per_warp_m <span class="op">*</span> thread_per_warp_n <span class="op">+</span></span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a>                                  thread_m <span class="op">*</span> thread_per_warp_n <span class="op">+</span> thread_n)</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"  Thread </span><span class="sc">{</span>global_thread_id<span class="sc">}</span><span class="ss">: Warp[</span><span class="sc">{</span>warp_m<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>warp_n<span class="sc">}</span><span class="ss">] Thread[</span><span class="sc">{</span>thread_m<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>thread_n<span class="sc">}</span><span class="ss">]"</span>)</span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>                thread_count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> thread_count <span class="op">&gt;=</span> <span class="dv">8</span>:  <span class="co"># Show first 8 threads</span></span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"  ... (showing first 8 threads)"</span>)</span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> thread_count <span class="op">&gt;=</span> <span class="dv">8</span>:</span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> thread_count <span class="op">&gt;=</span> <span class="dv">8</span>:</span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> thread_count <span class="op">&gt;=</span> <span class="dv">8</span>:</span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a><span class="fu">## Thread-to-Data Mapping</span></span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a>Once threads know their IDs, they need to map those IDs to specific data elements.</span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;div class="mermaid"&gt;</span></span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a><span class="in">graph TB</span></span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a><span class="in">    subgraph "Thread to Data Mapping"</span></span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Thread Grid"</span></span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a><span class="in">            T00["Thread[0,0]&lt;br/&gt;Warp 0"]</span></span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a><span class="in">            T01["Thread[0,1]&lt;br/&gt;Warp 0"]</span></span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a><span class="in">            T10["Thread[1,0]&lt;br/&gt;Warp 1"]</span></span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a><span class="in">            T11["Thread[1,1]&lt;br/&gt;Warp 1"]</span></span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Data Tiles"</span></span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a><span class="in">            D00["Data[0:4, 0:4]&lt;br/&gt;16 elements"]</span></span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a><span class="in">            D01["Data[0:4, 4:8]&lt;br/&gt;16 elements"]</span></span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a><span class="in">            D10["Data[4:8, 0:4]&lt;br/&gt;16 elements"]</span></span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a><span class="in">            D11["Data[4:8, 4:8]&lt;br/&gt;16 elements"]</span></span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Memory Access"</span></span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a><span class="in">            MA["Coalesced Access&lt;br/&gt;Adjacent threads → Adjacent memory"]</span></span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a><span class="in">    end</span></span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a><span class="in">    T00 --&gt; D00</span></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a><span class="in">    T01 --&gt; D01</span></span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a><span class="in">    T10 --&gt; D10</span></span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a><span class="in">    T11 --&gt; D11</span></span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a><span class="in">    D00 --&gt; MA</span></span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a><span class="in">    D01 --&gt; MA</span></span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a><span class="in">    style T00 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px</span></span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a><span class="in">    style D00 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px</span></span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a><span class="in">    style MA fill:#fff3e0,stroke:#f57c00,stroke-width:2px</span></span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/div&gt;</span></span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Distribution Pattern</span></span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a>The RMSNorm operation distributes tensor data across threads in a structured pattern:</span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🎯 RMSNorm Data Distribution Pattern"</span>)</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate total tensor size processed by this tile distribution</span></span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a>total_m <span class="op">=</span> repeat_m <span class="op">*</span> warp_per_block_m <span class="op">*</span> thread_per_warp_m <span class="op">*</span> vector_m</span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>total_n <span class="op">=</span> repeat_n <span class="op">*</span> warp_per_block_n <span class="op">*</span> thread_per_warp_n <span class="op">*</span> vector_n</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"📊 Tensor Organization:"</span>)</span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total tensor size (M×N): </span><span class="sc">{</span>total_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>total_n<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Elements per thread: </span><span class="sc">{</span>vector_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>vector_n<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>vector_m <span class="op">*</span> vector_n<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">📋 Hierarchical Data Distribution:"</span>)</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  🔹 Block Level: </span><span class="sc">{</span>repeat_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>repeat_n<span class="sc">}</span><span class="ss"> iterations"</span>)</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  🔹 Warp Level: </span><span class="sc">{</span>warp_per_block_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>warp_per_block_n<span class="sc">}</span><span class="ss"> warps per block"</span>)</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  🔹 Thread Level: </span><span class="sc">{</span>thread_per_warp_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>thread_per_warp_n<span class="sc">}</span><span class="ss"> threads per warp"</span>)</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  🔹 Vector Level: </span><span class="sc">{</span>vector_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>vector_n<span class="sc">}</span><span class="ss"> elements per thread"</span>)</span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a><span class="fu">### Thread Work Assignment</span></span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a>Each thread is assigned a specific rectangular region of the tensor:</span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"📋 Thread Work Assignment Example"</span>)</span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a><span class="co"># Pick a specific thread and show its work</span></span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a>example_warp_m, example_warp_n <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a>example_thread_m, example_thread_n <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate this thread's data region</span></span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>thread_start_m <span class="op">=</span> example_warp_m <span class="op">*</span> thread_per_warp_m <span class="op">*</span> vector_m <span class="op">+</span> example_thread_m <span class="op">*</span> vector_m</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a>thread_end_m <span class="op">=</span> thread_start_m <span class="op">+</span> vector_m</span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a>thread_start_n <span class="op">=</span> example_warp_n <span class="op">*</span> thread_per_warp_n <span class="op">*</span> vector_n <span class="op">+</span> example_thread_n <span class="op">*</span> vector_n</span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a>thread_end_n <span class="op">=</span> thread_start_n <span class="op">+</span> vector_n</span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Example thread: Warp[</span><span class="sc">{</span>example_warp_m<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>example_warp_n<span class="sc">}</span><span class="ss">] Thread[</span><span class="sc">{</span>example_thread_m<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>example_thread_n<span class="sc">}</span><span class="ss">]"</span>)</span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Data region (M): [</span><span class="sc">{</span>thread_start_m<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>thread_end_m<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Data region (N): [</span><span class="sc">{</span>thread_start_n<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>thread_end_n<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total elements: </span><span class="sc">{</span>vector_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>vector_n<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>vector_m <span class="op">*</span> vector_n<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">🔍 Thread Data Regions (first few threads):"</span>)</span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>shown_threads <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> warp_m <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, warp_per_block_m)):</span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> thread_m <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, thread_per_warp_m)):</span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> warp_n <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, warp_per_block_n)):</span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> thread_n <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, thread_per_warp_n)):</span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a>                start_m <span class="op">=</span> warp_m <span class="op">*</span> thread_per_warp_m <span class="op">*</span> vector_m <span class="op">+</span> thread_m <span class="op">*</span> vector_m</span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a>                end_m <span class="op">=</span> start_m <span class="op">+</span> vector_m</span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a>                start_n <span class="op">=</span> warp_n <span class="op">*</span> thread_per_warp_n <span class="op">*</span> vector_n <span class="op">+</span> thread_n <span class="op">*</span> vector_n</span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a>                end_n <span class="op">=</span> start_n <span class="op">+</span> vector_n</span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"  W[</span><span class="sc">{</span>warp_m<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>warp_n<span class="sc">}</span><span class="ss">]T[</span><span class="sc">{</span>thread_m<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>thread_n<span class="sc">}</span><span class="ss">]: M[</span><span class="sc">{</span>start_m<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>end_m<span class="sc">}</span><span class="ss">) N[</span><span class="sc">{</span>start_n<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>end_n<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a>                shown_threads <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> shown_threads <span class="op">&gt;=</span> <span class="dv">6</span>:</span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="st">"  ... (showing first 6 for brevity)"</span>)</span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> shown_threads <span class="op">&gt;=</span> <span class="dv">6</span>:</span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> shown_threads <span class="op">&gt;=</span> <span class="dv">6</span>:</span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> shown_threads <span class="op">&gt;=</span> <span class="dv">6</span>:</span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a><span class="fu">## Thread Cooperation Patterns</span></span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a>Threads don't work in isolation - they cooperate at different levels to achieve optimal performance.</span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-370"><a href="#cb6-370" aria-hidden="true" tabindex="-1"></a><span class="fu">### Warp-Level Cooperation</span></span>
<span id="cb6-371"><a href="#cb6-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a>Threads within a warp execute in lockstep (SIMD):</span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a>**🤝 Warp-Level Cooperation**</span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Warps per block**: <span class="in">`{warp_per_block_m}×{warp_per_block_n}`</span></span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Threads per warp**: <span class="in">`{thread_per_warp_m}×{thread_per_warp_n}`</span></span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cooperation pattern**: Threads within a warp process adjacent data</span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Synchronization**: Warp-level SIMD execution</span>
<span id="cb6-379"><a href="#cb6-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-380"><a href="#cb6-380" aria-hidden="true" tabindex="-1"></a><span class="fu">### Block-Level Cooperation</span></span>
<span id="cb6-381"><a href="#cb6-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-382"><a href="#cb6-382" aria-hidden="true" tabindex="-1"></a>Threads within a block can share data and synchronize:</span>
<span id="cb6-383"><a href="#cb6-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-384"><a href="#cb6-384" aria-hidden="true" tabindex="-1"></a>**🏗️ Block-Level Cooperation**</span>
<span id="cb6-385"><a href="#cb6-385" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Shared memory**: All threads in block can access shared memory</span>
<span id="cb6-386"><a href="#cb6-386" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Synchronization**: <span class="in">`__syncthreads()`</span> barriers available</span>
<span id="cb6-387"><a href="#cb6-387" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Data sharing**: Threads can exchange intermediate results</span>
<span id="cb6-388"><a href="#cb6-388" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Collective operations**: Reduction, broadcast across block</span>
<span id="cb6-389"><a href="#cb6-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-390"><a href="#cb6-390" aria-hidden="true" tabindex="-1"></a><span class="fu">### Vector-Level Processing</span></span>
<span id="cb6-391"><a href="#cb6-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-392"><a href="#cb6-392" aria-hidden="true" tabindex="-1"></a>Each thread processes multiple elements efficiently:</span>
<span id="cb6-393"><a href="#cb6-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-394"><a href="#cb6-394" aria-hidden="true" tabindex="-1"></a>**⚡ Vector-Level Processing**</span>
<span id="cb6-395"><a href="#cb6-395" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Elements per thread**: <span class="in">`{vector_m}×{vector_n}`</span> elements</span>
<span id="cb6-396"><a href="#cb6-396" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Memory coalescing**: Adjacent threads access adjacent memory</span>
<span id="cb6-397"><a href="#cb6-397" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Vectorization**: Hardware can combine multiple operations</span>
<span id="cb6-398"><a href="#cb6-398" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Register efficiency**: Multiple elements in registers</span>
<span id="cb6-399"><a href="#cb6-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-400"><a href="#cb6-400" aria-hidden="true" tabindex="-1"></a><span class="fu">## Memory Access Patterns</span></span>
<span id="cb6-401"><a href="#cb6-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-402"><a href="#cb6-402" aria-hidden="true" tabindex="-1"></a>The thread mapping directly affects memory access efficiency.</span>
<span id="cb6-403"><a href="#cb6-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-404"><a href="#cb6-404" aria-hidden="true" tabindex="-1"></a><span class="fu">### C++ Implementation of Memory Access</span></span>
<span id="cb6-405"><a href="#cb6-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-406"><a href="#cb6-406" aria-hidden="true" tabindex="-1"></a>Here's how CK implements efficient memory access patterns:</span>
<span id="cb6-407"><a href="#cb6-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-408"><a href="#cb6-408" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb6-409"><a href="#cb6-409" aria-hidden="true" tabindex="-1"></a><span class="co">// Coalesced memory access pattern</span></span>
<span id="cb6-410"><a href="#cb6-410" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> DataType<span class="op">,</span> <span class="dt">index_t</span> VectorSize<span class="op">&gt;</span></span>
<span id="cb6-411"><a href="#cb6-411" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> coalesced_load<span class="op">(</span><span class="at">const</span> DataType<span class="op">*</span> <span class="ex">__restrict__</span> src<span class="op">,</span></span>
<span id="cb6-412"><a href="#cb6-412" aria-hidden="true" tabindex="-1"></a>                               DataType<span class="op">*</span> <span class="ex">__restrict__</span> dst<span class="op">,</span></span>
<span id="cb6-413"><a href="#cb6-413" aria-hidden="true" tabindex="-1"></a>                               <span class="dt">index_t</span> tid<span class="op">)</span></span>
<span id="cb6-414"><a href="#cb6-414" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-415"><a href="#cb6-415" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread loads VectorSize elements</span></span>
<span id="cb6-416"><a href="#cb6-416" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Adjacent threads access adjacent memory</span></span>
<span id="cb6-417"><a href="#cb6-417" aria-hidden="true" tabindex="-1"></a>    <span class="kw">constexpr</span> <span class="dt">index_t</span> stride <span class="op">=</span> blockDim<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-418"><a href="#cb6-418" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-419"><a href="#cb6-419" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Vectorized load for efficiency</span></span>
<span id="cb6-420"><a href="#cb6-420" aria-hidden="true" tabindex="-1"></a>    <span class="kw">using</span> <span class="dt">vector_t</span> <span class="op">=</span> <span class="dt">vector_type_t</span><span class="op">&lt;</span>DataType<span class="op">,</span> VectorSize<span class="op">&gt;;</span></span>
<span id="cb6-421"><a href="#cb6-421" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-422"><a href="#cb6-422" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Calculate aligned address</span></span>
<span id="cb6-423"><a href="#cb6-423" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">vector_t</span><span class="op">*</span> src_vec <span class="op">=</span> <span class="kw">reinterpret_cast</span><span class="op">&lt;</span><span class="at">const</span> <span class="dt">vector_t</span><span class="op">*&gt;(</span></span>
<span id="cb6-424"><a href="#cb6-424" aria-hidden="true" tabindex="-1"></a>        src <span class="op">+</span> tid <span class="op">*</span> VectorSize<span class="op">);</span></span>
<span id="cb6-425"><a href="#cb6-425" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-426"><a href="#cb6-426" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Single vectorized load instruction</span></span>
<span id="cb6-427"><a href="#cb6-427" aria-hidden="true" tabindex="-1"></a>    <span class="dt">vector_t</span> data <span class="op">=</span> <span class="op">*</span>src_vec<span class="op">;</span></span>
<span id="cb6-428"><a href="#cb6-428" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-429"><a href="#cb6-429" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Store to registers</span></span>
<span id="cb6-430"><a href="#cb6-430" aria-hidden="true" tabindex="-1"></a>    <span class="kw">reinterpret_cast</span><span class="op">&lt;</span><span class="dt">vector_t</span><span class="op">*&gt;(</span>dst<span class="op">)[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> data<span class="op">;</span></span>
<span id="cb6-431"><a href="#cb6-431" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-432"><a href="#cb6-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-433"><a href="#cb6-433" aria-hidden="true" tabindex="-1"></a><span class="co">// CK's distributed tensor load implementation</span></span>
<span id="cb6-434"><a href="#cb6-434" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> DistributedTensor<span class="op">&gt;</span></span>
<span id="cb6-435"><a href="#cb6-435" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> load_tile_window<span class="op">(</span>DistributedTensor<span class="op">&amp;</span> dist_tensor<span class="op">,</span></span>
<span id="cb6-436"><a href="#cb6-436" aria-hidden="true" tabindex="-1"></a>                                <span class="at">const</span> <span class="kw">auto</span><span class="op">&amp;</span> tile_window<span class="op">)</span></span>
<span id="cb6-437"><a href="#cb6-437" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-438"><a href="#cb6-438" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Get thread's partition index</span></span>
<span id="cb6-439"><a href="#cb6-439" aria-hidden="true" tabindex="-1"></a>    <span class="kw">constexpr</span> <span class="kw">auto</span> partition <span class="op">=</span> tile_partition<span class="op">::</span>get_partition_index<span class="op">();</span></span>
<span id="cb6-440"><a href="#cb6-440" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-441"><a href="#cb6-441" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread loads its assigned data</span></span>
<span id="cb6-442"><a href="#cb6-442" aria-hidden="true" tabindex="-1"></a>    tile_window<span class="op">.</span>load<span class="op">(</span>dist_tensor<span class="op">,</span> partition<span class="op">);</span></span>
<span id="cb6-443"><a href="#cb6-443" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-444"><a href="#cb6-444" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Hardware automatically coalesces adjacent thread accesses</span></span>
<span id="cb6-445"><a href="#cb6-445" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-446"><a href="#cb6-446" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-447"><a href="#cb6-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-448"><a href="#cb6-448" aria-hidden="true" tabindex="-1"></a><span class="fu">### Memory Access Optimization Techniques</span></span>
<span id="cb6-449"><a href="#cb6-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-450"><a href="#cb6-450" aria-hidden="true" tabindex="-1"></a>CK uses several techniques to optimize memory access:</span>
<span id="cb6-451"><a href="#cb6-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-452"><a href="#cb6-452" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb6-453"><a href="#cb6-453" aria-hidden="true" tabindex="-1"></a><span class="co">// 1. Vector loads for maximum bandwidth</span></span>
<span id="cb6-454"><a href="#cb6-454" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="dt">index_t</span> N<span class="op">&gt;</span></span>
<span id="cb6-455"><a href="#cb6-455" aria-hidden="true" tabindex="-1"></a><span class="kw">using</span> <span class="dt">vector_load_t</span> <span class="op">=</span> <span class="dt">conditional_t</span><span class="op">&lt;</span>N <span class="op">==</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">float</span><span class="op">,</span></span>
<span id="cb6-456"><a href="#cb6-456" aria-hidden="true" tabindex="-1"></a>                     <span class="dt">conditional_t</span><span class="op">&lt;</span>N <span class="op">==</span> <span class="dv">2</span><span class="op">,</span> float2<span class="op">,</span></span>
<span id="cb6-457"><a href="#cb6-457" aria-hidden="true" tabindex="-1"></a>                     <span class="dt">conditional_t</span><span class="op">&lt;</span>N <span class="op">==</span> <span class="dv">4</span><span class="op">,</span> float4<span class="op">,</span></span>
<span id="cb6-458"><a href="#cb6-458" aria-hidden="true" tabindex="-1"></a>                                           <span class="dt">float</span><span class="op">&gt;&gt;&gt;;</span></span>
<span id="cb6-459"><a href="#cb6-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-460"><a href="#cb6-460" aria-hidden="true" tabindex="-1"></a><span class="co">// 2. Swizzling to avoid bank conflicts</span></span>
<span id="cb6-461"><a href="#cb6-461" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="dt">index_t</span> BankSize <span class="op">=</span> <span class="dv">32</span><span class="op">&gt;</span></span>
<span id="cb6-462"><a href="#cb6-462" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">index_t</span> swizzle_offset<span class="op">(</span><span class="dt">index_t</span> tid<span class="op">,</span> <span class="dt">index_t</span> offset<span class="op">)</span></span>
<span id="cb6-463"><a href="#cb6-463" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-464"><a href="#cb6-464" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Rotate access pattern to avoid conflicts</span></span>
<span id="cb6-465"><a href="#cb6-465" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">(</span>offset <span class="op">+</span> <span class="op">(</span>tid <span class="op">/</span> BankSize<span class="op">))</span> <span class="op">%</span> BankSize<span class="op">;</span></span>
<span id="cb6-466"><a href="#cb6-466" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-467"><a href="#cb6-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-468"><a href="#cb6-468" aria-hidden="true" tabindex="-1"></a><span class="co">// 3. Prefetching for latency hiding</span></span>
<span id="cb6-469"><a href="#cb6-469" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> prefetch_next_tile<span class="op">(</span><span class="at">const</span> <span class="dt">float</span><span class="op">*</span> src<span class="op">,</span> <span class="dt">index_t</span> offset<span class="op">)</span></span>
<span id="cb6-470"><a href="#cb6-470" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-471"><a href="#cb6-471" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Prefetch to L2 cache</span></span>
<span id="cb6-472"><a href="#cb6-472" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__builtin_prefetch</span><span class="op">(</span>src <span class="op">+</span> offset<span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="dv">3</span><span class="op">);</span></span>
<span id="cb6-473"><a href="#cb6-473" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-474"><a href="#cb6-474" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-475"><a href="#cb6-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-476"><a href="#cb6-476" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coalesced Memory Access</span></span>
<span id="cb6-477"><a href="#cb6-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-480"><a href="#cb6-480" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-481"><a href="#cb6-481" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🚀 Memory Access Pattern Analysis"</span>)</span>
<span id="cb6-482"><a href="#cb6-482" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-483"><a href="#cb6-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-484"><a href="#cb6-484" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tile distribution to analyze memory patterns</span></span>
<span id="cb6-485"><a href="#cb6-485" aria-hidden="true" tabindex="-1"></a>tile_distribution <span class="op">=</span> make_static_tile_distribution(encoding)</span>
<span id="cb6-486"><a href="#cb6-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-487"><a href="#cb6-487" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate tensor data</span></span>
<span id="cb6-488"><a href="#cb6-488" aria-hidden="true" tabindex="-1"></a>tensor_shape <span class="op">=</span> [total_m, total_n]</span>
<span id="cb6-489"><a href="#cb6-489" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.arange(np.prod(tensor_shape), dtype<span class="op">=</span>np.float32)</span>
<span id="cb6-490"><a href="#cb6-490" aria-hidden="true" tabindex="-1"></a>tensor_view <span class="op">=</span> make_naive_tensor_view_packed(data, tensor_shape)</span>
<span id="cb6-491"><a href="#cb6-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-492"><a href="#cb6-492" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"📊 Memory Access Analysis:"</span>)</span>
<span id="cb6-493"><a href="#cb6-493" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Tensor shape: </span><span class="sc">{</span>tensor_shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-494"><a href="#cb6-494" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Memory layout: Row-major"</span>)</span>
<span id="cb6-495"><a href="#cb6-495" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Vector size per thread: </span><span class="sc">{</span>vector_m<span class="sc">}</span><span class="ss">×</span><span class="sc">{</span>vector_n<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-496"><a href="#cb6-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-497"><a href="#cb6-497" aria-hidden="true" tabindex="-1"></a><span class="co"># Analyze access pattern for a few threads</span></span>
<span id="cb6-498"><a href="#cb6-498" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">🔍 Memory Access Pattern (first few threads):"</span>)</span>
<span id="cb6-499"><a href="#cb6-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-500"><a href="#cb6-500" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up different thread positions and show their access patterns</span></span>
<span id="cb6-501"><a href="#cb6-501" aria-hidden="true" tabindex="-1"></a>thread_examples <span class="op">=</span> [</span>
<span id="cb6-502"><a href="#cb6-502" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span>, <span class="dv">0</span>),  <span class="co"># First thread</span></span>
<span id="cb6-503"><a href="#cb6-503" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">0</span>, <span class="dv">1</span>),  <span class="co"># Second thread in same warp</span></span>
<span id="cb6-504"><a href="#cb6-504" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">1</span>, <span class="dv">0</span>),  <span class="co"># First thread in next warp</span></span>
<span id="cb6-505"><a href="#cb6-505" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb6-506"><a href="#cb6-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-507"><a href="#cb6-507" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> thread_p0, thread_p1 <span class="kw">in</span> thread_examples:</span>
<span id="cb6-508"><a href="#cb6-508" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set thread position</span></span>
<span id="cb6-509"><a href="#cb6-509" aria-hidden="true" tabindex="-1"></a>    set_global_thread_position(thread_p0, thread_p1)</span>
<span id="cb6-510"><a href="#cb6-510" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-511"><a href="#cb6-511" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create tile window</span></span>
<span id="cb6-512"><a href="#cb6-512" aria-hidden="true" tabindex="-1"></a>    tile_window <span class="op">=</span> make_tile_window(</span>
<span id="cb6-513"><a href="#cb6-513" aria-hidden="true" tabindex="-1"></a>        tensor_view<span class="op">=</span>tensor_view,</span>
<span id="cb6-514"><a href="#cb6-514" aria-hidden="true" tabindex="-1"></a>        window_lengths<span class="op">=</span>[total_m, total_n],</span>
<span id="cb6-515"><a href="#cb6-515" aria-hidden="true" tabindex="-1"></a>        origin<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb6-516"><a href="#cb6-516" aria-hidden="true" tabindex="-1"></a>        tile_distribution<span class="op">=</span>tile_distribution</span>
<span id="cb6-517"><a href="#cb6-517" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-518"><a href="#cb6-518" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-519"><a href="#cb6-519" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load data to see access pattern</span></span>
<span id="cb6-520"><a href="#cb6-520" aria-hidden="true" tabindex="-1"></a>    loaded_tensor <span class="op">=</span> tile_window.load()</span>
<span id="cb6-521"><a href="#cb6-521" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-522"><a href="#cb6-522" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Thread P=[</span><span class="sc">{</span>thread_p0<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>thread_p1<span class="sc">}</span><span class="ss">]:"</span>)</span>
<span id="cb6-523"><a href="#cb6-523" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    Elements loaded: </span><span class="sc">{</span>loaded_tensor<span class="sc">.</span>get_num_of_elements()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-524"><a href="#cb6-524" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-525"><a href="#cb6-525" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show first few elements accessed</span></span>
<span id="cb6-526"><a href="#cb6-526" aria-hidden="true" tabindex="-1"></a>    sample_values <span class="op">=</span> []</span>
<span id="cb6-527"><a href="#cb6-527" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> y0 <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, vector_m)):</span>
<span id="cb6-528"><a href="#cb6-528" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> y1 <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, vector_n)):</span>
<span id="cb6-529"><a href="#cb6-529" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb6-530"><a href="#cb6-530" aria-hidden="true" tabindex="-1"></a>                value <span class="op">=</span> loaded_tensor.get_element([y0, y1])</span>
<span id="cb6-531"><a href="#cb6-531" aria-hidden="true" tabindex="-1"></a>                sample_values.append(value)</span>
<span id="cb6-532"><a href="#cb6-532" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span>:</span>
<span id="cb6-533"><a href="#cb6-533" aria-hidden="true" tabindex="-1"></a>                <span class="cf">pass</span></span>
<span id="cb6-534"><a href="#cb6-534" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-535"><a href="#cb6-535" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sample_values:</span>
<span id="cb6-536"><a href="#cb6-536" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"    Sample values: </span><span class="sc">{</span>sample_values[:<span class="dv">4</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-537"><a href="#cb6-537" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-538"><a href="#cb6-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-539"><a href="#cb6-539" aria-hidden="true" tabindex="-1"></a><span class="fu">### Memory Efficiency Benefits</span></span>
<span id="cb6-540"><a href="#cb6-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-541"><a href="#cb6-541" aria-hidden="true" tabindex="-1"></a>The structured thread mapping provides several memory efficiency benefits:</span>
<span id="cb6-542"><a href="#cb6-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-543"><a href="#cb6-543" aria-hidden="true" tabindex="-1"></a>**🎯 Memory Coalescing Benefits:**</span>
<span id="cb6-544"><a href="#cb6-544" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Adjacent access**: Threads in same warp access adjacent memory locations</span>
<span id="cb6-545"><a href="#cb6-545" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cache efficiency**: Related data loaded together into cache lines</span>
<span id="cb6-546"><a href="#cb6-546" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bandwidth utilization**: Maximum memory bandwidth achieved</span>
<span id="cb6-547"><a href="#cb6-547" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Reduced latency**: Fewer memory transactions needed</span>
<span id="cb6-548"><a href="#cb6-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-549"><a href="#cb6-549" aria-hidden="true" tabindex="-1"></a>**⚡ Performance Characteristics:**</span>
<span id="cb6-550"><a href="#cb6-550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Predictable patterns**: Access patterns known at compile time</span>
<span id="cb6-551"><a href="#cb6-551" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Vectorization**: Hardware can optimize vector operations</span>
<span id="cb6-552"><a href="#cb6-552" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Reduced overhead**: No complex address calculations at runtime</span>
<span id="cb6-553"><a href="#cb6-553" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Scalability**: Pattern scales efficiently with thread count</span>
<span id="cb6-554"><a href="#cb6-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-555"><a href="#cb6-555" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practical Thread Mapping Example</span></span>
<span id="cb6-556"><a href="#cb6-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-557"><a href="#cb6-557" aria-hidden="true" tabindex="-1"></a><span class="fu">### Complete C++ Kernel Example</span></span>
<span id="cb6-558"><a href="#cb6-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-559"><a href="#cb6-559" aria-hidden="true" tabindex="-1"></a>Here's a complete example showing how thread mapping works in a real CK kernel:</span>
<span id="cb6-560"><a href="#cb6-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-561"><a href="#cb6-561" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb6-562"><a href="#cb6-562" aria-hidden="true" tabindex="-1"></a><span class="co">// RMSNorm kernel using CK's thread mapping</span></span>
<span id="cb6-563"><a href="#cb6-563" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> DataType<span class="op">,</span></span>
<span id="cb6-564"><a href="#cb6-564" aria-hidden="true" tabindex="-1"></a>          <span class="kw">typename</span> ComputeType<span class="op">,</span></span>
<span id="cb6-565"><a href="#cb6-565" aria-hidden="true" tabindex="-1"></a>          <span class="dt">index_t</span> BlockSize<span class="op">,</span></span>
<span id="cb6-566"><a href="#cb6-566" aria-hidden="true" tabindex="-1"></a>          <span class="dt">index_t</span> VectorSize<span class="op">&gt;</span></span>
<span id="cb6-567"><a href="#cb6-567" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> rmsnorm_kernel<span class="op">(</span><span class="at">const</span> DataType<span class="op">*</span> <span class="ex">__restrict__</span> x<span class="op">,</span></span>
<span id="cb6-568"><a href="#cb6-568" aria-hidden="true" tabindex="-1"></a>                              DataType<span class="op">*</span> <span class="ex">__restrict__</span> y<span class="op">,</span></span>
<span id="cb6-569"><a href="#cb6-569" aria-hidden="true" tabindex="-1"></a>                              <span class="at">const</span> DataType<span class="op">*</span> <span class="ex">__restrict__</span> weight<span class="op">,</span></span>
<span id="cb6-570"><a href="#cb6-570" aria-hidden="true" tabindex="-1"></a>                              ComputeType epsilon<span class="op">,</span></span>
<span id="cb6-571"><a href="#cb6-571" aria-hidden="true" tabindex="-1"></a>                              <span class="dt">index_t</span> hidden_size<span class="op">)</span></span>
<span id="cb6-572"><a href="#cb6-572" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb6-573"><a href="#cb6-573" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 1. Thread identification</span></span>
<span id="cb6-574"><a href="#cb6-574" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">index_t</span> tid <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-575"><a href="#cb6-575" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">index_t</span> bid <span class="op">=</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb6-576"><a href="#cb6-576" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-577"><a href="#cb6-577" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 2. Create tile distribution encoding</span></span>
<span id="cb6-578"><a href="#cb6-578" aria-hidden="true" tabindex="-1"></a>    <span class="co">// This would be defined based on your specific RMSNorm pattern</span></span>
<span id="cb6-579"><a href="#cb6-579" aria-hidden="true" tabindex="-1"></a>    <span class="kw">using</span> Encoding <span class="op">=</span> tile_distribution_encoding<span class="op">&lt;</span></span>
<span id="cb6-580"><a href="#cb6-580" aria-hidden="true" tabindex="-1"></a>        sequence<span class="op">&lt;&gt;,</span>                          <span class="co">// No replication</span></span>
<span id="cb6-581"><a href="#cb6-581" aria-hidden="true" tabindex="-1"></a>        tuple<span class="op">&lt;</span>sequence<span class="op">&lt;</span><span class="dv">4</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;,</span> sequence<span class="op">&lt;</span><span class="dv">4</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;&gt;,</span> <span class="co">// H dimensions</span></span>
<span id="cb6-582"><a href="#cb6-582" aria-hidden="true" tabindex="-1"></a>        tuple<span class="op">&lt;</span>sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;,</span> sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;&gt;,</span>     <span class="co">// P to RH major</span></span>
<span id="cb6-583"><a href="#cb6-583" aria-hidden="true" tabindex="-1"></a>        tuple<span class="op">&lt;</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;,</span> sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;&gt;,</span>     <span class="co">// P to RH minor</span></span>
<span id="cb6-584"><a href="#cb6-584" aria-hidden="true" tabindex="-1"></a>        sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;,</span>                      <span class="co">// Y to RH major</span></span>
<span id="cb6-585"><a href="#cb6-585" aria-hidden="true" tabindex="-1"></a>        sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">0</span><span class="op">&gt;</span>                       <span class="co">// Y to RH minor</span></span>
<span id="cb6-586"><a href="#cb6-586" aria-hidden="true" tabindex="-1"></a>    <span class="op">&gt;;</span></span>
<span id="cb6-587"><a href="#cb6-587" aria-hidden="true" tabindex="-1"></a>    <span class="kw">constexpr</span> <span class="kw">auto</span> tile_dist <span class="op">=</span> make_static_tile_distribution<span class="op">(</span>Encoding<span class="op">{});</span></span>
<span id="cb6-588"><a href="#cb6-588" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-589"><a href="#cb6-589" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 3. Get thread's partition index from distribution</span></span>
<span id="cb6-590"><a href="#cb6-590" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="kw">auto</span> partition_idx <span class="op">=</span> tile_dist<span class="op">.</span>_get_partition_index<span class="op">();</span></span>
<span id="cb6-591"><a href="#cb6-591" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-592"><a href="#cb6-592" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 4. Shared memory for reduction</span></span>
<span id="cb6-593"><a href="#cb6-593" aria-hidden="true" tabindex="-1"></a>    __shared__ ComputeType shared_sum<span class="op">[</span>BlockSize<span class="op">];</span></span>
<span id="cb6-594"><a href="#cb6-594" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-595"><a href="#cb6-595" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 5. Create tensor view and tile window</span></span>
<span id="cb6-596"><a href="#cb6-596" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> x_view <span class="op">=</span> make_naive_tensor_view<span class="op">&lt;</span>address_space_enum<span class="op">::</span>global<span class="op">&gt;(</span></span>
<span id="cb6-597"><a href="#cb6-597" aria-hidden="true" tabindex="-1"></a>        x <span class="op">+</span> bid <span class="op">*</span> hidden_size<span class="op">,</span></span>
<span id="cb6-598"><a href="#cb6-598" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>hidden_size<span class="op">),</span></span>
<span id="cb6-599"><a href="#cb6-599" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>number<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span></span>
<span id="cb6-600"><a href="#cb6-600" aria-hidden="true" tabindex="-1"></a>    <span class="op">);</span></span>
<span id="cb6-601"><a href="#cb6-601" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-602"><a href="#cb6-602" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> x_window <span class="op">=</span> make_tile_window<span class="op">(</span></span>
<span id="cb6-603"><a href="#cb6-603" aria-hidden="true" tabindex="-1"></a>        x_view<span class="op">,</span></span>
<span id="cb6-604"><a href="#cb6-604" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>hidden_size<span class="op">),</span></span>
<span id="cb6-605"><a href="#cb6-605" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>number<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{}),</span></span>
<span id="cb6-606"><a href="#cb6-606" aria-hidden="true" tabindex="-1"></a>        tile_dist<span class="op">);</span></span>
<span id="cb6-607"><a href="#cb6-607" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-608"><a href="#cb6-608" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 6. Each thread processes its assigned elements</span></span>
<span id="cb6-609"><a href="#cb6-609" aria-hidden="true" tabindex="-1"></a>    ComputeType thread_sum <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb6-610"><a href="#cb6-610" aria-hidden="true" tabindex="-1"></a>    static_for<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> VectorSize<span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}([&amp;](</span><span class="kw">auto</span> i<span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-611"><a href="#cb6-611" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Access pattern would depend on your tile window setup</span></span>
<span id="cb6-612"><a href="#cb6-612" aria-hidden="true" tabindex="-1"></a>        <span class="co">// This is conceptual - actual implementation varies</span></span>
<span id="cb6-613"><a href="#cb6-613" aria-hidden="true" tabindex="-1"></a>        thread_sum <span class="op">+=</span> val <span class="op">*</span> val<span class="op">;</span></span>
<span id="cb6-614"><a href="#cb6-614" aria-hidden="true" tabindex="-1"></a>    <span class="op">});</span></span>
<span id="cb6-615"><a href="#cb6-615" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-616"><a href="#cb6-616" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 7. Warp-level reduction</span></span>
<span id="cb6-617"><a href="#cb6-617" aria-hidden="true" tabindex="-1"></a>    thread_sum <span class="op">=</span> warp_reduce_sum<span class="op">&lt;</span>WarpSize<span class="op">&gt;(</span>thread_sum<span class="op">);</span></span>
<span id="cb6-618"><a href="#cb6-618" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-619"><a href="#cb6-619" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 8. Block-level reduction</span></span>
<span id="cb6-620"><a href="#cb6-620" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>tid <span class="op">%</span> WarpSize <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-621"><a href="#cb6-621" aria-hidden="true" tabindex="-1"></a>        shared_sum<span class="op">[</span>tid <span class="op">/</span> WarpSize<span class="op">]</span> <span class="op">=</span> thread_sum<span class="op">;</span></span>
<span id="cb6-622"><a href="#cb6-622" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-623"><a href="#cb6-623" aria-hidden="true" tabindex="-1"></a>    __syncthreads<span class="op">();</span></span>
<span id="cb6-624"><a href="#cb6-624" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-625"><a href="#cb6-625" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 9. Final reduction by first warp</span></span>
<span id="cb6-626"><a href="#cb6-626" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>tid <span class="op">&lt;</span> BlockSize <span class="op">/</span> WarpSize<span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-627"><a href="#cb6-627" aria-hidden="true" tabindex="-1"></a>        thread_sum <span class="op">=</span> shared_sum<span class="op">[</span>tid<span class="op">];</span></span>
<span id="cb6-628"><a href="#cb6-628" aria-hidden="true" tabindex="-1"></a>        thread_sum <span class="op">=</span> warp_reduce_sum<span class="op">&lt;</span>BlockSize <span class="op">/</span> WarpSize<span class="op">&gt;(</span>thread_sum<span class="op">);</span></span>
<span id="cb6-629"><a href="#cb6-629" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-630"><a href="#cb6-630" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-631"><a href="#cb6-631" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 10. Compute RMS and normalize</span></span>
<span id="cb6-632"><a href="#cb6-632" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>tid <span class="op">==</span> <span class="dv">0</span><span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-633"><a href="#cb6-633" aria-hidden="true" tabindex="-1"></a>        shared_sum<span class="op">[</span><span class="dv">0</span><span class="op">]</span> <span class="op">=</span> rsqrt<span class="op">(</span>thread_sum <span class="op">/</span> hidden_size <span class="op">+</span> epsilon<span class="op">);</span></span>
<span id="cb6-634"><a href="#cb6-634" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb6-635"><a href="#cb6-635" aria-hidden="true" tabindex="-1"></a>    __syncthreads<span class="op">();</span></span>
<span id="cb6-636"><a href="#cb6-636" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-637"><a href="#cb6-637" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> ComputeType rms_recip <span class="op">=</span> shared_sum<span class="op">[</span><span class="dv">0</span><span class="op">];</span></span>
<span id="cb6-638"><a href="#cb6-638" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-639"><a href="#cb6-639" aria-hidden="true" tabindex="-1"></a>    <span class="co">// 11. Write normalized output</span></span>
<span id="cb6-640"><a href="#cb6-640" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> y_window <span class="op">=</span> make_tile_window<span class="op">(</span></span>
<span id="cb6-641"><a href="#cb6-641" aria-hidden="true" tabindex="-1"></a>        make_tensor_view<span class="op">&lt;</span>address_space_enum<span class="op">::</span>global<span class="op">&gt;(</span>y <span class="op">+</span> bid <span class="op">*</span> hidden_size<span class="op">),</span></span>
<span id="cb6-642"><a href="#cb6-642" aria-hidden="true" tabindex="-1"></a>        tile_dist<span class="op">);</span></span>
<span id="cb6-643"><a href="#cb6-643" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-644"><a href="#cb6-644" aria-hidden="true" tabindex="-1"></a>    static_for<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> VectorSize<span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}([&amp;](</span><span class="kw">auto</span> i<span class="op">)</span> <span class="op">{</span></span>
<span id="cb6-645"><a href="#cb6-645" aria-hidden="true" tabindex="-1"></a>        <span class="kw">auto</span> idx <span class="op">=</span> tile_dist<span class="op">.</span>get_tensor_coordinate<span class="op">(</span>partition_idx<span class="op">,</span> i<span class="op">);</span></span>
<span id="cb6-646"><a href="#cb6-646" aria-hidden="true" tabindex="-1"></a>        ComputeType val <span class="op">=</span> <span class="kw">static_cast</span><span class="op">&lt;</span>ComputeType<span class="op">&gt;(</span>x_window<span class="op">.</span>get<span class="op">(</span>idx<span class="op">));</span></span>
<span id="cb6-647"><a href="#cb6-647" aria-hidden="true" tabindex="-1"></a>        ComputeType w <span class="op">=</span> <span class="kw">static_cast</span><span class="op">&lt;</span>ComputeType<span class="op">&gt;(</span>weight<span class="op">[</span>idx<span class="op">[</span><span class="dv">1</span><span class="op">]]);</span></span>
<span id="cb6-648"><a href="#cb6-648" aria-hidden="true" tabindex="-1"></a>        y_window<span class="op">.</span>set<span class="op">(</span>idx<span class="op">,</span> <span class="kw">static_cast</span><span class="op">&lt;</span>DataType<span class="op">&gt;(</span>val <span class="op">*</span> rms_recip <span class="op">*</span> w<span class="op">));</span></span>
<span id="cb6-649"><a href="#cb6-649" aria-hidden="true" tabindex="-1"></a>    <span class="op">});</span></span>
<span id="cb6-650"><a href="#cb6-650" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb6-651"><a href="#cb6-651" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-652"><a href="#cb6-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-653"><a href="#cb6-653" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Thread Mapping Concepts in Action</span></span>
<span id="cb6-654"><a href="#cb6-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-655"><a href="#cb6-655" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Thread-to-Data Assignment**: Each thread gets a unique <span class="in">`partition_idx`</span></span>
<span id="cb6-656"><a href="#cb6-656" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Vectorized Access**: Each thread processes <span class="in">`VectorSize`</span> elements</span>
<span id="cb6-657"><a href="#cb6-657" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Warp Cooperation**: Threads within a warp perform reductions</span>
<span id="cb6-658"><a href="#cb6-658" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Block Synchronization**: All threads synchronize for final result</span>
<span id="cb6-659"><a href="#cb6-659" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Coalesced Memory**: Adjacent threads access adjacent memory</span>
<span id="cb6-660"><a href="#cb6-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-661"><a href="#cb6-661" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practical Thread Mapping Example</span></span>
<span id="cb6-662"><a href="#cb6-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-663"><a href="#cb6-663" aria-hidden="true" tabindex="-1"></a>Let's see how thread mapping works in practice with a complete example:</span>
<span id="cb6-664"><a href="#cb6-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-667"><a href="#cb6-667" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-668"><a href="#cb6-668" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🎯 Complete Thread Mapping Example"</span>)</span>
<span id="cb6-669"><a href="#cb6-669" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-670"><a href="#cb6-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-671"><a href="#cb6-671" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the tile distribution</span></span>
<span id="cb6-672"><a href="#cb6-672" aria-hidden="true" tabindex="-1"></a>tile_distribution <span class="op">=</span> make_static_tile_distribution(encoding)</span>
<span id="cb6-673"><a href="#cb6-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-674"><a href="#cb6-674" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample tensor data</span></span>
<span id="cb6-675"><a href="#cb6-675" aria-hidden="true" tabindex="-1"></a>tensor_shape <span class="op">=</span> [<span class="dv">64</span>, <span class="dv">64</span>]  <span class="co"># Smaller for demonstration</span></span>
<span id="cb6-676"><a href="#cb6-676" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.arange(np.prod(tensor_shape), dtype<span class="op">=</span>np.float32)</span>
<span id="cb6-677"><a href="#cb6-677" aria-hidden="true" tabindex="-1"></a>tensor_view <span class="op">=</span> make_naive_tensor_view_packed(data, tensor_shape)</span>
<span id="cb6-678"><a href="#cb6-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-679"><a href="#cb6-679" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"📊 Example Setup:"</span>)</span>
<span id="cb6-680"><a href="#cb6-680" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Tensor shape: </span><span class="sc">{</span>tensor_shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-681"><a href="#cb6-681" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total elements: </span><span class="sc">{</span>np<span class="sc">.</span>prod(tensor_shape)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-682"><a href="#cb6-682" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Tile distribution: RMSNorm pattern"</span>)</span>
<span id="cb6-683"><a href="#cb6-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-684"><a href="#cb6-684" aria-hidden="true" tabindex="-1"></a><span class="co"># Show how different threads access different data</span></span>
<span id="cb6-685"><a href="#cb6-685" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">🔍 Thread-by-Thread Data Access:"</span>)</span>
<span id="cb6-686"><a href="#cb6-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-687"><a href="#cb6-687" aria-hidden="true" tabindex="-1"></a>example_threads <span class="op">=</span> [(<span class="dv">0</span>, <span class="dv">0</span>), (<span class="dv">0</span>, <span class="dv">1</span>), (<span class="dv">1</span>, <span class="dv">0</span>), (<span class="dv">1</span>, <span class="dv">1</span>)]</span>
<span id="cb6-688"><a href="#cb6-688" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (p0, p1) <span class="kw">in</span> <span class="bu">enumerate</span>(example_threads):</span>
<span id="cb6-689"><a href="#cb6-689" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set thread position</span></span>
<span id="cb6-690"><a href="#cb6-690" aria-hidden="true" tabindex="-1"></a>    set_global_thread_position(p0, p1)</span>
<span id="cb6-691"><a href="#cb6-691" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-692"><a href="#cb6-692" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create tile window and load data</span></span>
<span id="cb6-693"><a href="#cb6-693" aria-hidden="true" tabindex="-1"></a>    tile_window <span class="op">=</span> make_tile_window(</span>
<span id="cb6-694"><a href="#cb6-694" aria-hidden="true" tabindex="-1"></a>        tensor_view<span class="op">=</span>tensor_view,</span>
<span id="cb6-695"><a href="#cb6-695" aria-hidden="true" tabindex="-1"></a>        window_lengths<span class="op">=</span>[<span class="dv">32</span>, <span class="dv">32</span>],  <span class="co"># Window size</span></span>
<span id="cb6-696"><a href="#cb6-696" aria-hidden="true" tabindex="-1"></a>        origin<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb6-697"><a href="#cb6-697" aria-hidden="true" tabindex="-1"></a>        tile_distribution<span class="op">=</span>tile_distribution</span>
<span id="cb6-698"><a href="#cb6-698" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-699"><a href="#cb6-699" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-700"><a href="#cb6-700" aria-hidden="true" tabindex="-1"></a>    loaded_tensor <span class="op">=</span> tile_window.load()</span>
<span id="cb6-701"><a href="#cb6-701" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-702"><a href="#cb6-702" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Thread </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (P=[</span><span class="sc">{</span>p0<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>p1<span class="sc">}</span><span class="ss">]):"</span>)</span>
<span id="cb6-703"><a href="#cb6-703" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    Elements: </span><span class="sc">{</span>loaded_tensor<span class="sc">.</span>get_num_of_elements()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-704"><a href="#cb6-704" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-705"><a href="#cb6-705" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show data range accessed by this thread</span></span>
<span id="cb6-706"><a href="#cb6-706" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> []</span>
<span id="cb6-707"><a href="#cb6-707" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> y0 <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, vector_m)):</span>
<span id="cb6-708"><a href="#cb6-708" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> y1 <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">2</span>, vector_n)):</span>
<span id="cb6-709"><a href="#cb6-709" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb6-710"><a href="#cb6-710" aria-hidden="true" tabindex="-1"></a>                value <span class="op">=</span> loaded_tensor.get_element([y0, y1])</span>
<span id="cb6-711"><a href="#cb6-711" aria-hidden="true" tabindex="-1"></a>                values.append(value)</span>
<span id="cb6-712"><a href="#cb6-712" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span>:</span>
<span id="cb6-713"><a href="#cb6-713" aria-hidden="true" tabindex="-1"></a>                <span class="cf">pass</span></span>
<span id="cb6-714"><a href="#cb6-714" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-715"><a href="#cb6-715" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> values:</span>
<span id="cb6-716"><a href="#cb6-716" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"    Value range: [</span><span class="sc">{</span><span class="bu">min</span>(values)<span class="sc">:.0f}</span><span class="ss">, </span><span class="sc">{</span><span class="bu">max</span>(values)<span class="sc">:.0f}</span><span class="ss">]"</span>)</span>
<span id="cb6-717"><a href="#cb6-717" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"    Sample: </span><span class="sc">{</span>values[:<span class="dv">4</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-718"><a href="#cb6-718" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-719"><a href="#cb6-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-720"><a href="#cb6-720" aria-hidden="true" tabindex="-1"></a><span class="fu">## Testing Your Understanding</span></span>
<span id="cb6-721"><a href="#cb6-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-722"><a href="#cb6-722" aria-hidden="true" tabindex="-1"></a>Let's verify your understanding of thread mapping concepts:</span>
<span id="cb6-723"><a href="#cb6-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-726"><a href="#cb6-726" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb6-727"><a href="#cb6-727" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🧪 Testing Thread Mapping Understanding"</span>)</span>
<span id="cb6-728"><a href="#cb6-728" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb6-729"><a href="#cb6-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-730"><a href="#cb6-730" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_rmsnorm_encoding_creation():</span>
<span id="cb6-731"><a href="#cb6-731" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Test that we can create the RMSNorm encoding."""</span></span>
<span id="cb6-732"><a href="#cb6-732" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb6-733"><a href="#cb6-733" aria-hidden="true" tabindex="-1"></a>        encoding <span class="op">=</span> TileDistributionEncoding(</span>
<span id="cb6-734"><a href="#cb6-734" aria-hidden="true" tabindex="-1"></a>            rs_lengths<span class="op">=</span>[],</span>
<span id="cb6-735"><a href="#cb6-735" aria-hidden="true" tabindex="-1"></a>            hs_lengthss<span class="op">=</span>[[<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span>], [<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span>]],</span>
<span id="cb6-736"><a href="#cb6-736" aria-hidden="true" tabindex="-1"></a>            ps_to_rhss_major<span class="op">=</span>[[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">2</span>]],</span>
<span id="cb6-737"><a href="#cb6-737" aria-hidden="true" tabindex="-1"></a>            ps_to_rhss_minor<span class="op">=</span>[[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>]],</span>
<span id="cb6-738"><a href="#cb6-738" aria-hidden="true" tabindex="-1"></a>            ys_to_rhs_major<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>],</span>
<span id="cb6-739"><a href="#cb6-739" aria-hidden="true" tabindex="-1"></a>            ys_to_rhs_minor<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">3</span>]</span>
<span id="cb6-740"><a href="#cb6-740" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-741"><a href="#cb6-741" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb6-742"><a href="#cb6-742" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb6-743"><a href="#cb6-743" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-744"><a href="#cb6-744" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb6-745"><a href="#cb6-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-746"><a href="#cb6-746" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_thread_organization():</span>
<span id="cb6-747"><a href="#cb6-747" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Test that the thread organization makes sense."""</span></span>
<span id="cb6-748"><a href="#cb6-748" aria-hidden="true" tabindex="-1"></a>    repeat_m, warp_per_block_m, thread_per_warp_m, vector_m <span class="op">=</span> <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span></span>
<span id="cb6-749"><a href="#cb6-749" aria-hidden="true" tabindex="-1"></a>    repeat_n, warp_per_block_n, thread_per_warp_n, vector_n <span class="op">=</span> <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span></span>
<span id="cb6-750"><a href="#cb6-750" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-751"><a href="#cb6-751" aria-hidden="true" tabindex="-1"></a>    threads_per_block <span class="op">=</span> warp_per_block_m <span class="op">*</span> warp_per_block_n <span class="op">*</span> thread_per_warp_m <span class="op">*</span> thread_per_warp_n</span>
<span id="cb6-752"><a href="#cb6-752" aria-hidden="true" tabindex="-1"></a>    expected_threads <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> <span class="dv">2</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>  <span class="co"># 256 threads</span></span>
<span id="cb6-753"><a href="#cb6-753" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-754"><a href="#cb6-754" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> threads_per_block <span class="op">==</span> expected_threads</span>
<span id="cb6-755"><a href="#cb6-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-756"><a href="#cb6-756" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_memory_efficiency():</span>
<span id="cb6-757"><a href="#cb6-757" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Test that vector access is efficient."""</span></span>
<span id="cb6-758"><a href="#cb6-758" aria-hidden="true" tabindex="-1"></a>    vector_m, vector_n <span class="op">=</span> <span class="dv">4</span>, <span class="dv">4</span></span>
<span id="cb6-759"><a href="#cb6-759" aria-hidden="true" tabindex="-1"></a>    elements_per_thread <span class="op">=</span> vector_m <span class="op">*</span> vector_n</span>
<span id="cb6-760"><a href="#cb6-760" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-761"><a href="#cb6-761" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Each thread should handle multiple elements for efficiency</span></span>
<span id="cb6-762"><a href="#cb6-762" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> elements_per_thread <span class="op">&gt;=</span> <span class="dv">4</span></span>
<span id="cb6-763"><a href="#cb6-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-764"><a href="#cb6-764" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_tile_distribution_creation():</span>
<span id="cb6-765"><a href="#cb6-765" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Test that we can create tile distribution from encoding."""</span></span>
<span id="cb6-766"><a href="#cb6-766" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb6-767"><a href="#cb6-767" aria-hidden="true" tabindex="-1"></a>        encoding <span class="op">=</span> TileDistributionEncoding(</span>
<span id="cb6-768"><a href="#cb6-768" aria-hidden="true" tabindex="-1"></a>            rs_lengths<span class="op">=</span>[],</span>
<span id="cb6-769"><a href="#cb6-769" aria-hidden="true" tabindex="-1"></a>            hs_lengthss<span class="op">=</span>[[<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span>], [<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">4</span>]],</span>
<span id="cb6-770"><a href="#cb6-770" aria-hidden="true" tabindex="-1"></a>            ps_to_rhss_major<span class="op">=</span>[[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">2</span>]],</span>
<span id="cb6-771"><a href="#cb6-771" aria-hidden="true" tabindex="-1"></a>            ps_to_rhss_minor<span class="op">=</span>[[<span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">2</span>, <span class="dv">2</span>]],</span>
<span id="cb6-772"><a href="#cb6-772" aria-hidden="true" tabindex="-1"></a>            ys_to_rhs_major<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>],</span>
<span id="cb6-773"><a href="#cb6-773" aria-hidden="true" tabindex="-1"></a>            ys_to_rhs_minor<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">3</span>]</span>
<span id="cb6-774"><a href="#cb6-774" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-775"><a href="#cb6-775" aria-hidden="true" tabindex="-1"></a>        tile_distribution <span class="op">=</span> make_static_tile_distribution(encoding)</span>
<span id="cb6-776"><a href="#cb6-776" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb6-777"><a href="#cb6-777" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb6-778"><a href="#cb6-778" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-779"><a href="#cb6-779" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb6-780"><a href="#cb6-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-781"><a href="#cb6-781" aria-hidden="true" tabindex="-1"></a><span class="co"># Run tests</span></span>
<span id="cb6-782"><a href="#cb6-782" aria-hidden="true" tabindex="-1"></a>tests <span class="op">=</span> [</span>
<span id="cb6-783"><a href="#cb6-783" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"RMSNorm encoding creation"</span>, test_rmsnorm_encoding_creation),</span>
<span id="cb6-784"><a href="#cb6-784" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Thread organization"</span>, test_thread_organization),</span>
<span id="cb6-785"><a href="#cb6-785" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Memory efficiency"</span>, test_memory_efficiency),</span>
<span id="cb6-786"><a href="#cb6-786" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"Tile distribution creation"</span>, test_tile_distribution_creation)</span>
<span id="cb6-787"><a href="#cb6-787" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb6-788"><a href="#cb6-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-789"><a href="#cb6-789" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Running thread mapping tests:"</span>)</span>
<span id="cb6-790"><a href="#cb6-790" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> test_name, test_func <span class="kw">in</span> tests:</span>
<span id="cb6-791"><a href="#cb6-791" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb6-792"><a href="#cb6-792" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> test_func()</span>
<span id="cb6-793"><a href="#cb6-793" aria-hidden="true" tabindex="-1"></a>        status <span class="op">=</span> <span class="st">"✅ PASS"</span> <span class="cf">if</span> result <span class="cf">else</span> <span class="st">"❌ FAIL"</span></span>
<span id="cb6-794"><a href="#cb6-794" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>status<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>test_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-795"><a href="#cb6-795" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb6-796"><a href="#cb6-796" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  ❌ ERROR: </span><span class="sc">{</span>test_name<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-797"><a href="#cb6-797" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-798"><a href="#cb6-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-799"><a href="#cb6-799" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key Takeaways</span></span>
<span id="cb6-800"><a href="#cb6-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-801"><a href="#cb6-801" aria-hidden="true" tabindex="-1"></a>Thread mapping is the crucial bridge between mathematical abstractions and physical hardware execution:</span>
<span id="cb6-802"><a href="#cb6-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-803"><a href="#cb6-803" aria-hidden="true" tabindex="-1"></a>**🎯 Thread Identification:**</span>
<span id="cb6-804"><a href="#cb6-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-805"><a href="#cb6-805" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Hierarchical Organization**: Threads organized in blocks → warps → threads → vectors</span>
<span id="cb6-806"><a href="#cb6-806" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Each level has specific cooperation capabilities</span>
<span id="cb6-807"><a href="#cb6-807" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Hardware provides efficient primitives at each level</span>
<span id="cb6-808"><a href="#cb6-808" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Thread IDs map directly to data regions</span>
<span id="cb6-809"><a href="#cb6-809" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Predictable and efficient execution patterns</span>
<span id="cb6-810"><a href="#cb6-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-811"><a href="#cb6-811" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Data Assignment**: Each thread gets a specific rectangular region</span>
<span id="cb6-812"><a href="#cb6-812" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Work distributed evenly across threads</span>
<span id="cb6-813"><a href="#cb6-813" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Memory access patterns optimized for coalescing</span>
<span id="cb6-814"><a href="#cb6-814" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Vector operations maximize throughput</span>
<span id="cb6-815"><a href="#cb6-815" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Scalable across different hardware configurations</span>
<span id="cb6-816"><a href="#cb6-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-817"><a href="#cb6-817" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Cooperation Patterns**: Threads cooperate at multiple levels</span>
<span id="cb6-818"><a href="#cb6-818" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Warp-level SIMD execution for efficiency</span>
<span id="cb6-819"><a href="#cb6-819" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Block-level shared memory and synchronization</span>
<span id="cb6-820"><a href="#cb6-820" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Vector-level processing for maximum throughput</span>
<span id="cb6-821"><a href="#cb6-821" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>✅ Hierarchical coordination for complex operations</span>
<span id="cb6-822"><a href="#cb6-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-823"><a href="#cb6-823" aria-hidden="true" tabindex="-1"></a>**🚀 Performance Benefits:**</span>
<span id="cb6-824"><a href="#cb6-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-825"><a href="#cb6-825" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Memory Coalescing**: Adjacent threads access adjacent memory for optimal bandwidth</span>
<span id="cb6-826"><a href="#cb6-826" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Cache Efficiency**: Related data loaded together, reducing memory latency</span>
<span id="cb6-827"><a href="#cb6-827" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Vectorization**: Hardware can optimize multiple operations per thread</span>
<span id="cb6-828"><a href="#cb6-828" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Predictable Patterns**: Compile-time optimization of access patterns</span>
<span id="cb6-829"><a href="#cb6-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-830"><a href="#cb6-830" aria-hidden="true" tabindex="-1"></a>**💡 Why This Matters:**</span>
<span id="cb6-831"><a href="#cb6-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-832"><a href="#cb6-832" aria-hidden="true" tabindex="-1"></a>Thread mapping connects all the previous concepts (encodings, transformations, distributions) to actual hardware execution. It's the final piece that makes tile distribution practical for real-world GPU programming.</span>
<span id="cb6-833"><a href="#cb6-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-834"><a href="#cb6-834" aria-hidden="true" tabindex="-1"></a>The RMSNorm example shows how a real operation uses these concepts to achieve optimal performance on modern GPU hardware. Every thread knows exactly what data to process, how to access it efficiently, and how to cooperate with other threads - all determined by the mathematical encoding we started with!</span>
<span id="cb6-835"><a href="#cb6-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-836"><a href="#cb6-836" aria-hidden="true" tabindex="-1"></a>This completes the journey from basic memory concepts to hardware-optimized execution. You now understand the complete tile distribution system from mathematical foundations to practical implementation. </span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script src="font-cleanup.js"></script>




</body></html>