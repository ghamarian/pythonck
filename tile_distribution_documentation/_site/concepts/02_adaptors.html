<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Tensor Adaptors - Chaining Transformations – Tile Distribution Documentation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-038ebe7de1ad581fc619d66ba7f7845b.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-9cae0046c5fab5900eed4751693c39dd.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-038ebe7de1ad581fc619d66ba7f7845b.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-185961ed47a39db2ff9d8581d2d02664.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-1f647ac581ac6b74d75948daead8752e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-185961ed47a39db2ff9d8581d2d02664.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    mermaid.initialize({ 
        startOnLoad: true,
        theme: 'default',
        themeVariables: {
            primaryColor: '#f0f7ff',
            primaryTextColor: '#1e293b',
            primaryBorderColor: '#2563eb',
            lineColor: '#6b7280',
            secondaryColor: '#fef3e2',
            tertiaryColor: '#f0fdf4',
            background: '#ffffff',
            mainBkg: '#f0f7ff',
            secondBkg: '#fef3e2',
            tertiaryBkg: '#f0fdf4',
            primaryTextColor: '#1e293b',
            fontSize: '16px'
        }
    });
});
</script>
<script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">


<link rel="stylesheet" href="../global-font-override.css">
<link rel="stylesheet" href="../diagram-sizing-fixes.css">
</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../concepts/02_tensor_coordinates.html">Transformation Engine</a></li><li class="breadcrumb-item"><a href="../concepts/02_adaptors.html">Tensor Adaptors - Chaining Transformations</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Tile Distribution Documentation</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tile Distribution Documentation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/00_introduction_motivation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction and Motivation - Why Tile Distribution Matters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/01_buffer_view.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Buffer Views - Raw Memory Access</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/01_tensor_view.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tensor Views - Multi-Dimensional Structure</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Transformation Engine</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_tensor_coordinates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Coordinates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_transforms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Individual Transforms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_adaptors.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Tensor Adaptors - Chaining Transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_descriptors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tensor Descriptors - Complete Tensor Specifications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_convolution_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolution Implementation with Tensor Descriptors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/02_coordinate_movement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Coordinate Operations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Distribution API</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/03_tile_distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tile Distribution - The Core API</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/03_tile_window.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tile Window - Data Access Gateway</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/03_sweep_tile.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sweep Tile - Elegant Iteration</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Coordinate Systems</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/04_coordinate_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coordinate Systems - The Mathematical Foundation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Implementation Deep Dive</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/05_encoding_internals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Encoding Internals - The Internal Machinery</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/05_static_distributed_tensor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Static Distributed Tensor - Thread-Local Data Containers</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Thread Mapping</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../concepts/06_thread_mapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Thread Mapping - Connecting to Hardware</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#tensoradaptor-basics" id="toc-tensoradaptor-basics" class="nav-link" data-scroll-target="#tensoradaptor-basics">TensorAdaptor Basics</a></li>
  <li><a href="#transpose-adaptor-dimension-reordering" id="toc-transpose-adaptor-dimension-reordering" class="nav-link" data-scroll-target="#transpose-adaptor-dimension-reordering">Transpose Adaptor: Dimension Reordering</a>
  <ul class="collapse">
  <li><a href="#c-implementation" id="toc-c-implementation" class="nav-link" data-scroll-target="#c-implementation">C++ Implementation</a></li>
  </ul></li>
  <li><a href="#single-stage-adaptors-custom-transform-chains" id="toc-single-stage-adaptors-custom-transform-chains" class="nav-link" data-scroll-target="#single-stage-adaptors-custom-transform-chains">Single-Stage Adaptors: Custom Transform Chains</a>
  <ul class="collapse">
  <li><a href="#c-implementation-1" id="toc-c-implementation-1" class="nav-link" data-scroll-target="#c-implementation-1">C++ Implementation</a></li>
  </ul></li>
  <li><a href="#chaining-adaptors-building-complex-transformations" id="toc-chaining-adaptors-building-complex-transformations" class="nav-link" data-scroll-target="#chaining-adaptors-building-complex-transformations">Chaining Adaptors: Building Complex Transformations</a>
  <ul class="collapse">
  <li><a href="#c-implementation-2" id="toc-c-implementation-2" class="nav-link" data-scroll-target="#c-implementation-2">C++ Implementation</a></li>
  </ul></li>
  <li><a href="#transform-addition-extending-existing-adaptors" id="toc-transform-addition-extending-existing-adaptors" class="nav-link" data-scroll-target="#transform-addition-extending-existing-adaptors">Transform Addition: Extending Existing Adaptors</a>
  <ul class="collapse">
  <li><a href="#c-implementation-3" id="toc-c-implementation-3" class="nav-link" data-scroll-target="#c-implementation-3">C++ Implementation</a></li>
  </ul></li>
  <li><a href="#advanced-c-patterns" id="toc-advanced-c-patterns" class="nav-link" data-scroll-target="#advanced-c-patterns">Advanced C++ Patterns</a>
  <ul class="collapse">
  <li><a href="#complex-nested-transforms-in-c" id="toc-complex-nested-transforms-in-c" class="nav-link" data-scroll-target="#complex-nested-transforms-in-c">Complex Nested Transforms in C++</a></li>
  <li><a href="#gpu-memory-layout-example" id="toc-gpu-memory-layout-example" class="nav-link" data-scroll-target="#gpu-memory-layout-example">GPU Memory Layout Example</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#breakthrough-discovery" id="toc-breakthrough-discovery" class="nav-link" data-scroll-target="#breakthrough-discovery">Breakthrough Discovery</a></li>
  <li><a href="#key-c-patterns-in-composable-kernel" id="toc-key-c-patterns-in-composable-kernel" class="nav-link" data-scroll-target="#key-c-patterns-in-composable-kernel">Key C++ Patterns in Composable Kernel</a></li>
  <li><a href="#common-c-transform-chains" id="toc-common-c-transform-chains" class="nav-link" data-scroll-target="#common-c-transform-chains">Common C++ Transform Chains</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../concepts/02_tensor_coordinates.html">Transformation Engine</a></li><li class="breadcrumb-item"><a href="../concepts/02_adaptors.html">Tensor Adaptors - Chaining Transformations</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Tensor Adaptors - Chaining Transformations</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>While individual transforms are powerful, TensorAdaptors let us chain multiple transforms together to create complex coordinate transformations. Think of adaptors as transformation pipelines that can reshape, reorder, and restructure tensors in sophisticated ways.</p>
<p>TensorAdaptors are the bridge between individual transforms and the high-level tensor operations you’ll use in real applications.</p>
<div>
<div id="pyodide-1" class="exercise-cell">

</div>
<script type="pyodide-1-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOnRydWUsImVjaG8iOmZhbHNlLCJlZGl0IjpmYWxzZSwiZXZhbCI6dHJ1ZSwib3V0cHV0IjpmYWxzZX0sImNvZGUiOiJcbiMgQXV0by1pbnN0YWxsIHB5dGhvbmNrIHBhY2thZ2VcbmltcG9ydCBtaWNyb3BpcFxuYXdhaXQgbWljcm9waXAuaW5zdGFsbChcImh0dHBzOi8vcmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbS9naGFtYXJpYW4vcHl0aG9uY2svbWFzdGVyL2RvY3VtZW50YXRpb24vcHl0aG9uY2stMC4xLjAtcHkzLW5vbmUtYW55LndobFwiKSJ9
</script>
</div>
</section>
<section id="tensoradaptor-basics" class="level2">
<h2 class="anchored" data-anchor-id="tensoradaptor-basics">TensorAdaptor Basics</h2>
<p>Let’s start by understanding what a TensorAdaptor is and how it works:</p>
<div class="mermaid">
graph TB
    subgraph "Adaptor Composition"
        subgraph "Single Transform"
            T1["Transform<br>(e.g., Transpose)"]
            I1["Input Coords<br>[0,1,2]"]
            O1["Output Coords<br>[2,0,1]"]
        end
        
        subgraph "Chained Transforms"
            T2A["Transform A<br>(e.g., Merge)"]
            T2B["Transform B<br>(e.g., Pad)"]
            I2["Input<br>2D"]
            M2["Intermediate<br>1D"]
            O2["Output<br>1D Padded"]
        end
        
        subgraph "Complex Pipeline"
            T3A["Transpose"]
            T3B["Unmerge"]
            T3C["Pad"]
            I3["Input"]
            O3["Output"]
        end
    end
    
    I1 --&gt; T1
    T1 --&gt; O1
    
    I2 --&gt; T2A
    T2A --&gt; M2
    M2 --&gt; T2B
    T2B --&gt; O2
    
    I3 --&gt; T3A
    T3A --&gt; T3B
    T3B --&gt; T3C
    T3C --&gt; O3
    
    style T1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style T2A fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style T2B fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style T3A fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style T3B fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style T3C fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
</div>
<div>
<div id="pyodide-2" class="exercise-cell">

</div>
<script type="pyodide-2-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOmZhbHNlLCJlY2hvIjp0cnVlLCJlZGl0Ijp0cnVlLCJldmFsIjp0cnVlLCJvdXRwdXQiOnRydWV9LCJjb2RlIjoiXG4jIEltcG9ydCByZXF1aXJlZCBtb2R1bGVzXG5mcm9tIHB5dGVuc29yLnRlbnNvcl9hZGFwdG9yIGltcG9ydCAoXG4gICAgbWFrZV9zaW5nbGVfc3RhZ2VfdGVuc29yX2FkYXB0b3IsXG4gICAgdHJhbnNmb3JtX3RlbnNvcl9hZGFwdG9yLFxuICAgIGNoYWluX3RlbnNvcl9hZGFwdG9ycyxcbiAgICBjaGFpbl90ZW5zb3JfYWRhcHRvcnNfbXVsdGksXG4gICAgbWFrZV9pZGVudGl0eV9hZGFwdG9yLFxuICAgIG1ha2VfdHJhbnNwb3NlX2FkYXB0b3JcbilcbmZyb20gcHl0ZW5zb3IudGVuc29yX2Rlc2NyaXB0b3IgaW1wb3J0IChcbiAgICBUZW5zb3JBZGFwdG9yLFxuICAgIFBhc3NUaHJvdWdoVHJhbnNmb3JtLFxuICAgIFBhZFRyYW5zZm9ybSxcbiAgICBNZXJnZVRyYW5zZm9ybSxcbiAgICBSZXBsaWNhdGVUcmFuc2Zvcm0sXG4gICAgRW1iZWRUcmFuc2Zvcm0sXG4gICAgVW5tZXJnZVRyYW5zZm9ybSxcbiAgICB0cmFuc2Zvcm1fdGVuc29yX2Rlc2NyaXB0b3IsXG4gICAgbWFrZV9uYWl2ZV90ZW5zb3JfZGVzY3JpcHRvcl9wYWNrZWQsXG4gICAgbWFrZV9tZXJnZV90cmFuc2Zvcm0sXG4gICAgbWFrZV9wYXNzX3Rocm91Z2hfdHJhbnNmb3JtLFxuICAgIG1ha2VfdW5tZXJnZV90cmFuc2Zvcm0sXG4gICAgbWFrZV90dXBsZSxcbiAgICBudW1iZXIsXG4gICAgc2VxdWVuY2VcbilcbmZyb20gcHl0ZW5zb3IudGVuc29yX2Nvb3JkaW5hdGUgaW1wb3J0IE11bHRpSW5kZXhcbmltcG9ydCBudW1weSBhcyBucFxuXG5wcmludChcIvCflJcgVGVuc29yQWRhcHRvciBPdmVydmlld1wiKVxucHJpbnQoXCItLVwiICogNDApXG5wcmludChcIiAgVGVuc29yQWRhcHRvciBjaGFpbnMgbXVsdGlwbGUgdHJhbnNmb3JtcyB0b2dldGhlclwiKVxucHJpbnQoXCIgIEVhY2ggYWRhcHRvciBoYXM6XCIpXG5wcmludChcIiAgICDigKIgdHJhbnNmb3JtczogTGlzdCBvZiBpbmRpdmlkdWFsIHRyYW5zZm9ybXNcIilcbnByaW50KFwiICAgIOKAoiBsb3dlcl9kaW1lbnNpb25faGlkZGVuX2lkc3M6IEhvdyB0cmFuc2Zvcm1zIGNvbm5lY3RcIilcbnByaW50KFwiICAgIOKAoiB1cHBlcl9kaW1lbnNpb25faGlkZGVuX2lkc3M6IEhpZGRlbiBkaW1lbnNpb24gbWFwcGluZ3NcIilcbnByaW50KFwiICAgIOKAoiBib3R0b21fZGltZW5zaW9uX2hpZGRlbl9pZHM6IElucHV0IGRpbWVuc2lvbnNcIilcbnByaW50KFwiICAgIOKAoiB0b3BfZGltZW5zaW9uX2hpZGRlbl9pZHM6IE91dHB1dCBkaW1lbnNpb25zXCIpIn0=
</script>
</div>
<p>The most important method of a TensorAdaptor is <code>calculate_bottom_index</code>, which calculates the lower index from the upper index. It achives this by applying the transforms in reverse order and calling <code>calculate_lower_index</code> on each transform.</p>
<p>Let’s go over some of the utility functions for creating tensor adaptors and see how they work in real life. We start with one of the simplest one.</p>
</section>
<section id="transpose-adaptor-dimension-reordering" class="level2">
<h2 class="anchored" data-anchor-id="transpose-adaptor-dimension-reordering">Transpose Adaptor: Dimension Reordering</h2>
<p>The transpose adaptor reorders tensor dimensions according to a permutation pattern.</p>
<div>
<div id="pyodide-3" class="exercise-cell">

</div>
<script type="pyodide-3-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOmZhbHNlLCJlY2hvIjp0cnVlLCJlZGl0Ijp0cnVlLCJldmFsIjp0cnVlLCJvdXRwdXQiOnRydWV9LCJjb2RlIjoiXG5wcmludChcIjLvuI/ig6MgVHJhbnNwb3NlIEFkYXB0b3JcIilcbnByaW50KFwiLS1cIiAqIDQwKVxuXG4jIENyZWF0ZSB0cmFuc3Bvc2UgYWRhcHRvcjogWzAsIDEsIDJdIOKGkiBbMiwgMCwgMV1cbnRyYW5zcG9zZV9hZGFwdG9yID0gbWFrZV90cmFuc3Bvc2VfYWRhcHRvcigzLCBbMiwgMCwgMV0pXG5cbnByaW50KGZcIiAgUGVybXV0YXRpb246IFsyLCAwLCAxXSAoZGltZW5zaW9uIDDihpIyLCAx4oaSMCwgMuKGkjEpXCIpXG5wcmludChmXCIgIE51bWJlciBvZiB0cmFuc2Zvcm1zOiB7dHJhbnNwb3NlX2FkYXB0b3IuZ2V0X251bV9vZl90cmFuc2Zvcm0oKX1cIilcbnByaW50KGZcIiAgQm90dG9tIGRpbWVuc2lvbnM6IHt0cmFuc3Bvc2VfYWRhcHRvci5nZXRfbnVtX29mX2JvdHRvbV9kaW1lbnNpb24oKX1cIilcbnByaW50KGZcIiAgVG9wIGRpbWVuc2lvbnM6IHt0cmFuc3Bvc2VfYWRhcHRvci5nZXRfbnVtX29mX3RvcF9kaW1lbnNpb24oKX1cIilcblxuIyBUZXN0IGNvb3JkaW5hdGUgdHJhbnNmb3JtYXRpb25cbnRlc3RfY29vcmRzID0gW1swLCAxLCAyXSwgWzEsIDAsIDJdLCBbMiwgMSwgMF1dXG5wcmludChcIlxcbiAgVHJhbnNwb3NlIHRyYW5zZm9ybWF0aW9uIHRlc3Q6XCIpXG5mb3IgY29vcmRfbGlzdCBpbiB0ZXN0X2Nvb3JkczpcbiAgICB0b3BfY29vcmQgPSBNdWx0aUluZGV4KDMsIGNvb3JkX2xpc3QpXG4gICAgYm90dG9tX2Nvb3JkID0gdHJhbnNwb3NlX2FkYXB0b3IuY2FsY3VsYXRlX2JvdHRvbV9pbmRleCh0b3BfY29vcmQpXG4gICAgcHJpbnQoZlwiICAgIHtjb29yZF9saXN0fSDihpIge2JvdHRvbV9jb29yZC50b19saXN0KCl9XCIpIn0=
</script>
</div>
<section id="c-implementation" class="level3">
<h3 class="anchored" data-anchor-id="c-implementation">C++ Implementation</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - create transpose adaptor</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">// Transpose adaptor example: [0, 1, 2] → [2, 0, 1]</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> transpose_adaptor <span class="op">=</span> make_identity_tensor_adaptor<span class="op">&lt;</span><span class="dv">3</span><span class="op">&gt;();</span>  <span class="co">// Start with identity</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">// Apply transpose using transform_tensor_adaptor</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">// In CK, transpose is typically done through tensor descriptor transformations</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> transposed_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    original_desc<span class="op">,</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_pass_through_transform<span class="op">(</span>original_desc<span class="op">.</span>get_length<span class="op">(</span><span class="dv">2</span><span class="op">)),</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>original_desc<span class="op">.</span>get_length<span class="op">(</span><span class="dv">0</span><span class="op">)),</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>original_desc<span class="op">.</span>get_length<span class="op">(</span><span class="dv">1</span><span class="op">))),</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// old dims</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;{})</span>   <span class="co">// new dims</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">// Alternative: Direct coordinate transformation</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>multi_index<span class="op">&lt;</span><span class="dv">3</span><span class="op">&gt;</span> top_coord<span class="op">{</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">};</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">// After transpose [2, 0, 1]: coord becomes [2, 0, 1]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="single-stage-adaptors-custom-transform-chains" class="level2">
<h2 class="anchored" data-anchor-id="single-stage-adaptors-custom-transform-chains">Single-Stage Adaptors: Custom Transform Chains</h2>
<p>You can create custom adaptors by specifying exactly which transforms to use and how they connect, the API for that is called <code>make_single_stage_tensor_adaptor</code>:</p>
<div>
<div id="pyodide-4" class="exercise-cell">

</div>
<script type="pyodide-4-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOmZhbHNlLCJlY2hvIjp0cnVlLCJlZGl0Ijp0cnVlLCJldmFsIjp0cnVlLCJvdXRwdXQiOnRydWV9LCJjb2RlIjoiXG5wcmludChcIjPvuI/ig6MgU2luZ2xlLVN0YWdlIEN1c3RvbSBBZGFwdG9yXCIpXG5wcmludChcIi0tXCIgKiA0MClcblxuIyBDcmVhdGUgYWRhcHRvciB0aGF0IHNwbGl0cyAxRCBjb29yZGluYXRlcyB0byAyRFxuIyBOb3RlOiBNZXJnZVRyYW5zZm9ybSBoYXMgMUQgdXBwZXIgKHRvcCkgYW5kIDJEIGxvd2VyIChib3R0b20pXG5tZXJnZV9hZGFwdG9yID0gbWFrZV9zaW5nbGVfc3RhZ2VfdGVuc29yX2FkYXB0b3IoXG4gICAgdHJhbnNmb3Jtcz1bTWVyZ2VUcmFuc2Zvcm0oWzIsIDNdKV0sXG4gICAgbG93ZXJfZGltZW5zaW9uX29sZF90b3BfaWRzcz1bWzAsIDFdXSwgICMgQm90dG9tOiAyRCBkaW1lbnNpb25zIDAgYW5kIDFcbiAgICB1cHBlcl9kaW1lbnNpb25fbmV3X3RvcF9pZHNzPVtbMF1dICAgICAgICMgVG9wOiAxRCBkaW1lbnNpb24gMCAobWVyZ2VkKVxuKVxuXG5wcmludChmXCIgIFRyYW5zZm9ybTogTWVyZ2VUcmFuc2Zvcm0oWzIsIDNdKSAtIHNwbGl0cyAxRCB0byAyRFwiKVxucHJpbnQoZlwiICBCb3R0b20gZGltZW5zaW9uczoge21lcmdlX2FkYXB0b3IuZ2V0X251bV9vZl9ib3R0b21fZGltZW5zaW9uKCl9XCIpXG5wcmludChmXCIgIFRvcCBkaW1lbnNpb25zOiB7bWVyZ2VfYWRhcHRvci5nZXRfbnVtX29mX3RvcF9kaW1lbnNpb24oKX1cIilcblxuIyBUZXN0IG1lcmdlIHRyYW5zZm9ybWF0aW9uOiAxRCB0b3Ag4oaSIDJEIGJvdHRvbVxudGVzdF9pbmRpY2VzID0gWzAsIDIsIDMsIDVdXG5wcmludChcIlxcbiAgTWVyZ2UgdHJhbnNmb3JtYXRpb24gdGVzdCAoMUQg4oaSIDJEKTpcIilcbmZvciBpZHggaW4gdGVzdF9pbmRpY2VzOlxuICAgIHRvcF9jb29yZCA9IE11bHRpSW5kZXgoMSwgW2lkeF0pICAjIDFEIHRvcCBjb29yZGluYXRlXG4gICAgYm90dG9tX2Nvb3JkID0gbWVyZ2VfYWRhcHRvci5jYWxjdWxhdGVfYm90dG9tX2luZGV4KHRvcF9jb29yZClcbiAgICBleHBlY3RlZF9yb3cgPSBpZHggLy8gM1xuICAgIGV4cGVjdGVkX2NvbCA9IGlkeCAlIDNcbiAgICBwcmludChmXCIgICAgW3tpZHh9XSDihpIge2JvdHRvbV9jb29yZC50b19saXN0KCl9IChleHBlY3RlZDogW3tleHBlY3RlZF9yb3d9LCB7ZXhwZWN0ZWRfY29sfV0pXCIpIn0=
</script>
</div>
<section id="c-implementation-1" class="level3">
<h3 class="anchored" data-anchor-id="c-implementation-1">C++ Implementation</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - create single-stage tensor adaptor</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">// Note: In CK, adaptors are typically created through tensor descriptors</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">// Create a descriptor that merges 2x3 dimensions into single dimension</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> base_desc <span class="op">=</span> make_naive_tensor_descriptor_packed<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">));</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">// Apply merge transform</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> merged_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    base_desc<span class="op">,</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">))),</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// merge dims 0,1</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{})</span>      <span class="co">// to single dim 0</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">// The adaptor is embedded in the descriptor</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">// To use it:</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>multi_index<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;</span> top_coord<span class="op">{</span><span class="dv">5</span><span class="op">};</span>  <span class="co">// 1D coordinate</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">// This internally calculates: row = 5/3 = 1, col = 5%3 = 2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now that we saw how we can create an adaptor, let’s see how we can combine a few of them together.</p>
</section>
</section>
<section id="chaining-adaptors-building-complex-transformations" class="level2">
<h2 class="anchored" data-anchor-id="chaining-adaptors-building-complex-transformations">Chaining Adaptors: Building Complex Transformations</h2>
<p>The real power comes from chaining multiple adaptors together to create sophisticated transformations. Below we try some trivial example of combining merge and unmerge just to show how these transformations combine.</p>
<div class="mermaid">
graph LR
    subgraph "Adaptor Chaining Flow"
        subgraph "Adaptor 1"
            A1I["Bottom Dims<br>[0,1]"]
            A1T["Transform:<br>Merge[2,3]"]
            A1O["Top Dims<br>[0]"]
        end
        
        subgraph "Adaptor 2"
            A2I["Bottom Dims<br>[0]"]
            A2T["Transform:<br>Unmerge[2,3]"]
            A2O["Top Dims<br>[0,1]"]
        end
        
        subgraph "Chained Result"
            CI["Input 2D<br>Bottom[0,1]"]
            CO["Output 2D<br>Top[0,1]"]
        end
    end
    
    A1I --&gt; A1T
    A1T --&gt; A1O
    A1O --&gt; A2I
    A2I --&gt; A2T
    A2T --&gt; A2O
    
    CI --&gt; A1I
    A2O --&gt; CO
    
    style A1T fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style A2T fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style CI fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    style CO fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
</div>
<div>
<div id="pyodide-5" class="exercise-cell">

</div>
<script type="pyodide-5-contents">
eyJhdHRyIjp7ImF1dG9ydW4iOmZhbHNlLCJlY2hvIjp0cnVlLCJlZGl0Ijp0cnVlLCJldmFsIjp0cnVlLCJvdXRwdXQiOnRydWV9LCJjb2RlIjoiXG5wcmludChcIjTvuI/ig6MgQ2hhaW5pbmcgQWRhcHRvcnNcIilcbnByaW50KFwiLS1cIiAqIDQwKVxuXG4jIENyZWF0ZSBmaXJzdCBhZGFwdG9yOiAxRCDihpIgMkQgKG1lcmdlIHNwbGl0cylcbmFkYXB0b3JfbWVyZ2UgPSBtYWtlX3NpbmdsZV9zdGFnZV90ZW5zb3JfYWRhcHRvcihcbiAgICB0cmFuc2Zvcm1zPVtNZXJnZVRyYW5zZm9ybShbMiwgM10pXSxcbiAgICBsb3dlcl9kaW1lbnNpb25fb2xkX3RvcF9pZHNzPVtbMCwgMV1dLFxuICAgIHVwcGVyX2RpbWVuc2lvbl9uZXdfdG9wX2lkc3M9W1swXV1cbilcblxuIyBDcmVhdGUgc2Vjb25kIGFkYXB0b3I6IDJEIOKGkiAxRCAodW5tZXJnZSBjb21iaW5lcylcbmFkYXB0b3JfdW5tZXJnZSA9IG1ha2Vfc2luZ2xlX3N0YWdlX3RlbnNvcl9hZGFwdG9yKFxuICAgIHRyYW5zZm9ybXM9W1VubWVyZ2VUcmFuc2Zvcm0oWzIsIDNdKV0sXG4gICAgbG93ZXJfZGltZW5zaW9uX29sZF90b3BfaWRzcz1bWzBdXSxcbiAgICB1cHBlcl9kaW1lbnNpb25fbmV3X3RvcF9pZHNzPVtbMCwgMV1dXG4pXG5cbiMgQ2hhaW4gdGhlbSB0b2dldGhlciAoc2hvdWxkIGJlIGlkZW50aXR5IG92ZXJhbGwpXG5jaGFpbmVkX2FkYXB0b3IgPSBjaGFpbl90ZW5zb3JfYWRhcHRvcnMoYWRhcHRvcl9tZXJnZSwgYWRhcHRvcl91bm1lcmdlKVxuXG5wcmludChmXCIgIENoYWluOiAxRCDihpIgMkQg4oaSIDFEIChidXQgYWN0dWFsbHkgcmVzdWx0cyBpbiAyRCDihpIgMkQpXCIpXG5wcmludChmXCIgIE51bWJlciBvZiB0cmFuc2Zvcm1zOiB7Y2hhaW5lZF9hZGFwdG9yLmdldF9udW1fb2ZfdHJhbnNmb3JtKCl9XCIpXG5wcmludChmXCIgIEJvdHRvbSBkaW1lbnNpb25zOiB7Y2hhaW5lZF9hZGFwdG9yLmdldF9udW1fb2ZfYm90dG9tX2RpbWVuc2lvbigpfVwiKVxucHJpbnQoZlwiICBUb3AgZGltZW5zaW9uczoge2NoYWluZWRfYWRhcHRvci5nZXRfbnVtX29mX3RvcF9kaW1lbnNpb24oKX1cIilcblxuIyBUZXN0IHRoZSBjaGFpbmVkIHRyYW5zZm9ybWF0aW9uIChzaG91bGQgYmUgaWRlbnRpdHkpXG50ZXN0X2Nvb3JkcyA9IFtbMCwgMF0sIFswLCAyXSwgWzEsIDBdLCBbMSwgMl1dXG5wcmludChcIlxcbiAgQ2hhaW5lZCB0cmFuc2Zvcm1hdGlvbiB0ZXN0IChzaG91bGQgYmUgaWRlbnRpdHkpOlwiKVxuZm9yIGNvb3JkX2xpc3QgaW4gdGVzdF9jb29yZHM6XG4gICAgdG9wX2Nvb3JkID0gTXVsdGlJbmRleCgyLCBjb29yZF9saXN0KSAgIyAyRCBpbnB1dFxuICAgIGJvdHRvbV9jb29yZCA9IGNoYWluZWRfYWRhcHRvci5jYWxjdWxhdGVfYm90dG9tX2luZGV4KHRvcF9jb29yZClcbiAgICBwcmludChmXCIgICAge2Nvb3JkX2xpc3R9IOKGkiB7Ym90dG9tX2Nvb3JkLnRvX2xpc3QoKX1cIikifQ==
</script>
</div>
<section id="c-implementation-2" class="level3">
<h3 class="anchored" data-anchor-id="c-implementation-2">C++ Implementation</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - chaining adaptors through descriptors</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">// Start with a 2D descriptor</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> desc1 <span class="op">=</span> make_naive_tensor_descriptor_packed<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">));</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">// First transformation: merge 2D to 1D</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> merged_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    desc1<span class="op">,</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">))),</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// merge dims 0,1</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{})</span>      <span class="co">// to dim 0</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">// Second transformation: unmerge 1D back to 2D</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> final_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    merged_desc<span class="op">,</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">))),</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{}),</span>     <span class="co">// from dim 0</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{})</span>   <span class="co">// to dims 0,1</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co">// The chained transformation is embedded in final_desc</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">// Result should be identity transformation</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="transform-addition-extending-existing-adaptors" class="level2">
<h2 class="anchored" data-anchor-id="transform-addition-extending-existing-adaptors">Transform Addition: Extending Existing Adaptors</h2>
<p>You can add new transforms to existing adaptors using <code>transform_tensor_adaptor</code>. <strong>Important</strong>: The <code>new_upper_dimension_new_top_idss</code> parameter controls the <strong>final output dimensions</strong> of the adaptor.</p>
<div>
<div id="pyodide-6" class="exercise-cell">

</div>
<script type="pyodide-6-contents">
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
</script>
</div>
<section id="c-implementation-3" class="level3">
<h3 class="anchored" data-anchor-id="c-implementation-3">C++ Implementation</h3>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - transform tensor adaptor pattern</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">// Start with transposed descriptor</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> base_desc <span class="op">=</span> make_naive_tensor_descriptor<span class="op">(</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span><span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">),</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span><span class="dv">1</span><span class="op">,</span> <span class="dv">3</span><span class="op">)</span>   <span class="co">// transposed strides</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">// Add padding to both dimensions</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> padded_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    base_desc<span class="op">,</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_pad_transform<span class="op">(</span><span class="dv">3</span><span class="op">,</span> <span class="dv">1</span><span class="op">,</span> <span class="dv">1</span><span class="op">),</span>   <span class="co">// pad dim 0: 3 → 5</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>               make_pad_transform<span class="op">(</span><span class="dv">4</span><span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="dv">0</span><span class="op">)),</span>   <span class="co">// keep dim 1: 4 → 4</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// input dims</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span>   <span class="co">// output dims (keep 2D)</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">// Access pattern</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>multi_index<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;</span> padded_coord<span class="op">{</span><span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">};</span>  <span class="co">// In padded space</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co">// Internally calculates: unpadded = [1-1, 2] = [0, 2]</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co">// Then applies transpose strides</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="advanced-c-patterns" class="level2">
<h2 class="anchored" data-anchor-id="advanced-c-patterns">Advanced C++ Patterns</h2>
<section id="complex-nested-transforms-in-c" class="level3">
<h3 class="anchored" data-anchor-id="complex-nested-transforms-in-c">Complex Nested Transforms in C++</h3>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - complex nested transform patterns</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">// Example: 4D tensor with complex transformations</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">// Shape: [A, B, C, D] with various transforms</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">// 1. Create base descriptor</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> base_desc <span class="op">=</span> make_naive_tensor_descriptor_packed<span class="op">(</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>A<span class="op">,</span> B<span class="op">,</span> C<span class="op">,</span> D<span class="op">)</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">// 2. Apply multiple transformations</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">// First: merge first 3 dimensions</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> step1_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    base_desc<span class="op">,</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span>A<span class="op">,</span> B<span class="op">,</span> C<span class="op">)),</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>D<span class="op">)),</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">3</span><span class="op">&gt;{}),</span>  <span class="co">// input mapping</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span>         <span class="co">// output: 2D</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">// 3. Then unmerge back but with different grouping</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> step2_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    step1_desc<span class="op">,</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span>A<span class="op">*</span>B<span class="op">,</span> C<span class="op">)),</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>D<span class="op">)),</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>        <span class="co">// from 2D</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;{})</span>      <span class="co">// to 3D</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co">// The adaptor chain is embedded in the descriptors</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="co">// CK optimizes these at compile time</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="gpu-memory-layout-example" class="level3">
<h3 class="anchored" data-anchor-id="gpu-memory-layout-example">GPU Memory Layout Example</h3>
<div class="sourceCode" id="cb6"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - typical GPU block descriptor pattern</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">// Create descriptor for thread block tile: 64x64</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">// With 8x8 vector loads per thread</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> BlockM <span class="op">=</span> <span class="dv">64</span><span class="op">;</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> BlockN <span class="op">=</span> <span class="dv">64</span><span class="op">;</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> VectorM <span class="op">=</span> <span class="dv">8</span><span class="op">;</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> VectorN <span class="op">=</span> <span class="dv">8</span><span class="op">;</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">// Thread arrangement: 8x8 threads</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> ThreadM <span class="op">=</span> BlockM <span class="op">/</span> VectorM<span class="op">;</span>  <span class="co">// 8</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> ThreadN <span class="op">=</span> BlockN <span class="op">/</span> VectorN<span class="op">;</span>  <span class="co">// 8</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">// Create block descriptor with proper layout</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> block_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    make_naive_tensor_descriptor_packed<span class="op">(</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>number<span class="op">&lt;</span>BlockM<span class="op">&gt;{},</span> number<span class="op">&lt;</span>BlockN<span class="op">&gt;{})</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">),</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>            number<span class="op">&lt;</span>ThreadM<span class="op">&gt;{},</span> number<span class="op">&lt;</span>VectorM<span class="op">&gt;{}</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="op">)),</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>            number<span class="op">&lt;</span>ThreadN<span class="op">&gt;{},</span> number<span class="op">&lt;</span>VectorN<span class="op">&gt;{}</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="op">))</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="op">),</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>           <span class="co">// from 2D</span></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">,</span> <span class="dv">3</span><span class="op">&gt;{})</span>     <span class="co">// to 4D: [TM,TN,VM,VN]</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="co">// This creates the layout:</span></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co">// - Dimension 0,1: Thread indices</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co">// - Dimension 2,3: Vector indices within thread</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="co">// Enables coalesced memory access on GPU</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>TensorAdaptors are the coordination layer that makes complex tensor operations possible:</p>
<ul>
<li><strong>Identity Adaptor</strong>: Starting point for building transformations</li>
<li><strong>Transpose Adaptor</strong>: Dimension reordering with permutation patterns</li>
<li><strong>Single-Stage Adaptors</strong>: Custom transform chains with precise control</li>
<li><strong>Chained Adaptors</strong>: Complex multi-stage transformation pipelines</li>
<li><strong>Transform Addition</strong>: Extending existing adaptors with new transforms</li>
<li><strong>Advanced Examples</strong>: Complex nested transforms with flattening behavior</li>
<li><strong>GPU Block Descriptors</strong>: Real-world GPU memory layout patterns</li>
<li><strong>C++ Equivalents</strong>: <strong>True working equivalent</strong> of complex nested C++ transforms</li>
</ul>
<p>Key concepts: - <strong>Bottom/Top Dimensions</strong>: Input and output coordinate spaces - <strong>Hidden Dimensions</strong>: Internal coordinate mappings between transforms - <strong>Transform Chains</strong>: Sequential application of multiple transforms - <strong>Coordinate Transformation</strong>: Bidirectional mapping between coordinate spaces - <strong>Nested Transforms</strong>: Complex multi-level transformation hierarchies</p>
<section id="breakthrough-discovery" class="level3">
<h3 class="anchored" data-anchor-id="breakthrough-discovery">Breakthrough Discovery</h3>
<p>We successfully created the <strong>true C++ equivalent</strong> of complex nested transforms:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># C++ nested transform equivalent</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>cpp_equivalent <span class="op">=</span> make_single_stage_tensor_adaptor(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    transforms<span class="op">=</span>[</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        UnmergeTransform([A, B, C]),  <span class="co"># Converts 3D (A,B,C) to 1D linear  </span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        PassThroughTransform(D)       <span class="co"># Passes through D dimension</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    lower_dimension_old_top_idss<span class="op">=</span>[[<span class="dv">0</span>], [<span class="dv">1</span>]],          <span class="co"># Transform inputs</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    upper_dimension_new_top_idss<span class="op">=</span>[[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>]]     <span class="co"># Transform outputs</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Key insights:</strong> - <strong>Transform direction</strong>: Names refer to lower→higher, but <code>calculate_lower_index()</code> goes higher→lower - <strong>UnmergeTransform</strong>: Converts multi-D to linear when used with <code>calculate_lower_index()</code> - <strong>Parameter mapping</strong>: Controls the coordinate flow between dimensions - <strong>Mathematical equivalence</strong>: Exact same results as C++ nested structure</p>
<p>TensorAdaptors bridge the gap between low-level transforms and high-level tensor operations, providing the flexibility to create sophisticated data layouts and access patterns that are essential for efficient GPU computing.</p>
</section>
<section id="key-c-patterns-in-composable-kernel" class="level3">
<h3 class="anchored" data-anchor-id="key-c-patterns-in-composable-kernel">Key C++ Patterns in Composable Kernel</h3>
<ol type="1">
<li><strong>Descriptor-Based Adaptors</strong>: In CK, adaptors are typically embedded within tensor descriptors rather than created separately</li>
<li><strong>Compile-Time Optimization</strong>: All transformations are resolved at compile time for zero overhead</li>
<li><strong>Type Safety</strong>: Template metaprogramming ensures coordinate transformations are type-safe</li>
<li><strong>GPU Optimization</strong>: Transform chains are designed for efficient GPU memory access patterns</li>
</ol>
</section>
<section id="common-c-transform-chains" class="level3">
<h3 class="anchored" data-anchor-id="common-c-transform-chains">Common C++ Transform Chains</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Padding for convolution</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> padded <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    input<span class="op">,</span> </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_pad_transform<span class="op">(</span>H<span class="op">,</span> pad_h<span class="op">,</span> pad_h<span class="op">),</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>               make_pad_transform<span class="op">(</span>W<span class="op">,</span> pad_w<span class="op">,</span> pad_w<span class="op">)),</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">// Dimension merging for GEMM</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> merged <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    input<span class="op">,</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span>M<span class="op">,</span> K<span class="op">))),</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}),</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{})</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co">// Broadcasting for elementwise ops</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> broadcast <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    scalar<span class="op">,</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_replicate_transform<span class="op">(</span>make_tuple<span class="op">(</span>M<span class="op">,</span> N<span class="op">))),</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;&gt;{}),</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{})</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Next, we’ll see how TensorAdaptors are combined with element space information to create complete <strong>TensorDescriptors</strong>.</p>


<!-- -->

<script type="pyodide-data">
eyJvcHRpb25zIjp7ImVudiI6eyJQTE9UTFlfUkVOREVSRVIiOiJwbG90bHlfbWltZXR5cGUifSwiaW5kZXhVUkwiOiJodHRwczovL2Nkbi5qc2RlbGl2ci5uZXQvcHlvZGlkZS92MC4yNy4wL2Z1bGwvIn0sInBhY2thZ2VzIjp7InBrZ3MiOlsicHlvZGlkZV9odHRwIiwibWljcm9waXAiLCJpcHl0aG9uIiwibnVtcHkiLCJwYW5kYXMiLCJzeW1weSIsIm1pY3JvcGlwIl19fQ==
</script>
<script type="ojs-module-contents">
{"contents":[{"cellName":"pyodide-6","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_6 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-6-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-6-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_6 = pyodideOjs.process(_pyodide_editor_6, {});\n"},{"cellName":"pyodide-5","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_5 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-5-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-5-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_5 = pyodideOjs.process(_pyodide_editor_5, {});\n"},{"cellName":"pyodide-4","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_4 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-4-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-4-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_4 = pyodideOjs.process(_pyodide_editor_4, {});\n"},{"cellName":"pyodide-3","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_3 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-3-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-3-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_3 = pyodideOjs.process(_pyodide_editor_3, {});\n"},{"cellName":"pyodide-2","inline":false,"methodName":"interpret","source":"viewof _pyodide_editor_2 = {\n  const { PyodideExerciseEditor, b64Decode } = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-2-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  const options = Object.assign({ id: `pyodide-2-contents` }, block.attr);\n  const editor = new PyodideExerciseEditor(\n    pyodideOjs.pyodidePromise,\n    block.code,\n    options\n  );\n\n  return editor.container;\n}\n_pyodide_value_2 = pyodideOjs.process(_pyodide_editor_2, {});\n"},{"cellName":"pyodide-1","inline":false,"methodName":"interpret","source":"_pyodide_value_1 = {\n  const { highlightPython, b64Decode} = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-1-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  // Default evaluation configuration\n  const options = Object.assign({\n    id: \"pyodide-1-contents\",\n    echo: true,\n    output: true\n  }, block.attr);\n\n  // Evaluate the provided Python code\n  const result = pyodideOjs.process({code: block.code, options}, {});\n\n  // Early yield while we wait for the first evaluation and render\n  if (options.output && !(\"1\" in pyodideOjs.renderedOjs)) {\n    const container = document.createElement(\"div\");\n    const spinner = document.createElement(\"div\");\n\n    if (options.echo) {\n      // Show output as highlighted source\n      const preElem = document.createElement(\"pre\");\n      container.className = \"sourceCode\";\n      preElem.className = \"sourceCode python\";\n      preElem.appendChild(highlightPython(block.code));\n      spinner.className = \"spinner-grow spinner-grow-sm m-2 position-absolute top-0 end-0\";\n      preElem.appendChild(spinner);\n      container.appendChild(preElem);\n    } else {\n      spinner.className = \"spinner-border spinner-border-sm\";\n      container.appendChild(spinner);\n    }\n\n    yield container;\n  }\n\n  pyodideOjs.renderedOjs[\"1\"] = true;\n  yield await result;\n}\n"},{"cellName":"pyodide-prelude","inline":false,"methodName":"interpretQuiet","source":"pyodideOjs = {\n  const {\n    PyodideEvaluator,\n    PyodideEnvironmentManager,\n    setupPython,\n    startPyodideWorker,\n    b64Decode,\n    collapsePath,\n  } = window._exercise_ojs_runtime;\n\n  const statusContainer = document.getElementById(\"exercise-loading-status\");\n  const indicatorContainer = document.getElementById(\"exercise-loading-indicator\");\n  indicatorContainer.classList.remove(\"d-none\");\n\n  let statusText = document.createElement(\"div\")\n  statusText.classList = \"exercise-loading-details\";\n  statusText = statusContainer.appendChild(statusText);\n  statusText.textContent = `Initialise`;\n\n  // Hoist indicator out from final slide when running under reveal\n  const revealStatus = document.querySelector(\".reveal .exercise-loading-indicator\");\n  if (revealStatus) {\n    revealStatus.remove();\n    document.querySelector(\".reveal > .slides\").appendChild(revealStatus);\n  }\n\n  // Make any reveal slides with live cells scrollable\n  document.querySelectorAll(\".reveal .exercise-cell\").forEach((el) => {\n    el.closest('section.slide').classList.add(\"scrollable\");\n  })\n\n  // Pyodide supplemental data and options\n  const dataContent = document.querySelector(`script[type=\\\"pyodide-data\\\"]`).textContent;\n  const data = JSON.parse(b64Decode(dataContent));\n\n  // Grab list of resources to be downloaded\n  const filesContent = document.querySelector(`script[type=\\\"vfs-file\\\"]`).textContent;\n  const files = JSON.parse(b64Decode(filesContent));\n\n  let pyodidePromise = (async () => {\n    statusText.textContent = `Downloading Pyodide`;\n    const pyodide = await startPyodideWorker(data.options);\n\n    statusText.textContent = `Downloading package: micropip`;\n    await pyodide.loadPackage(\"micropip\");\n    const micropip = await pyodide.pyimport(\"micropip\");\n    await data.packages.pkgs.map((pkg) => () => {\n      statusText.textContent = `Downloading package: ${pkg}`;\n      return micropip.install(pkg);\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n    await micropip.destroy();\n\n    // Download and install resources\n    await files.map((file) => async () => {\n      const name = file.substring(file.lastIndexOf('/') + 1);\n      statusText.textContent = `Downloading resource: ${name}`;\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`Can't download \\`${file}\\`. Error ${response.status}: \"${response.statusText}\".`);\n      }\n      const data = await response.arrayBuffer();\n\n      // Store URLs in the cwd without any subdirectory structure\n      if (file.includes(\"://\")) {\n        file = name;\n      }\n\n      // Collapse higher directory structure\n      file = collapsePath(file);\n\n      // Create directory tree, ignoring \"directory exists\" VFS errors\n      const parts = file.split('/').slice(0, -1);\n      let path = '';\n      while (parts.length > 0) {\n        path += parts.shift() + '/';\n        try {\n          await pyodide.FS.mkdir(path);\n        } catch (e) {\n          if (e.name !== \"ErrnoError\") throw e;\n          if (e.errno !== 20) {\n            const errorTextPtr = await pyodide._module._strerror(e.errno);\n            const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n            throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n          }\n        }\n      }\n\n      // Write this file to the VFS\n      try {\n        return await pyodide.FS.writeFile(file, new Uint8Array(data));\n      } catch (e) {\n        if (e.name !== \"ErrnoError\") throw e;\n        const errorTextPtr = await pyodide._module._strerror(e.errno);\n        const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n        throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n      }\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n\n    statusText.textContent = `Pyodide environment setup`;\n    await setupPython(pyodide);\n\n    statusText.remove();\n    if (statusContainer.children.length == 0) {\n      statusContainer.parentNode.remove();\n    }\n    return pyodide;\n  })().catch((err) => {\n    statusText.style.color = \"var(--exercise-editor-hl-er, #AD0000)\";\n    statusText.textContent = err.message;\n    //indicatorContainer.querySelector(\".spinner-grow\").classList.add(\"d-none\");\n    throw err;\n  });\n\n  // Keep track of initial OJS block render\n  const renderedOjs = {};\n\n  const process = async (context, inputs) => {\n    const pyodide = await pyodidePromise;\n    const evaluator = new PyodideEvaluator(pyodide, context);\n    await evaluator.process(inputs);\n    return evaluator.container;\n  }\n\n  return {\n    pyodidePromise,\n    renderedOjs,\n    process,\n  };\n}\n"}]}
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../concepts";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Tensor Adaptors - Chaining Transformations"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> live-html</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overview</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>While individual transforms are powerful, TensorAdaptors let us chain multiple transforms together to create complex coordinate transformations. Think of adaptors as transformation pipelines that can reshape, reorder, and restructure tensors in sophisticated ways.</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>TensorAdaptors are the bridge between individual transforms and the high-level tensor operations you'll use in real applications.</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co">#| autorun: true</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Auto-install pythonck package</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> micropip</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="cf">await</span> micropip.install(<span class="st">"https://raw.githubusercontent.com/ghamarian/pythonck/master/documentation/pythonck-0.1.0-py3-none-any.whl"</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="fu">## TensorAdaptor Basics</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>Let's start by understanding what a TensorAdaptor is and how it works:</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;div class="mermaid"&gt;</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="in">graph TB</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="in">    subgraph "Adaptor Composition"</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Single Transform"</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="in">            T1["Transform&lt;br/&gt;(e.g., Transpose)"]</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="in">            I1["Input Coords&lt;br/&gt;[0,1,2]"]</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="in">            O1["Output Coords&lt;br/&gt;[2,0,1]"]</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Chained Transforms"</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="in">            T2A["Transform A&lt;br/&gt;(e.g., Merge)"]</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="in">            T2B["Transform B&lt;br/&gt;(e.g., Pad)"]</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a><span class="in">            I2["Input&lt;br/&gt;2D"]</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="in">            M2["Intermediate&lt;br/&gt;1D"]</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="in">            O2["Output&lt;br/&gt;1D Padded"]</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Complex Pipeline"</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a><span class="in">            T3A["Transpose"]</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="in">            T3B["Unmerge"]</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="in">            T3C["Pad"]</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a><span class="in">            I3["Input"]</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="in">            O3["Output"]</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="in">    end</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="in">    I1 --&gt; T1</span></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="in">    T1 --&gt; O1</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="in">    I2 --&gt; T2A</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="in">    T2A --&gt; M2</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a><span class="in">    M2 --&gt; T2B</span></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a><span class="in">    T2B --&gt; O2</span></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a><span class="in">    I3 --&gt; T3A</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a><span class="in">    T3A --&gt; T3B</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a><span class="in">    T3B --&gt; T3C</span></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a><span class="in">    T3C --&gt; O3</span></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a><span class="in">    style T1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px</span></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a><span class="in">    style T2A fill:#fff3e0,stroke:#f57c00,stroke-width:2px</span></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a><span class="in">    style T2B fill:#fff3e0,stroke:#f57c00,stroke-width:2px</span></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a><span class="in">    style T3A fill:#e8f5e9,stroke:#388e3c,stroke-width:2px</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a><span class="in">    style T3B fill:#e8f5e9,stroke:#388e3c,stroke-width:2px</span></span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a><span class="in">    style T3C fill:#e8f5e9,stroke:#388e3c,stroke-width:2px</span></span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/div&gt;</span></span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required modules</span></span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tensor_adaptor <span class="im">import</span> (</span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>    make_single_stage_tensor_adaptor,</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>    transform_tensor_adaptor,</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>    chain_tensor_adaptors,</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>    chain_tensor_adaptors_multi,</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>    make_identity_adaptor,</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>    make_transpose_adaptor</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tensor_descriptor <span class="im">import</span> (</span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>    TensorAdaptor,</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>    PassThroughTransform,</span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>    PadTransform,</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>    MergeTransform,</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>    ReplicateTransform,</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>    EmbedTransform,</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>    UnmergeTransform,</span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>    transform_tensor_descriptor,</span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>    make_naive_tensor_descriptor_packed,</span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>    make_merge_transform,</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>    make_pass_through_transform,</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>    make_unmerge_transform,</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>    make_tuple,</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>    number,</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>    sequence</span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pytensor.tensor_coordinate <span class="im">import</span> MultiIndex</span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"🔗 TensorAdaptor Overview"</span>)</span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  TensorAdaptor chains multiple transforms together"</span>)</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Each adaptor has:"</span>)</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"    • transforms: List of individual transforms"</span>)</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"    • lower_dimension_hidden_idss: How transforms connect"</span>)</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"    • upper_dimension_hidden_idss: Hidden dimension mappings"</span>)</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"    • bottom_dimension_hidden_ids: Input dimensions"</span>)</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"    • top_dimension_hidden_ids: Output dimensions"</span>)</span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>The most important method of a TensorAdaptor is <span class="in">`calculate_bottom_index`</span>, which calculates the lower index from the upper index. It achives this by applying the transforms in reverse order and calling <span class="in">`calculate_lower_index`</span> on each transform. </span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a>Let's go over some of the utility functions for creating tensor adaptors and see how they work in real life. We start with one of the simplest one.</span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transpose Adaptor: Dimension Reordering</span></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a>The transpose adaptor reorders tensor dimensions according to a permutation pattern.</span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"2️⃣ Transpose Adaptor"</span>)</span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a><span class="co"># Create transpose adaptor: [0, 1, 2] → [2, 0, 1]</span></span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a>transpose_adaptor <span class="op">=</span> make_transpose_adaptor(<span class="dv">3</span>, [<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Permutation: [2, 0, 1] (dimension 0→2, 1→0, 2→1)"</span>)</span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of transforms: </span><span class="sc">{</span>transpose_adaptor<span class="sc">.</span>get_num_of_transform()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bottom dimensions: </span><span class="sc">{</span>transpose_adaptor<span class="sc">.</span>get_num_of_bottom_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Top dimensions: </span><span class="sc">{</span>transpose_adaptor<span class="sc">.</span>get_num_of_top_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Test coordinate transformation</span></span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a>test_coords <span class="op">=</span> [[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>]]</span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">  Transpose transformation test:"</span>)</span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> coord_list <span class="kw">in</span> test_coords:</span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a>    top_coord <span class="op">=</span> MultiIndex(<span class="dv">3</span>, coord_list)</span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a>    bottom_coord <span class="op">=</span> transpose_adaptor.calculate_bottom_index(top_coord)</span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>coord_list<span class="sc">}</span><span class="ss"> → </span><span class="sc">{</span>bottom_coord<span class="sc">.</span>to_list()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a><span class="fu">### C++ Implementation</span></span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - create transpose adaptor</span></span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a><span class="co">// Transpose adaptor example: [0, 1, 2] → [2, 0, 1]</span></span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> transpose_adaptor <span class="op">=</span> make_identity_tensor_adaptor<span class="op">&lt;</span><span class="dv">3</span><span class="op">&gt;();</span>  <span class="co">// Start with identity</span></span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a><span class="co">// Apply transpose using transform_tensor_adaptor</span></span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a><span class="co">// In CK, transpose is typically done through tensor descriptor transformations</span></span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> transposed_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a>    original_desc<span class="op">,</span></span>
<span id="cb9-168"><a href="#cb9-168" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_pass_through_transform<span class="op">(</span>original_desc<span class="op">.</span>get_length<span class="op">(</span><span class="dv">2</span><span class="op">)),</span></span>
<span id="cb9-169"><a href="#cb9-169" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>original_desc<span class="op">.</span>get_length<span class="op">(</span><span class="dv">0</span><span class="op">)),</span></span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>original_desc<span class="op">.</span>get_length<span class="op">(</span><span class="dv">1</span><span class="op">))),</span></span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// old dims</span></span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;{})</span>   <span class="co">// new dims</span></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a><span class="co">// Alternative: Direct coordinate transformation</span></span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a>multi_index<span class="op">&lt;</span><span class="dv">3</span><span class="op">&gt;</span> top_coord<span class="op">{</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">};</span></span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a><span class="co">// After transpose [2, 0, 1]: coord becomes [2, 0, 1]</span></span>
<span id="cb9-178"><a href="#cb9-178" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-179"><a href="#cb9-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a><span class="fu">## Single-Stage Adaptors: Custom Transform Chains</span></span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>You can create custom adaptors by specifying exactly which transforms to use and how they connect, the API for that is called <span class="in">`make_single_stage_tensor_adaptor`</span>:</span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"3️⃣ Single-Stage Custom Adaptor"</span>)</span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a><span class="co"># Create adaptor that splits 1D coordinates to 2D</span></span>
<span id="cb9-194"><a href="#cb9-194" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: MergeTransform has 1D upper (top) and 2D lower (bottom)</span></span>
<span id="cb9-195"><a href="#cb9-195" aria-hidden="true" tabindex="-1"></a>merge_adaptor <span class="op">=</span> make_single_stage_tensor_adaptor(</span>
<span id="cb9-196"><a href="#cb9-196" aria-hidden="true" tabindex="-1"></a>    transforms<span class="op">=</span>[MergeTransform([<span class="dv">2</span>, <span class="dv">3</span>])],</span>
<span id="cb9-197"><a href="#cb9-197" aria-hidden="true" tabindex="-1"></a>    lower_dimension_old_top_idss<span class="op">=</span>[[<span class="dv">0</span>, <span class="dv">1</span>]],  <span class="co"># Bottom: 2D dimensions 0 and 1</span></span>
<span id="cb9-198"><a href="#cb9-198" aria-hidden="true" tabindex="-1"></a>    upper_dimension_new_top_idss<span class="op">=</span>[[<span class="dv">0</span>]]       <span class="co"># Top: 1D dimension 0 (merged)</span></span>
<span id="cb9-199"><a href="#cb9-199" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-200"><a href="#cb9-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-201"><a href="#cb9-201" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Transform: MergeTransform([2, 3]) - splits 1D to 2D"</span>)</span>
<span id="cb9-202"><a href="#cb9-202" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bottom dimensions: </span><span class="sc">{</span>merge_adaptor<span class="sc">.</span>get_num_of_bottom_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-203"><a href="#cb9-203" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Top dimensions: </span><span class="sc">{</span>merge_adaptor<span class="sc">.</span>get_num_of_top_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-204"><a href="#cb9-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-205"><a href="#cb9-205" aria-hidden="true" tabindex="-1"></a><span class="co"># Test merge transformation: 1D top → 2D bottom</span></span>
<span id="cb9-206"><a href="#cb9-206" aria-hidden="true" tabindex="-1"></a>test_indices <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>]</span>
<span id="cb9-207"><a href="#cb9-207" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">  Merge transformation test (1D → 2D):"</span>)</span>
<span id="cb9-208"><a href="#cb9-208" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> test_indices:</span>
<span id="cb9-209"><a href="#cb9-209" aria-hidden="true" tabindex="-1"></a>    top_coord <span class="op">=</span> MultiIndex(<span class="dv">1</span>, [idx])  <span class="co"># 1D top coordinate</span></span>
<span id="cb9-210"><a href="#cb9-210" aria-hidden="true" tabindex="-1"></a>    bottom_coord <span class="op">=</span> merge_adaptor.calculate_bottom_index(top_coord)</span>
<span id="cb9-211"><a href="#cb9-211" aria-hidden="true" tabindex="-1"></a>    expected_row <span class="op">=</span> idx <span class="op">//</span> <span class="dv">3</span></span>
<span id="cb9-212"><a href="#cb9-212" aria-hidden="true" tabindex="-1"></a>    expected_col <span class="op">=</span> idx <span class="op">%</span> <span class="dv">3</span></span>
<span id="cb9-213"><a href="#cb9-213" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    [</span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">] → </span><span class="sc">{</span>bottom_coord<span class="sc">.</span>to_list()<span class="sc">}</span><span class="ss"> (expected: [</span><span class="sc">{</span>expected_row<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>expected_col<span class="sc">}</span><span class="ss">])"</span>)</span>
<span id="cb9-214"><a href="#cb9-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-215"><a href="#cb9-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-216"><a href="#cb9-216" aria-hidden="true" tabindex="-1"></a><span class="fu">### C++ Implementation</span></span>
<span id="cb9-217"><a href="#cb9-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-218"><a href="#cb9-218" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-219"><a href="#cb9-219" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - create single-stage tensor adaptor</span></span>
<span id="cb9-220"><a href="#cb9-220" aria-hidden="true" tabindex="-1"></a><span class="co">// Note: In CK, adaptors are typically created through tensor descriptors</span></span>
<span id="cb9-221"><a href="#cb9-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-222"><a href="#cb9-222" aria-hidden="true" tabindex="-1"></a><span class="co">// Create a descriptor that merges 2x3 dimensions into single dimension</span></span>
<span id="cb9-223"><a href="#cb9-223" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> base_desc <span class="op">=</span> make_naive_tensor_descriptor_packed<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">));</span></span>
<span id="cb9-224"><a href="#cb9-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-225"><a href="#cb9-225" aria-hidden="true" tabindex="-1"></a><span class="co">// Apply merge transform</span></span>
<span id="cb9-226"><a href="#cb9-226" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> merged_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-227"><a href="#cb9-227" aria-hidden="true" tabindex="-1"></a>    base_desc<span class="op">,</span></span>
<span id="cb9-228"><a href="#cb9-228" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">))),</span></span>
<span id="cb9-229"><a href="#cb9-229" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// merge dims 0,1</span></span>
<span id="cb9-230"><a href="#cb9-230" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{})</span>      <span class="co">// to single dim 0</span></span>
<span id="cb9-231"><a href="#cb9-231" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-232"><a href="#cb9-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-233"><a href="#cb9-233" aria-hidden="true" tabindex="-1"></a><span class="co">// The adaptor is embedded in the descriptor</span></span>
<span id="cb9-234"><a href="#cb9-234" aria-hidden="true" tabindex="-1"></a><span class="co">// To use it:</span></span>
<span id="cb9-235"><a href="#cb9-235" aria-hidden="true" tabindex="-1"></a>multi_index<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;</span> top_coord<span class="op">{</span><span class="dv">5</span><span class="op">};</span>  <span class="co">// 1D coordinate</span></span>
<span id="cb9-236"><a href="#cb9-236" aria-hidden="true" tabindex="-1"></a><span class="co">// This internally calculates: row = 5/3 = 1, col = 5%3 = 2</span></span>
<span id="cb9-237"><a href="#cb9-237" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-238"><a href="#cb9-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-239"><a href="#cb9-239" aria-hidden="true" tabindex="-1"></a>Now that we saw how we can create an adaptor, let's see how we can combine a few of them together.</span>
<span id="cb9-240"><a href="#cb9-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-241"><a href="#cb9-241" aria-hidden="true" tabindex="-1"></a><span class="fu">## Chaining Adaptors: Building Complex Transformations</span></span>
<span id="cb9-242"><a href="#cb9-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-243"><a href="#cb9-243" aria-hidden="true" tabindex="-1"></a>The real power comes from chaining multiple adaptors together to create sophisticated transformations. Below we try some trivial example of combining merge and unmerge just to show how these transformations combine.</span>
<span id="cb9-244"><a href="#cb9-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-245"><a href="#cb9-245" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb9-246"><a href="#cb9-246" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;div class="mermaid"&gt;</span></span>
<span id="cb9-247"><a href="#cb9-247" aria-hidden="true" tabindex="-1"></a><span class="in">graph LR</span></span>
<span id="cb9-248"><a href="#cb9-248" aria-hidden="true" tabindex="-1"></a><span class="in">    subgraph "Adaptor Chaining Flow"</span></span>
<span id="cb9-249"><a href="#cb9-249" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Adaptor 1"</span></span>
<span id="cb9-250"><a href="#cb9-250" aria-hidden="true" tabindex="-1"></a><span class="in">            A1I["Bottom Dims&lt;br/&gt;[0,1]"]</span></span>
<span id="cb9-251"><a href="#cb9-251" aria-hidden="true" tabindex="-1"></a><span class="in">            A1T["Transform:&lt;br/&gt;Merge[2,3]"]</span></span>
<span id="cb9-252"><a href="#cb9-252" aria-hidden="true" tabindex="-1"></a><span class="in">            A1O["Top Dims&lt;br/&gt;[0]"]</span></span>
<span id="cb9-253"><a href="#cb9-253" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb9-254"><a href="#cb9-254" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb9-255"><a href="#cb9-255" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Adaptor 2"</span></span>
<span id="cb9-256"><a href="#cb9-256" aria-hidden="true" tabindex="-1"></a><span class="in">            A2I["Bottom Dims&lt;br/&gt;[0]"]</span></span>
<span id="cb9-257"><a href="#cb9-257" aria-hidden="true" tabindex="-1"></a><span class="in">            A2T["Transform:&lt;br/&gt;Unmerge[2,3]"]</span></span>
<span id="cb9-258"><a href="#cb9-258" aria-hidden="true" tabindex="-1"></a><span class="in">            A2O["Top Dims&lt;br/&gt;[0,1]"]</span></span>
<span id="cb9-259"><a href="#cb9-259" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb9-260"><a href="#cb9-260" aria-hidden="true" tabindex="-1"></a><span class="in">        </span></span>
<span id="cb9-261"><a href="#cb9-261" aria-hidden="true" tabindex="-1"></a><span class="in">        subgraph "Chained Result"</span></span>
<span id="cb9-262"><a href="#cb9-262" aria-hidden="true" tabindex="-1"></a><span class="in">            CI["Input 2D&lt;br/&gt;Bottom[0,1]"]</span></span>
<span id="cb9-263"><a href="#cb9-263" aria-hidden="true" tabindex="-1"></a><span class="in">            CO["Output 2D&lt;br/&gt;Top[0,1]"]</span></span>
<span id="cb9-264"><a href="#cb9-264" aria-hidden="true" tabindex="-1"></a><span class="in">        end</span></span>
<span id="cb9-265"><a href="#cb9-265" aria-hidden="true" tabindex="-1"></a><span class="in">    end</span></span>
<span id="cb9-266"><a href="#cb9-266" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-267"><a href="#cb9-267" aria-hidden="true" tabindex="-1"></a><span class="in">    A1I --&gt; A1T</span></span>
<span id="cb9-268"><a href="#cb9-268" aria-hidden="true" tabindex="-1"></a><span class="in">    A1T --&gt; A1O</span></span>
<span id="cb9-269"><a href="#cb9-269" aria-hidden="true" tabindex="-1"></a><span class="in">    A1O --&gt; A2I</span></span>
<span id="cb9-270"><a href="#cb9-270" aria-hidden="true" tabindex="-1"></a><span class="in">    A2I --&gt; A2T</span></span>
<span id="cb9-271"><a href="#cb9-271" aria-hidden="true" tabindex="-1"></a><span class="in">    A2T --&gt; A2O</span></span>
<span id="cb9-272"><a href="#cb9-272" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-273"><a href="#cb9-273" aria-hidden="true" tabindex="-1"></a><span class="in">    CI --&gt; A1I</span></span>
<span id="cb9-274"><a href="#cb9-274" aria-hidden="true" tabindex="-1"></a><span class="in">    A2O --&gt; CO</span></span>
<span id="cb9-275"><a href="#cb9-275" aria-hidden="true" tabindex="-1"></a><span class="in">    </span></span>
<span id="cb9-276"><a href="#cb9-276" aria-hidden="true" tabindex="-1"></a><span class="in">    style A1T fill:#e3f2fd,stroke:#1976d2,stroke-width:2px</span></span>
<span id="cb9-277"><a href="#cb9-277" aria-hidden="true" tabindex="-1"></a><span class="in">    style A2T fill:#fff3e0,stroke:#f57c00,stroke-width:2px</span></span>
<span id="cb9-278"><a href="#cb9-278" aria-hidden="true" tabindex="-1"></a><span class="in">    style CI fill:#e8f5e9,stroke:#388e3c,stroke-width:2px</span></span>
<span id="cb9-279"><a href="#cb9-279" aria-hidden="true" tabindex="-1"></a><span class="in">    style CO fill:#e8f5e9,stroke:#388e3c,stroke-width:2px</span></span>
<span id="cb9-280"><a href="#cb9-280" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;/div&gt;</span></span>
<span id="cb9-281"><a href="#cb9-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-282"><a href="#cb9-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-285"><a href="#cb9-285" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb9-286"><a href="#cb9-286" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb9-287"><a href="#cb9-287" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb9-288"><a href="#cb9-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-289"><a href="#cb9-289" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"4️⃣ Chaining Adaptors"</span>)</span>
<span id="cb9-290"><a href="#cb9-290" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-291"><a href="#cb9-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-292"><a href="#cb9-292" aria-hidden="true" tabindex="-1"></a><span class="co"># Create first adaptor: 1D → 2D (merge splits)</span></span>
<span id="cb9-293"><a href="#cb9-293" aria-hidden="true" tabindex="-1"></a>adaptor_merge <span class="op">=</span> make_single_stage_tensor_adaptor(</span>
<span id="cb9-294"><a href="#cb9-294" aria-hidden="true" tabindex="-1"></a>    transforms<span class="op">=</span>[MergeTransform([<span class="dv">2</span>, <span class="dv">3</span>])],</span>
<span id="cb9-295"><a href="#cb9-295" aria-hidden="true" tabindex="-1"></a>    lower_dimension_old_top_idss<span class="op">=</span>[[<span class="dv">0</span>, <span class="dv">1</span>]],</span>
<span id="cb9-296"><a href="#cb9-296" aria-hidden="true" tabindex="-1"></a>    upper_dimension_new_top_idss<span class="op">=</span>[[<span class="dv">0</span>]]</span>
<span id="cb9-297"><a href="#cb9-297" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-298"><a href="#cb9-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-299"><a href="#cb9-299" aria-hidden="true" tabindex="-1"></a><span class="co"># Create second adaptor: 2D → 1D (unmerge combines)</span></span>
<span id="cb9-300"><a href="#cb9-300" aria-hidden="true" tabindex="-1"></a>adaptor_unmerge <span class="op">=</span> make_single_stage_tensor_adaptor(</span>
<span id="cb9-301"><a href="#cb9-301" aria-hidden="true" tabindex="-1"></a>    transforms<span class="op">=</span>[UnmergeTransform([<span class="dv">2</span>, <span class="dv">3</span>])],</span>
<span id="cb9-302"><a href="#cb9-302" aria-hidden="true" tabindex="-1"></a>    lower_dimension_old_top_idss<span class="op">=</span>[[<span class="dv">0</span>]],</span>
<span id="cb9-303"><a href="#cb9-303" aria-hidden="true" tabindex="-1"></a>    upper_dimension_new_top_idss<span class="op">=</span>[[<span class="dv">0</span>, <span class="dv">1</span>]]</span>
<span id="cb9-304"><a href="#cb9-304" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-305"><a href="#cb9-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-306"><a href="#cb9-306" aria-hidden="true" tabindex="-1"></a><span class="co"># Chain them together (should be identity overall)</span></span>
<span id="cb9-307"><a href="#cb9-307" aria-hidden="true" tabindex="-1"></a>chained_adaptor <span class="op">=</span> chain_tensor_adaptors(adaptor_merge, adaptor_unmerge)</span>
<span id="cb9-308"><a href="#cb9-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-309"><a href="#cb9-309" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Chain: 1D → 2D → 1D (but actually results in 2D → 2D)"</span>)</span>
<span id="cb9-310"><a href="#cb9-310" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of transforms: </span><span class="sc">{</span>chained_adaptor<span class="sc">.</span>get_num_of_transform()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-311"><a href="#cb9-311" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bottom dimensions: </span><span class="sc">{</span>chained_adaptor<span class="sc">.</span>get_num_of_bottom_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-312"><a href="#cb9-312" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Top dimensions: </span><span class="sc">{</span>chained_adaptor<span class="sc">.</span>get_num_of_top_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-313"><a href="#cb9-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-314"><a href="#cb9-314" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the chained transformation (should be identity)</span></span>
<span id="cb9-315"><a href="#cb9-315" aria-hidden="true" tabindex="-1"></a>test_coords <span class="op">=</span> [[<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">2</span>]]</span>
<span id="cb9-316"><a href="#cb9-316" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">  Chained transformation test (should be identity):"</span>)</span>
<span id="cb9-317"><a href="#cb9-317" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> coord_list <span class="kw">in</span> test_coords:</span>
<span id="cb9-318"><a href="#cb9-318" aria-hidden="true" tabindex="-1"></a>    top_coord <span class="op">=</span> MultiIndex(<span class="dv">2</span>, coord_list)  <span class="co"># 2D input</span></span>
<span id="cb9-319"><a href="#cb9-319" aria-hidden="true" tabindex="-1"></a>    bottom_coord <span class="op">=</span> chained_adaptor.calculate_bottom_index(top_coord)</span>
<span id="cb9-320"><a href="#cb9-320" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>coord_list<span class="sc">}</span><span class="ss"> → </span><span class="sc">{</span>bottom_coord<span class="sc">.</span>to_list()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-321"><a href="#cb9-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-322"><a href="#cb9-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-323"><a href="#cb9-323" aria-hidden="true" tabindex="-1"></a><span class="fu">### C++ Implementation</span></span>
<span id="cb9-324"><a href="#cb9-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-325"><a href="#cb9-325" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-326"><a href="#cb9-326" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - chaining adaptors through descriptors</span></span>
<span id="cb9-327"><a href="#cb9-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-328"><a href="#cb9-328" aria-hidden="true" tabindex="-1"></a><span class="co">// Start with a 2D descriptor</span></span>
<span id="cb9-329"><a href="#cb9-329" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> desc1 <span class="op">=</span> make_naive_tensor_descriptor_packed<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">));</span></span>
<span id="cb9-330"><a href="#cb9-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-331"><a href="#cb9-331" aria-hidden="true" tabindex="-1"></a><span class="co">// First transformation: merge 2D to 1D</span></span>
<span id="cb9-332"><a href="#cb9-332" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> merged_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-333"><a href="#cb9-333" aria-hidden="true" tabindex="-1"></a>    desc1<span class="op">,</span></span>
<span id="cb9-334"><a href="#cb9-334" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">))),</span></span>
<span id="cb9-335"><a href="#cb9-335" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// merge dims 0,1</span></span>
<span id="cb9-336"><a href="#cb9-336" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{})</span>      <span class="co">// to dim 0</span></span>
<span id="cb9-337"><a href="#cb9-337" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-338"><a href="#cb9-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-339"><a href="#cb9-339" aria-hidden="true" tabindex="-1"></a><span class="co">// Second transformation: unmerge 1D back to 2D</span></span>
<span id="cb9-340"><a href="#cb9-340" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> final_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-341"><a href="#cb9-341" aria-hidden="true" tabindex="-1"></a>    merged_desc<span class="op">,</span></span>
<span id="cb9-342"><a href="#cb9-342" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span><span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">))),</span></span>
<span id="cb9-343"><a href="#cb9-343" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{}),</span>     <span class="co">// from dim 0</span></span>
<span id="cb9-344"><a href="#cb9-344" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{})</span>   <span class="co">// to dims 0,1</span></span>
<span id="cb9-345"><a href="#cb9-345" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-346"><a href="#cb9-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-347"><a href="#cb9-347" aria-hidden="true" tabindex="-1"></a><span class="co">// The chained transformation is embedded in final_desc</span></span>
<span id="cb9-348"><a href="#cb9-348" aria-hidden="true" tabindex="-1"></a><span class="co">// Result should be identity transformation</span></span>
<span id="cb9-349"><a href="#cb9-349" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-350"><a href="#cb9-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-351"><a href="#cb9-351" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transform Addition: Extending Existing Adaptors</span></span>
<span id="cb9-352"><a href="#cb9-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-353"><a href="#cb9-353" aria-hidden="true" tabindex="-1"></a>You can add new transforms to existing adaptors using <span class="in">`transform_tensor_adaptor`</span>. **Important**: The `new_upper_dimension_new_top_idss` parameter controls the **final output dimensions** of the adaptor.</span>
<span id="cb9-354"><a href="#cb9-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-357"><a href="#cb9-357" aria-hidden="true" tabindex="-1"></a><span class="in">```{pyodide}</span></span>
<span id="cb9-358"><a href="#cb9-358" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb9-359"><a href="#cb9-359" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb9-360"><a href="#cb9-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-361"><a href="#cb9-361" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"7️⃣ Practical Example: Matrix Transpose + Padding"</span>)</span>
<span id="cb9-362"><a href="#cb9-362" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-363"><a href="#cb9-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-364"><a href="#cb9-364" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a matrix transpose adaptor</span></span>
<span id="cb9-365"><a href="#cb9-365" aria-hidden="true" tabindex="-1"></a>matrix_transpose <span class="op">=</span> make_transpose_adaptor(<span class="dv">2</span>, [<span class="dv">1</span>, <span class="dv">0</span>])</span>
<span id="cb9-366"><a href="#cb9-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-367"><a href="#cb9-367" aria-hidden="true" tabindex="-1"></a>padded_transpose_2d <span class="op">=</span> transform_tensor_adaptor(</span>
<span id="cb9-368"><a href="#cb9-368" aria-hidden="true" tabindex="-1"></a>    old_adaptor<span class="op">=</span>matrix_transpose,</span>
<span id="cb9-369"><a href="#cb9-369" aria-hidden="true" tabindex="-1"></a>    new_transforms<span class="op">=</span>[</span>
<span id="cb9-370"><a href="#cb9-370" aria-hidden="true" tabindex="-1"></a>        PadTransform(lower_length<span class="op">=</span><span class="dv">4</span>, left_pad<span class="op">=</span><span class="dv">1</span>, right_pad<span class="op">=</span><span class="dv">1</span>),  <span class="co"># Pad first dimension</span></span>
<span id="cb9-371"><a href="#cb9-371" aria-hidden="true" tabindex="-1"></a>        PassThroughTransform(<span class="dv">3</span>)                                 <span class="co"># Keep second dimension</span></span>
<span id="cb9-372"><a href="#cb9-372" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb9-373"><a href="#cb9-373" aria-hidden="true" tabindex="-1"></a>    new_lower_dimension_old_top_idss<span class="op">=</span>[[<span class="dv">0</span>], [<span class="dv">1</span>]],  <span class="co"># Apply to both dimensions</span></span>
<span id="cb9-374"><a href="#cb9-374" aria-hidden="true" tabindex="-1"></a>    new_upper_dimension_new_top_idss<span class="op">=</span>[[<span class="dv">0</span>], [<span class="dv">1</span>]]   <span class="co"># Keep both in final output</span></span>
<span id="cb9-375"><a href="#cb9-375" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-376"><a href="#cb9-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-377"><a href="#cb9-377" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Operation: 2D transpose → 2D (pad first dim, pass second)"</span>)</span>
<span id="cb9-378"><a href="#cb9-378" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total transforms: </span><span class="sc">{</span>padded_transpose_2d<span class="sc">.</span>get_num_of_transform()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-379"><a href="#cb9-379" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Bottom dimensions: </span><span class="sc">{</span>padded_transpose_2d<span class="sc">.</span>get_num_of_bottom_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-380"><a href="#cb9-380" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Top dimensions: </span><span class="sc">{</span>padded_transpose_2d<span class="sc">.</span>get_num_of_top_dimension()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-381"><a href="#cb9-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-382"><a href="#cb9-382" aria-hidden="true" tabindex="-1"></a><span class="co"># Test with a 3x4 matrix conceptually</span></span>
<span id="cb9-383"><a href="#cb9-383" aria-hidden="true" tabindex="-1"></a>test_coords <span class="op">=</span> [[<span class="dv">0</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">0</span>], [<span class="dv">3</span>, <span class="dv">2</span>]]</span>
<span id="cb9-384"><a href="#cb9-384" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">  Matrix transpose with padding test:"</span>)</span>
<span id="cb9-385"><a href="#cb9-385" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> coord_list <span class="kw">in</span> test_coords:</span>
<span id="cb9-386"><a href="#cb9-386" aria-hidden="true" tabindex="-1"></a>    top_coord <span class="op">=</span> MultiIndex(<span class="dv">2</span>, coord_list)</span>
<span id="cb9-387"><a href="#cb9-387" aria-hidden="true" tabindex="-1"></a>    bottom_coord <span class="op">=</span> padded_transpose_2d.calculate_bottom_index(top_coord)</span>
<span id="cb9-388"><a href="#cb9-388" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Manual verification: [i,j] → transpose → [j,i] → pad first → [j-1,i]</span></span>
<span id="cb9-389"><a href="#cb9-389" aria-hidden="true" tabindex="-1"></a>    expected <span class="op">=</span> [coord_list[<span class="dv">1</span>] <span class="op">-</span> <span class="dv">1</span>, coord_list[<span class="dv">0</span>]]</span>
<span id="cb9-390"><a href="#cb9-390" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"    </span><span class="sc">{</span>coord_list<span class="sc">}</span><span class="ss"> → </span><span class="sc">{</span>bottom_coord<span class="sc">.</span>to_list()<span class="sc">}</span><span class="ss"> (expected: </span><span class="sc">{</span>expected<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb9-391"><a href="#cb9-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-392"><a href="#cb9-392" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">  ⚠️  Common mistake: Using [[0]] for new_upper_dimension_new_top_idss"</span>)</span>
<span id="cb9-393"><a href="#cb9-393" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"     This creates 1D output, losing the second dimension!"</span>)</span>
<span id="cb9-394"><a href="#cb9-394" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-395"><a href="#cb9-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-396"><a href="#cb9-396" aria-hidden="true" tabindex="-1"></a><span class="fu">### C++ Implementation</span></span>
<span id="cb9-397"><a href="#cb9-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-398"><a href="#cb9-398" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-399"><a href="#cb9-399" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - transform tensor adaptor pattern</span></span>
<span id="cb9-400"><a href="#cb9-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-401"><a href="#cb9-401" aria-hidden="true" tabindex="-1"></a><span class="co">// Start with transposed descriptor</span></span>
<span id="cb9-402"><a href="#cb9-402" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> base_desc <span class="op">=</span> make_naive_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-403"><a href="#cb9-403" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span><span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">),</span></span>
<span id="cb9-404"><a href="#cb9-404" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span><span class="dv">1</span><span class="op">,</span> <span class="dv">3</span><span class="op">)</span>   <span class="co">// transposed strides</span></span>
<span id="cb9-405"><a href="#cb9-405" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-406"><a href="#cb9-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-407"><a href="#cb9-407" aria-hidden="true" tabindex="-1"></a><span class="co">// Add padding to both dimensions</span></span>
<span id="cb9-408"><a href="#cb9-408" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> padded_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-409"><a href="#cb9-409" aria-hidden="true" tabindex="-1"></a>    base_desc<span class="op">,</span></span>
<span id="cb9-410"><a href="#cb9-410" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_pad_transform<span class="op">(</span><span class="dv">3</span><span class="op">,</span> <span class="dv">1</span><span class="op">,</span> <span class="dv">1</span><span class="op">),</span>   <span class="co">// pad dim 0: 3 → 5</span></span>
<span id="cb9-411"><a href="#cb9-411" aria-hidden="true" tabindex="-1"></a>               make_pad_transform<span class="op">(</span><span class="dv">4</span><span class="op">,</span> <span class="dv">0</span><span class="op">,</span> <span class="dv">0</span><span class="op">)),</span>   <span class="co">// keep dim 1: 4 → 4</span></span>
<span id="cb9-412"><a href="#cb9-412" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>  <span class="co">// input dims</span></span>
<span id="cb9-413"><a href="#cb9-413" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span>   <span class="co">// output dims (keep 2D)</span></span>
<span id="cb9-414"><a href="#cb9-414" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-415"><a href="#cb9-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-416"><a href="#cb9-416" aria-hidden="true" tabindex="-1"></a><span class="co">// Access pattern</span></span>
<span id="cb9-417"><a href="#cb9-417" aria-hidden="true" tabindex="-1"></a>multi_index<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;</span> padded_coord<span class="op">{</span><span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">};</span>  <span class="co">// In padded space</span></span>
<span id="cb9-418"><a href="#cb9-418" aria-hidden="true" tabindex="-1"></a><span class="co">// Internally calculates: unpadded = [1-1, 2] = [0, 2]</span></span>
<span id="cb9-419"><a href="#cb9-419" aria-hidden="true" tabindex="-1"></a><span class="co">// Then applies transpose strides</span></span>
<span id="cb9-420"><a href="#cb9-420" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-421"><a href="#cb9-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-422"><a href="#cb9-422" aria-hidden="true" tabindex="-1"></a><span class="fu">## Advanced C++ Patterns</span></span>
<span id="cb9-423"><a href="#cb9-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-424"><a href="#cb9-424" aria-hidden="true" tabindex="-1"></a><span class="fu">### Complex Nested Transforms in C++</span></span>
<span id="cb9-425"><a href="#cb9-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-426"><a href="#cb9-426" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-427"><a href="#cb9-427" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - complex nested transform patterns</span></span>
<span id="cb9-428"><a href="#cb9-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-429"><a href="#cb9-429" aria-hidden="true" tabindex="-1"></a><span class="co">// Example: 4D tensor with complex transformations</span></span>
<span id="cb9-430"><a href="#cb9-430" aria-hidden="true" tabindex="-1"></a><span class="co">// Shape: [A, B, C, D] with various transforms</span></span>
<span id="cb9-431"><a href="#cb9-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-432"><a href="#cb9-432" aria-hidden="true" tabindex="-1"></a><span class="co">// 1. Create base descriptor</span></span>
<span id="cb9-433"><a href="#cb9-433" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> base_desc <span class="op">=</span> make_naive_tensor_descriptor_packed<span class="op">(</span></span>
<span id="cb9-434"><a href="#cb9-434" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>A<span class="op">,</span> B<span class="op">,</span> C<span class="op">,</span> D<span class="op">)</span></span>
<span id="cb9-435"><a href="#cb9-435" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-436"><a href="#cb9-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-437"><a href="#cb9-437" aria-hidden="true" tabindex="-1"></a><span class="co">// 2. Apply multiple transformations</span></span>
<span id="cb9-438"><a href="#cb9-438" aria-hidden="true" tabindex="-1"></a><span class="co">// First: merge first 3 dimensions</span></span>
<span id="cb9-439"><a href="#cb9-439" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> step1_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-440"><a href="#cb9-440" aria-hidden="true" tabindex="-1"></a>    base_desc<span class="op">,</span></span>
<span id="cb9-441"><a href="#cb9-441" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span>A<span class="op">,</span> B<span class="op">,</span> C<span class="op">)),</span></span>
<span id="cb9-442"><a href="#cb9-442" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>D<span class="op">)),</span></span>
<span id="cb9-443"><a href="#cb9-443" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">3</span><span class="op">&gt;{}),</span>  <span class="co">// input mapping</span></span>
<span id="cb9-444"><a href="#cb9-444" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span>         <span class="co">// output: 2D</span></span>
<span id="cb9-445"><a href="#cb9-445" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-446"><a href="#cb9-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-447"><a href="#cb9-447" aria-hidden="true" tabindex="-1"></a><span class="co">// 3. Then unmerge back but with different grouping</span></span>
<span id="cb9-448"><a href="#cb9-448" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> step2_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-449"><a href="#cb9-449" aria-hidden="true" tabindex="-1"></a>    step1_desc<span class="op">,</span></span>
<span id="cb9-450"><a href="#cb9-450" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span>A<span class="op">*</span>B<span class="op">,</span> C<span class="op">)),</span></span>
<span id="cb9-451"><a href="#cb9-451" aria-hidden="true" tabindex="-1"></a>               make_pass_through_transform<span class="op">(</span>D<span class="op">)),</span></span>
<span id="cb9-452"><a href="#cb9-452" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>        <span class="co">// from 2D</span></span>
<span id="cb9-453"><a href="#cb9-453" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">2</span><span class="op">&gt;{})</span>      <span class="co">// to 3D</span></span>
<span id="cb9-454"><a href="#cb9-454" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-455"><a href="#cb9-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-456"><a href="#cb9-456" aria-hidden="true" tabindex="-1"></a><span class="co">// The adaptor chain is embedded in the descriptors</span></span>
<span id="cb9-457"><a href="#cb9-457" aria-hidden="true" tabindex="-1"></a><span class="co">// CK optimizes these at compile time</span></span>
<span id="cb9-458"><a href="#cb9-458" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-459"><a href="#cb9-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-460"><a href="#cb9-460" aria-hidden="true" tabindex="-1"></a><span class="fu">### GPU Memory Layout Example</span></span>
<span id="cb9-461"><a href="#cb9-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-462"><a href="#cb9-462" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-463"><a href="#cb9-463" aria-hidden="true" tabindex="-1"></a><span class="co">// From composable_kernel - typical GPU block descriptor pattern</span></span>
<span id="cb9-464"><a href="#cb9-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-465"><a href="#cb9-465" aria-hidden="true" tabindex="-1"></a><span class="co">// Create descriptor for thread block tile: 64x64</span></span>
<span id="cb9-466"><a href="#cb9-466" aria-hidden="true" tabindex="-1"></a><span class="co">// With 8x8 vector loads per thread</span></span>
<span id="cb9-467"><a href="#cb9-467" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> BlockM <span class="op">=</span> <span class="dv">64</span><span class="op">;</span></span>
<span id="cb9-468"><a href="#cb9-468" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> BlockN <span class="op">=</span> <span class="dv">64</span><span class="op">;</span></span>
<span id="cb9-469"><a href="#cb9-469" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> VectorM <span class="op">=</span> <span class="dv">8</span><span class="op">;</span></span>
<span id="cb9-470"><a href="#cb9-470" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> VectorN <span class="op">=</span> <span class="dv">8</span><span class="op">;</span></span>
<span id="cb9-471"><a href="#cb9-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-472"><a href="#cb9-472" aria-hidden="true" tabindex="-1"></a><span class="co">// Thread arrangement: 8x8 threads</span></span>
<span id="cb9-473"><a href="#cb9-473" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> ThreadM <span class="op">=</span> BlockM <span class="op">/</span> VectorM<span class="op">;</span>  <span class="co">// 8</span></span>
<span id="cb9-474"><a href="#cb9-474" aria-hidden="true" tabindex="-1"></a><span class="kw">constexpr</span> <span class="kw">auto</span> ThreadN <span class="op">=</span> BlockN <span class="op">/</span> VectorN<span class="op">;</span>  <span class="co">// 8</span></span>
<span id="cb9-475"><a href="#cb9-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-476"><a href="#cb9-476" aria-hidden="true" tabindex="-1"></a><span class="co">// Create block descriptor with proper layout</span></span>
<span id="cb9-477"><a href="#cb9-477" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> block_desc <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-478"><a href="#cb9-478" aria-hidden="true" tabindex="-1"></a>    make_naive_tensor_descriptor_packed<span class="op">(</span></span>
<span id="cb9-479"><a href="#cb9-479" aria-hidden="true" tabindex="-1"></a>        make_tuple<span class="op">(</span>number<span class="op">&lt;</span>BlockM<span class="op">&gt;{},</span> number<span class="op">&lt;</span>BlockN<span class="op">&gt;{})</span></span>
<span id="cb9-480"><a href="#cb9-480" aria-hidden="true" tabindex="-1"></a>    <span class="op">),</span></span>
<span id="cb9-481"><a href="#cb9-481" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span></span>
<span id="cb9-482"><a href="#cb9-482" aria-hidden="true" tabindex="-1"></a>        make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span></span>
<span id="cb9-483"><a href="#cb9-483" aria-hidden="true" tabindex="-1"></a>            number<span class="op">&lt;</span>ThreadM<span class="op">&gt;{},</span> number<span class="op">&lt;</span>VectorM<span class="op">&gt;{}</span></span>
<span id="cb9-484"><a href="#cb9-484" aria-hidden="true" tabindex="-1"></a>        <span class="op">)),</span></span>
<span id="cb9-485"><a href="#cb9-485" aria-hidden="true" tabindex="-1"></a>        make_unmerge_transform<span class="op">(</span>make_tuple<span class="op">(</span></span>
<span id="cb9-486"><a href="#cb9-486" aria-hidden="true" tabindex="-1"></a>            number<span class="op">&lt;</span>ThreadN<span class="op">&gt;{},</span> number<span class="op">&lt;</span>VectorN<span class="op">&gt;{}</span></span>
<span id="cb9-487"><a href="#cb9-487" aria-hidden="true" tabindex="-1"></a>        <span class="op">))</span></span>
<span id="cb9-488"><a href="#cb9-488" aria-hidden="true" tabindex="-1"></a>    <span class="op">),</span></span>
<span id="cb9-489"><a href="#cb9-489" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span>           <span class="co">// from 2D</span></span>
<span id="cb9-490"><a href="#cb9-490" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">2</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">,</span> <span class="dv">3</span><span class="op">&gt;{})</span>     <span class="co">// to 4D: [TM,TN,VM,VN]</span></span>
<span id="cb9-491"><a href="#cb9-491" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-492"><a href="#cb9-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-493"><a href="#cb9-493" aria-hidden="true" tabindex="-1"></a><span class="co">// This creates the layout:</span></span>
<span id="cb9-494"><a href="#cb9-494" aria-hidden="true" tabindex="-1"></a><span class="co">// - Dimension 0,1: Thread indices</span></span>
<span id="cb9-495"><a href="#cb9-495" aria-hidden="true" tabindex="-1"></a><span class="co">// - Dimension 2,3: Vector indices within thread</span></span>
<span id="cb9-496"><a href="#cb9-496" aria-hidden="true" tabindex="-1"></a><span class="co">// Enables coalesced memory access on GPU</span></span>
<span id="cb9-497"><a href="#cb9-497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-498"><a href="#cb9-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-499"><a href="#cb9-499" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb9-500"><a href="#cb9-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-501"><a href="#cb9-501" aria-hidden="true" tabindex="-1"></a>TensorAdaptors are the coordination layer that makes complex tensor operations possible:</span>
<span id="cb9-502"><a href="#cb9-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-503"><a href="#cb9-503" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Identity Adaptor**: Starting point for building transformations</span>
<span id="cb9-504"><a href="#cb9-504" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Transpose Adaptor**: Dimension reordering with permutation patterns</span>
<span id="cb9-505"><a href="#cb9-505" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Single-Stage Adaptors**: Custom transform chains with precise control</span>
<span id="cb9-506"><a href="#cb9-506" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Chained Adaptors**: Complex multi-stage transformation pipelines</span>
<span id="cb9-507"><a href="#cb9-507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Transform Addition**: Extending existing adaptors with new transforms</span>
<span id="cb9-508"><a href="#cb9-508" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Advanced Examples**: Complex nested transforms with flattening behavior</span>
<span id="cb9-509"><a href="#cb9-509" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**GPU Block Descriptors**: Real-world GPU memory layout patterns</span>
<span id="cb9-510"><a href="#cb9-510" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**C++ Equivalents**: **True working equivalent** of complex nested C++ transforms</span>
<span id="cb9-511"><a href="#cb9-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-512"><a href="#cb9-512" aria-hidden="true" tabindex="-1"></a>Key concepts:</span>
<span id="cb9-513"><a href="#cb9-513" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bottom/Top Dimensions**: Input and output coordinate spaces</span>
<span id="cb9-514"><a href="#cb9-514" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hidden Dimensions**: Internal coordinate mappings between transforms</span>
<span id="cb9-515"><a href="#cb9-515" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Transform Chains**: Sequential application of multiple transforms</span>
<span id="cb9-516"><a href="#cb9-516" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Coordinate Transformation**: Bidirectional mapping between coordinate spaces</span>
<span id="cb9-517"><a href="#cb9-517" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Nested Transforms**: Complex multi-level transformation hierarchies</span>
<span id="cb9-518"><a href="#cb9-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-519"><a href="#cb9-519" aria-hidden="true" tabindex="-1"></a><span class="fu">### Breakthrough Discovery</span></span>
<span id="cb9-520"><a href="#cb9-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-521"><a href="#cb9-521" aria-hidden="true" tabindex="-1"></a>We successfully created the **true C++ equivalent** of complex nested transforms:</span>
<span id="cb9-522"><a href="#cb9-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-523"><a href="#cb9-523" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-524"><a href="#cb9-524" aria-hidden="true" tabindex="-1"></a><span class="co"># C++ nested transform equivalent</span></span>
<span id="cb9-525"><a href="#cb9-525" aria-hidden="true" tabindex="-1"></a>cpp_equivalent <span class="op">=</span> make_single_stage_tensor_adaptor(</span>
<span id="cb9-526"><a href="#cb9-526" aria-hidden="true" tabindex="-1"></a>    transforms<span class="op">=</span>[</span>
<span id="cb9-527"><a href="#cb9-527" aria-hidden="true" tabindex="-1"></a>        UnmergeTransform([A, B, C]),  <span class="co"># Converts 3D (A,B,C) to 1D linear  </span></span>
<span id="cb9-528"><a href="#cb9-528" aria-hidden="true" tabindex="-1"></a>        PassThroughTransform(D)       <span class="co"># Passes through D dimension</span></span>
<span id="cb9-529"><a href="#cb9-529" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb9-530"><a href="#cb9-530" aria-hidden="true" tabindex="-1"></a>    lower_dimension_old_top_idss<span class="op">=</span>[[<span class="dv">0</span>], [<span class="dv">1</span>]],          <span class="co"># Transform inputs</span></span>
<span id="cb9-531"><a href="#cb9-531" aria-hidden="true" tabindex="-1"></a>    upper_dimension_new_top_idss<span class="op">=</span>[[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>]]     <span class="co"># Transform outputs</span></span>
<span id="cb9-532"><a href="#cb9-532" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-533"><a href="#cb9-533" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-534"><a href="#cb9-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-535"><a href="#cb9-535" aria-hidden="true" tabindex="-1"></a>**Key insights:**</span>
<span id="cb9-536"><a href="#cb9-536" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Transform direction**: Names refer to lower→higher, but <span class="in">`calculate_lower_index()`</span> goes higher→lower</span>
<span id="cb9-537"><a href="#cb9-537" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**UnmergeTransform**: Converts multi-D to linear when used with <span class="in">`calculate_lower_index()`</span></span>
<span id="cb9-538"><a href="#cb9-538" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Parameter mapping**: Controls the coordinate flow between dimensions</span>
<span id="cb9-539"><a href="#cb9-539" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Mathematical equivalence**: Exact same results as C++ nested structure</span>
<span id="cb9-540"><a href="#cb9-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-541"><a href="#cb9-541" aria-hidden="true" tabindex="-1"></a>TensorAdaptors bridge the gap between low-level transforms and high-level tensor operations, providing the flexibility to create sophisticated data layouts and access patterns that are essential for efficient GPU computing.</span>
<span id="cb9-542"><a href="#cb9-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-543"><a href="#cb9-543" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key C++ Patterns in Composable Kernel</span></span>
<span id="cb9-544"><a href="#cb9-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-545"><a href="#cb9-545" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Descriptor-Based Adaptors**: In CK, adaptors are typically embedded within tensor descriptors rather than created separately</span>
<span id="cb9-546"><a href="#cb9-546" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Compile-Time Optimization**: All transformations are resolved at compile time for zero overhead</span>
<span id="cb9-547"><a href="#cb9-547" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Type Safety**: Template metaprogramming ensures coordinate transformations are type-safe</span>
<span id="cb9-548"><a href="#cb9-548" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**GPU Optimization**: Transform chains are designed for efficient GPU memory access patterns</span>
<span id="cb9-549"><a href="#cb9-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-550"><a href="#cb9-550" aria-hidden="true" tabindex="-1"></a><span class="fu">### Common C++ Transform Chains</span></span>
<span id="cb9-551"><a href="#cb9-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-552"><a href="#cb9-552" aria-hidden="true" tabindex="-1"></a><span class="in">```cpp</span></span>
<span id="cb9-553"><a href="#cb9-553" aria-hidden="true" tabindex="-1"></a><span class="co">// Padding for convolution</span></span>
<span id="cb9-554"><a href="#cb9-554" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> padded <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-555"><a href="#cb9-555" aria-hidden="true" tabindex="-1"></a>    input<span class="op">,</span> </span>
<span id="cb9-556"><a href="#cb9-556" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_pad_transform<span class="op">(</span>H<span class="op">,</span> pad_h<span class="op">,</span> pad_h<span class="op">),</span></span>
<span id="cb9-557"><a href="#cb9-557" aria-hidden="true" tabindex="-1"></a>               make_pad_transform<span class="op">(</span>W<span class="op">,</span> pad_w<span class="op">,</span> pad_w<span class="op">)),</span></span>
<span id="cb9-558"><a href="#cb9-558" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{}),</span></span>
<span id="cb9-559"><a href="#cb9-559" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{},</span> sequence<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;{})</span></span>
<span id="cb9-560"><a href="#cb9-560" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-561"><a href="#cb9-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-562"><a href="#cb9-562" aria-hidden="true" tabindex="-1"></a><span class="co">// Dimension merging for GEMM</span></span>
<span id="cb9-563"><a href="#cb9-563" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> merged <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-564"><a href="#cb9-564" aria-hidden="true" tabindex="-1"></a>    input<span class="op">,</span></span>
<span id="cb9-565"><a href="#cb9-565" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_merge_transform<span class="op">(</span>make_tuple<span class="op">(</span>M<span class="op">,</span> K<span class="op">))),</span></span>
<span id="cb9-566"><a href="#cb9-566" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{}),</span></span>
<span id="cb9-567"><a href="#cb9-567" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;{})</span></span>
<span id="cb9-568"><a href="#cb9-568" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-569"><a href="#cb9-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-570"><a href="#cb9-570" aria-hidden="true" tabindex="-1"></a><span class="co">// Broadcasting for elementwise ops</span></span>
<span id="cb9-571"><a href="#cb9-571" aria-hidden="true" tabindex="-1"></a><span class="kw">auto</span> broadcast <span class="op">=</span> transform_tensor_descriptor<span class="op">(</span></span>
<span id="cb9-572"><a href="#cb9-572" aria-hidden="true" tabindex="-1"></a>    scalar<span class="op">,</span></span>
<span id="cb9-573"><a href="#cb9-573" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>make_replicate_transform<span class="op">(</span>make_tuple<span class="op">(</span>M<span class="op">,</span> N<span class="op">))),</span></span>
<span id="cb9-574"><a href="#cb9-574" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;&gt;{}),</span></span>
<span id="cb9-575"><a href="#cb9-575" aria-hidden="true" tabindex="-1"></a>    make_tuple<span class="op">(</span>sequence<span class="op">&lt;</span><span class="dv">0</span><span class="op">,</span> <span class="dv">1</span><span class="op">&gt;{})</span></span>
<span id="cb9-576"><a href="#cb9-576" aria-hidden="true" tabindex="-1"></a><span class="op">);</span></span>
<span id="cb9-577"><a href="#cb9-577" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-578"><a href="#cb9-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-579"><a href="#cb9-579" aria-hidden="true" tabindex="-1"></a>Next, we'll see how TensorAdaptors are combined with element space information to create complete **TensorDescriptors**.</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<script src="font-cleanup.js"></script>




</body></html>