[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tile Distribution Documentation",
    "section": "",
    "text": "Welcome to the complete tile distribution documentation! This is a standalone learning journey from basic memory concepts to advanced GPU optimization techniques.",
    "crumbs": [
      "Getting Started",
      "Tile Distribution Documentation"
    ]
  },
  {
    "objectID": "index.html#complete-learning-journey",
    "href": "index.html#complete-learning-journey",
    "title": "Tile Distribution Documentation",
    "section": "🎓 Complete Learning Journey",
    "text": "🎓 Complete Learning Journey\nFollow our structured 8-part learning path:\n\nIntroduction and Motivation\n\nIntroduction and Motivation - Why tile distribution matters, GPU memory challenges, and the solution overview\n\n\n\nFoundation\n\nBuffer Views - Raw memory access\nTensor Views - Multi-dimensional structure\n\n\n\nTransformation Engine\n\nBasic Coordinates - MultiIndex fundamentals\nIndividual Transforms - Building blocks (EmbedTransform, UnmergeTransform, etc.)\nChaining Adaptors - Combining transforms into complex operations\nComplete Descriptors - Full tensor specifications with layouts\nConvolution Example - Practical convolution implementation\nSwizzling Example - Morton ordering and memory patterns\nAdvanced Coordinates - TensorCoordinate and movement operations\n\n\n\nDistribution API\n\nTile Distribution - The core API for work assignment\nTile Window - Data access gateway with windowing\nSweep Tile - Elegant iteration patterns\n\n\n\nCoordinate Systems\n\nCoordinate Systems - The mathematical foundation (P, Y, X, R, D spaces)\n\n\n\nImplementation Deep Dive\n\nEncoding Internals - How mathematical encoding creates transformation components\nStatic Distributed Tensor - Thread-local data containers and organization\n\n\n\nThread Mapping\n\nThread Mapping - Connecting to hardware, thread cooperation patterns\n\n\n\nComing Soon\n\nAdvanced Topics - Performance optimization and debugging",
    "crumbs": [
      "Getting Started",
      "Tile Distribution Documentation"
    ]
  },
  {
    "objectID": "index.html#interactive-applications",
    "href": "index.html#interactive-applications",
    "title": "Tile Distribution Documentation",
    "section": "🎮 Interactive Applications",
    "text": "🎮 Interactive Applications\nExplore tile distribution concepts through interactive web applications:\n\n📊 Tile Distribution Visualizer\nInteractive visualization of tile distribution structures and GPU memory layouts. Perfect for understanding how data is distributed across parallel processing elements.\n\n\n🔄 Tensor Transform Visualizer\nExplore tensor descriptor transformations with visual graphs and mathematical formulas. See how data layouts change through various transformations.\n\n\n🧵 Thread Visualization App\nVisualize GPU thread coordinate mapping and access patterns. Understand how individual threads access distributed tensor data.",
    "crumbs": [
      "Getting Started",
      "Tile Distribution Documentation"
    ]
  },
  {
    "objectID": "index.html#quick-test",
    "href": "index.html#quick-test",
    "title": "Tile Distribution Documentation",
    "section": "🚀 Quick Test",
    "text": "🚀 Quick Test\nLet’s verify everything is working:",
    "crumbs": [
      "Getting Started",
      "Tile Distribution Documentation"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-documentation",
    "href": "index.html#how-to-use-this-documentation",
    "title": "Tile Distribution Documentation",
    "section": "📖 How to Use This Documentation",
    "text": "📖 How to Use This Documentation\n\nFollow the learning path - Each part builds on the previous ones\nRun the code - All examples are interactive and executable\nExperiment - Modify the code to deepen your understanding\nTest yourself - Each section includes validation exercises\n\nReady to start? Begin with Part 0: Introduction and Motivation!",
    "crumbs": [
      "Getting Started",
      "Tile Distribution Documentation"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html",
    "href": "concepts/03_tile_distribution.html",
    "title": "Tile Distribution - The Core API",
    "section": "",
    "text": "TileDistribution is the heart of Composable Kernels’ efficient GPU computation. It automatically maps logical coordinates to physical threads and memory locations, eliminating the need for manual thread management. This is the high-level API that GPU programmers actually use.",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#overview",
    "href": "concepts/03_tile_distribution.html#overview",
    "title": "Tile Distribution - The Core API",
    "section": "",
    "text": "TileDistribution is the heart of Composable Kernels’ efficient GPU computation. It automatically maps logical coordinates to physical threads and memory locations, eliminating the need for manual thread management. This is the high-level API that GPU programmers actually use.",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#interactive-exploration",
    "href": "concepts/03_tile_distribution.html#interactive-exploration",
    "title": "Tile Distribution - The Core API",
    "section": "🎮 Interactive Exploration",
    "text": "🎮 Interactive Exploration\nExplore tile distribution concepts interactively:\n📊 Tile Distribution Visualizer - Interactive visualization of tile distribution structures and GPU memory layouts. Perfect for understanding how data is distributed across parallel processing elements.",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#what-is-tile-distribution",
    "href": "concepts/03_tile_distribution.html#what-is-tile-distribution",
    "title": "Tile Distribution - The Core API",
    "section": "What is Tile Distribution?",
    "text": "What is Tile Distribution?\nBefore diving into code, let’s understand the fundamental problem TileDistribution solves:\nThe Challenge: You have a 256×256 matrix multiplication and 64 GPU threads. How do you divide the work efficiently?\nThe Solution: TileDistribution automatically maps logical coordinates (like matrix position [i,j]) to physical threads and memory locations.\n🎯 Without TileDistribution:\n\nManual global memory address calculations\nComplex index arithmetic\nError-prone memory access patterns\nDifferent code for different matrix sizes\n\n🎯 With TileDistribution:\n\nAutomatic work assignment and memory access patterns\nSame code works for any size\nHardware-aware thread cooperation by copying data to the correct threads registers\nNo manual global memory address calculations\n\nKey Insight: TileDistribution basically provides two functions, that given the warp id and thread id, it returns the global memory address and the access pattern for the thread.",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#creating-real-world-distributions",
    "href": "concepts/03_tile_distribution.html#creating-real-world-distributions",
    "title": "Tile Distribution - The Core API",
    "section": "Creating Real-World Distributions",
    "text": "Creating Real-World Distributions\nLet’s create a real tile distribution that is used for many operations including RMSNorm, a common GPU operation, for the sake of naming let’s call it RMSNorm Distribution.",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#understanding-distribution-structure",
    "href": "concepts/03_tile_distribution.html#understanding-distribution-structure",
    "title": "Tile Distribution - The Core API",
    "section": "Understanding Distribution Structure",
    "text": "Understanding Distribution Structure\nLet’s analyze what this distribution actually represents:\n📈 RMSNorm Distribution Structure:\nThe hierarchical structure breaks down as: - X0 (M dimension): 4×2×8×4 = 256 elements - X1 (N dimension): 4×2×8×4 = 256 elements - Total tile size: 256×256 - P dimensions: 2 (warp + thread within warp) - Y dimensions: 4 (access pattern) - R dimensions: 0 (no replication)\n🔄 P + Y → X Magic: P dimensions (thread partitioning) + Y dimensions (access patterns) = X dimensions (logical data)\nThis is the core CK pattern!",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#thread-work-assignments",
    "href": "concepts/03_tile_distribution.html#thread-work-assignments",
    "title": "Tile Distribution - The Core API",
    "section": "Thread Work Assignments",
    "text": "Thread Work Assignments\nNow let’s see how different threads get their work assignments:\n\n\n\n\n\n\n2D Thread Cooperation: Notice how threads in different positions (M,N) get different X coordinates. Thread[0,0] handles different data than Thread[1,0] or Thread[0,1]. This creates a 2D grid of work distribution where:\n\nM dimension changes: Thread[0,0] vs Thread[1,0] - different M positions\nN dimension changes: Thread[0,0] vs Thread[0,1] - different N positions\n\nEach thread gets a unique partition index and automatically calculates which data elements to process. This calculation works usually by utility functions in tile_window and sweep_tile.\nThe Magic: Notice what you DON’T see: manual thread ID arithmetic, complex index calculations, or memory offset computations. TileDistribution handles all of that automatically!",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#real-world-gpu-kernel-pattern",
    "href": "concepts/03_tile_distribution.html#real-world-gpu-kernel-pattern",
    "title": "Tile Distribution - The Core API",
    "section": "Real-World GPU Kernel Pattern",
    "text": "Real-World GPU Kernel Pattern\nHere’s how this looks in actual GPU kernel code:\n🔥 Typical CK Kernel Structure:\n__global__ void my_kernel() {\n    // 1. Get thread's partition index (automatic)\n    auto partition_idx = distribution.get_partition_index();\n    \n    // 2. Calculate this thread's coordinates (automatic)  \n    auto x_coords = distribution.calculate_index(partition_idx);\n    \n    // 3. Do the actual work\n    for (auto y_idx : y_access_pattern) {\n        auto data = load_from_memory(x_coords, y_idx);\n        auto result = compute(data);\n        store_to_memory(result, x_coords, y_idx);\n    }\n}\nThe Magic: Notice what you DON’T see: manual thread ID arithmetic, complex index calculations, or memory offset computations. TileDistribution handles all of that automatically!",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#comparing-distribution-patterns",
    "href": "concepts/03_tile_distribution.html#comparing-distribution-patterns",
    "title": "Tile Distribution - The Core API",
    "section": "Comparing Distribution Patterns",
    "text": "Comparing Distribution Patterns\nLet’s start simple and only focus on the Y dimension.",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#distribution-properties",
    "href": "concepts/03_tile_distribution.html#distribution-properties",
    "title": "Tile Distribution - The Core API",
    "section": "Distribution Properties",
    "text": "Distribution Properties\nLet’s explore important properties of tile distributions:",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#testing-your-understanding",
    "href": "concepts/03_tile_distribution.html#testing-your-understanding",
    "title": "Tile Distribution - The Core API",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that tile distribution operations work correctly:",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/03_tile_distribution.html#key-takeaways",
    "href": "concepts/03_tile_distribution.html#key-takeaways",
    "title": "Tile Distribution - The Core API",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nTileDistribution is the foundation of efficient GPU computation in Composable Kernels:\n1. Automatic Work Assignment\n\nMaps logical coordinates to physical threads\nEliminates manual thread ID calculations\nEnsures optimal work distribution\n\n2. Hardware-Aware Optimization\n\nOptimizes memory access patterns\nEnables efficient thread cooperation\nAdapts to different GPU architectures\n\n3. Scalable Design\n\nSame code works for any tensor size\nHandles complex hierarchical patterns\nSupports replication for broadcast operations\n\n4. Real-World Applications\n\nPowers operations like RMSNorm, GEMM, convolutions\nEnables high-performance AI/ML kernels\nSimplifies GPU programming complexity\n\nMaster TileDistribution, and you’re ready to understand how it connects to actual data access through TileWindow in the next section!",
    "crumbs": [
      "Distribution API",
      "Tile Distribution - The Core API"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html",
    "href": "concepts/00_introduction_motivation.html",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "",
    "text": "Before diving into any code, let’s establish the fundamental problem tile distribution solves and why it’s essential for GPU programming. Understanding the “why” will make all the subsequent concepts much clearer.\nLearning Objectives: - Understand the GPU memory coalescing challenge - See how tile distribution enables efficient thread cooperation - Get intuition for coordinate mapping concepts - Appreciate the performance benefits of structured data access",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#overview",
    "href": "concepts/00_introduction_motivation.html#overview",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "",
    "text": "Before diving into any code, let’s establish the fundamental problem tile distribution solves and why it’s essential for GPU programming. Understanding the “why” will make all the subsequent concepts much clearer.\nLearning Objectives: - Understand the GPU memory coalescing challenge - See how tile distribution enables efficient thread cooperation - Get intuition for coordinate mapping concepts - Appreciate the performance benefits of structured data access",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#the-gpu-memory-problem",
    "href": "concepts/00_introduction_motivation.html#the-gpu-memory-problem",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "The GPU Memory Problem",
    "text": "The GPU Memory Problem\n\nWhy Random Memory Access is Slow\nModern GPUs have incredible computational power, but they’re fundamentally limited by memory bandwidth. When thousands of threads try to access memory randomly, several problems occur:\n\nMemory Coalescing: GPU memory controllers work most efficiently when adjacent threads access adjacent memory locations. Random access patterns prevent this optimization.\nCache Efficiency: Random access patterns don’t benefit from cache locality, leading to frequent cache misses.\nThread Divergence: When threads in a warp access memory in unpredictable patterns, the hardware can’t optimize the memory requests.\n\n\n\nThe Thread Cooperation Challenge\nConsider a simple matrix multiplication where 256 threads need to cooperate:\n# Inefficient: Random access pattern\ndef naive_matrix_multiply():\n    thread_id = get_thread_id()\n    # Each thread randomly accesses matrix elements\n    # No coordination between threads\n    # Poor memory coalescing\n    pass\nProblems with this approach: - Unpredictable Memory Access: Threads access memory randomly - No Cooperation: Threads don’t coordinate their memory accesses - Poor Cache Utilization: No locality of reference - Inefficient Bandwidth Usage: Memory controllers can’t optimize",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#the-tile-distribution-solution",
    "href": "concepts/00_introduction_motivation.html#the-tile-distribution-solution",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "The Tile Distribution Solution",
    "text": "The Tile Distribution Solution\n\nStructured Mapping from Logical to Physical Coordinates\nTile distribution solves these problems by providing a structured mapping from logical coordinates (what data does each thread need?) to physical coordinates (where is that data in memory?).\n# Efficient: Tile-based distribution\ndef tile_distributed_matrix_multiply():\n    # 1. Each thread gets a unique tile of data\n    tile_distribution = make_static_tile_distribution(encoding)\n    \n    # 2. Threads cooperate to access memory efficiently\n    tile_window = make_tile_window(tensor_view, window_lengths, origin, tile_distribution)\n    \n    # 3. Memory accesses are coalesced and predictable\n    loaded_tensor = tile_window.load()\n    \n    # 4. Process tile data efficiently\n    def process_element(y_indices):\n        value = loaded_tensor.get_element(y_indices)\n        # ... efficient computation\n    \n    sweep_tile(loaded_tensor, process_element)\n\n\nKey Benefits\n\nPredictable Memory Access Patterns: Threads access memory in structured, predictable ways\nEfficient Thread Cooperation: Threads coordinate their memory accesses for optimal coalescing\nCache-Friendly Access: Spatial and temporal locality improve cache utilization\nScalable Performance: Patterns work across different GPU architectures and problem sizes",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#the-coordinate-mapping-insight",
    "href": "concepts/00_introduction_motivation.html#the-coordinate-mapping-insight",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "The Coordinate Mapping Insight",
    "text": "The Coordinate Mapping Insight\nThe key insight is that tile distribution provides a mathematical framework for mapping between different coordinate spaces:\n\nP-space: Where is each thread? (thread_x, thread_y, warp_id, block_id)\nY-space: What data does each thread need? (y0, y1, y2, y3)\nX-space: Where is that data physically located? (x0, x1)\nD-space: What’s the actual memory address? (linearized coordinates)\n\nThe magic happens in the transformations: P + Y → X → D",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#whats-coming-next",
    "href": "concepts/00_introduction_motivation.html#whats-coming-next",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "What’s Coming Next",
    "text": "What’s Coming Next\nNow that you understand why tile distribution matters, we’ll build up the complete system:\n\nFoundation: Start with raw memory and build up to structured tensors\nTransformation Engine: Learn the coordinate transformation engine\nDistribution API: Master the high-level tile distribution APIs\nCoordinate Systems: Understand the complete coordinate system\nImplementation: Dive into the internal implementation\nThread Mapping: See how it all connects to hardware threads\nAdvanced Topics: Learn advanced optimization techniques",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#interactive-learning-tools",
    "href": "concepts/00_introduction_motivation.html#interactive-learning-tools",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "🎮 Interactive Learning Tools",
    "text": "🎮 Interactive Learning Tools\nEnhance your learning with interactive applications:\n\n📊 Tile Distribution Visualizer - See memory access pattern comparisons, thread cooperation visualization, and performance impact demonstrations\n🔄 Tensor Transform Visualizer - Explore coordinate transformations with visual graphs\n\n🧵 Thread Visualization App - Visualize how threads map to data elements",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#summary",
    "href": "concepts/00_introduction_motivation.html#summary",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "Summary",
    "text": "Summary\nTile distribution isn’t just a technical detail—it’s the foundation that makes GPU computing efficient. By providing structured, predictable mappings between logical and physical coordinates, it enables:\n\nEfficient Memory Access: Coalesced, cache-friendly patterns\nThread Cooperation: Coordinated work distribution\nScalable Performance: Patterns that work across different hardware\nPredictable Optimization: Mathematical framework for performance tuning\n\nReady to see how it all works? Let’s start building from the foundation: From Raw Memory to Structured Tensors.",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/00_introduction_motivation.html#next-steps",
    "href": "concepts/00_introduction_motivation.html#next-steps",
    "title": "Introduction and Motivation - Why Tile Distribution Matters",
    "section": "Next Steps",
    "text": "Next Steps\nContinue to Buffer Views to start building your understanding from the ground up.",
    "crumbs": [
      "Foundation",
      "Introduction and Motivation - Why Tile Distribution Matters"
    ]
  },
  {
    "objectID": "concepts/02_tensor_coordinates.html",
    "href": "concepts/02_tensor_coordinates.html",
    "title": "Basic Coordinates",
    "section": "",
    "text": "Before diving into transforms and adaptors, we need to understand the basic coordinate system. MultiIndex is the fundamental building block used throughout the pytensor system.",
    "crumbs": [
      "Transformation Engine",
      "Basic Coordinates"
    ]
  },
  {
    "objectID": "concepts/02_tensor_coordinates.html#what-is-multiindex",
    "href": "concepts/02_tensor_coordinates.html#what-is-multiindex",
    "title": "Basic Coordinates",
    "section": "What is MultiIndex?",
    "text": "What is MultiIndex?\nMultiIndex represents a position in N-dimensional space - think of it as GPS coordinates for tensors:\n\nSimple: Just stores a list of integers\nFundamental: Used by all transforms, adaptors, and descriptors\nFlexible: Supports copying, comparison, and modification",
    "crumbs": [
      "Transformation Engine",
      "Basic Coordinates"
    ]
  },
  {
    "objectID": "concepts/02_tensor_coordinates.html#multiindex-basic-multi-dimensional-coordinates",
    "href": "concepts/02_tensor_coordinates.html#multiindex-basic-multi-dimensional-coordinates",
    "title": "Basic Coordinates",
    "section": "MultiIndex: Basic Multi-Dimensional Coordinates",
    "text": "MultiIndex: Basic Multi-Dimensional Coordinates\nMultiIndex is the simplest form of tensor coordinate - it represents a position in N-dimensional space:",
    "crumbs": [
      "Transformation Engine",
      "Basic Coordinates"
    ]
  },
  {
    "objectID": "concepts/02_tensor_coordinates.html#why-multiindex-matters",
    "href": "concepts/02_tensor_coordinates.html#why-multiindex-matters",
    "title": "Basic Coordinates",
    "section": "Why MultiIndex Matters",
    "text": "Why MultiIndex Matters\nMultiIndex is a simple but essential compile-time templated container in the C++ codebase. In the Python implementation, it serves as a runtime equivalent.\n\nWhat MultiIndex Actually Is\n\nCompile-time sized container: In C++, MultiIndex&lt;N&gt; has size known at compile time\nSimple coordinate storage: Just holds N integers representing positions in N-dimensional space\nTransform interface: Used as input/output for coordinate transformations\nBasic operations: Supports indexing, copying, and comparison\n\n\n\nWhere MultiIndex is Actually Used\nBased on the C++ codebase analysis:\n\nTransform inputs and outputs: Every transform takes and returns MultiIndex coordinates\nAdaptor coordinate tracking: TensorAdaptor uses MultiIndex to track positions through transform chains\nElement access: Tensor views use MultiIndex to specify which element to access",
    "crumbs": [
      "Transformation Engine",
      "Basic Coordinates"
    ]
  },
  {
    "objectID": "concepts/02_tensor_coordinates.html#quick-check",
    "href": "concepts/02_tensor_coordinates.html#quick-check",
    "title": "Basic Coordinates",
    "section": "Quick Check",
    "text": "Quick Check\nTry creating and modifying a MultiIndex yourself:",
    "crumbs": [
      "Transformation Engine",
      "Basic Coordinates"
    ]
  },
  {
    "objectID": "concepts/02_tensor_coordinates.html#key-takeaways",
    "href": "concepts/02_tensor_coordinates.html#key-takeaways",
    "title": "Basic Coordinates",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n🎯 MultiIndex: Your basic coordinate toolkit\n\nSimple but essential: MultiIndex is just a container for N integers, but it’s used everywhere in the coordinate system\nTransform interface: Every coordinate transformation takes MultiIndex input and produces MultiIndex output\nAdaptor foundation: TensorAdaptor chains coordinate transformations using MultiIndex to track positions\nElement access: Tensor views use MultiIndex to specify which element to access\n\nNext steps: - Learn individual transforms (merge, unmerge, pad, etc.) - Understand how adaptors chain transforms together - See how descriptors define complete tensor layouts - Master advanced coordinate operations\nMultiIndex is simple but powerful - master it now, and everything else will make sense!",
    "crumbs": [
      "Transformation Engine",
      "Basic Coordinates"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html",
    "href": "concepts/02_convolution_example.html",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "This chapter demonstrates a practical application of tensor descriptors by implementing convolution operations. We’ll progress from a naive implementation to an optimized approach using tensor descriptors, showing how they enable efficient memory access patterns for GPU acceleration. First we show how we can achieve the results using numpy implementation.\nThe convolution operation is fundamental in deep learning, and understanding its implementation details reveals how high-performance libraries achieve their efficiency. We’ll explore:\n\nNaive Implementation: Direct nested loops for reference\nWindow Extraction: Using NumPy’s as_strided for overlapping windows\nTensor Descriptor Windows: Achieving the same with tensor descriptors\nIm2col Transformation: Converting convolution to matrix multiplication\nMulti-channel Extension: Handling realistic deep learning scenarios\n\n\n\n\n# Import all required modules for the page\nimport sys\nsys.path.insert(0, \"../pytensor\")\nfrom pytensor.tensor_descriptor import (\n    make_naive_tensor_descriptor,\n    make_naive_tensor_descriptor_packed,\n    make_naive_tensor_descriptor_aligned,\n    transform_tensor_descriptor,\n    PassThroughTransform,\n    UnmergeTransform,\n    MergeTransform, make_merge_transform\n)\n\n\nimport numpy as np\nfrom pytensor.tensor_descriptor import (\n    EmbedTransform, MergeTransform, MultiIndex,\n    make_naive_tensor_descriptor, transform_tensor_descriptor,\n    make_merge_transform\n)\n\ndef create_test_data():\n    \"\"\"Create test data for convolution examples.\"\"\"\n    # 6x6 input image with sequential numbers (easier to follow)\n    image = np.arange(1, 37).reshape(6, 6)\n    \n    # Random 3x3 kernel for more interesting output\n    np.random.seed(42)  # For reproducible results\n    kernel = np.random.randint(-2, 3, (3, 3))\n    \n    return image, kernel\n\ndef print_matrix(matrix, title=\"Matrix\"):\n    \"\"\"Print a matrix in a nice format.\"\"\"\n    if title:\n        print(f\"\\n{title}:\")\n    if len(matrix.shape) == 2:\n        for row in matrix:\n            print(\" \".join(f\"{val:3.0f}\" if abs(val - round(val)) &lt; 1e-10 else f\"{val:3.1f}\" \n                          for val in row))\n    else:\n        print(f\"Shape: {matrix.shape}\")\n        print(matrix)\n\n\ndef print_windows_tiled(windows, title=\"Windows Tiled View\"):\n    \"\"\"Print 4D windows tensor as a tiled 2D layout with spacing.\"\"\"\n    if title:\n        print(f\"\\n{title}:\")\n    \n    out_h, out_w, K, K = windows.shape\n    \n    # Create separator patterns\n    # Each number takes 3 chars, separated by spaces, so K numbers = 3*K + (K-1) chars\n    window_width = 3 * K + (K - 1)\n    row_sep = \"-\" * window_width\n    col_sep = \" | \"\n    \n    for window_row in range(out_h):\n        # Print each row of windows\n        for k_row in range(K):\n            line_parts = []\n            for window_col in range(out_w):\n                window_data = \" \".join(f\"{val:3.0f}\" for val in windows[window_row, window_col, k_row, :])\n                line_parts.append(window_data)\n            print(col_sep.join(line_parts))\n        \n        # Print horizontal separator between window rows (except after last row)\n        if window_row &lt; out_h - 1:\n            # Create separator that aligns with the | characters in content lines\n            # Content uses \" | \" so separator should use \" + \"\n            sep_parts = [row_sep] * out_w\n            sep_line = (\" + \").join(sep_parts)\n            print(sep_line)\n    \n    print()  # Empty line for spacing\n\n# Create our test data\nimage, kernel = create_test_data()\nprint_matrix(image, \"6×6 Input Image\")\nprint_matrix(kernel, \"3×3 Kernel (Edge Detection)\")\n\n\n6×6 Input Image:\n  1   2   3   4   5   6\n  7   8   9  10  11  12\n 13  14  15  16  17  18\n 19  20  21  22  23  24\n 25  26  27  28  29  30\n 31  32  33  34  35  36\n\n3×3 Kernel (Edge Detection):\n  1   2   0\n  2   2  -1\n  0   0   0\n\n\n\n\n\nBefore diving into convolution, let’s understand how as_strided works with a simple example. We’ll start by tiling our matrix into non-overlapping blocks.\n\ndef demonstrate_simple_tiling():\n    \"\"\"Demonstrate simple tiling with as_strided (no overlap).\"\"\"\n    from numpy.lib.stride_tricks import as_strided\n    \n    # Create a simple 6x6 matrix\n    matrix = np.arange(1, 37).reshape(6, 6)\n    print_matrix(matrix, \"Original 6×6 Matrix\")\n    \n    # Tile into 2x2 blocks (no overlap)\n    tile_size = 2\n    matrix_h, matrix_w = matrix.shape\n    num_tiles_h = matrix_h // tile_size\n    num_tiles_w = matrix_w // tile_size\n    \n    print(f\"\\nTiling into {num_tiles_h}×{num_tiles_w} tiles of size {tile_size}×{tile_size}\")\n    print(f\"Original strides: {matrix.strides} (bytes per step)\")\n    \n    # Calculate new strides for tiling\n    # To move to next tile vertically: jump tile_size rows\n    # To move to next tile horizontally: jump tile_size columns  \n    # Within tile: use original strides\n    tiles = as_strided(\n        matrix,\n        shape=(num_tiles_h, num_tiles_w, tile_size, tile_size),\n        strides=(matrix.strides[0] * tile_size, matrix.strides[1] * tile_size, \n                matrix.strides[0], matrix.strides[1])\n    )\n    \n    print(f\"Tiles shape: {tiles.shape}\")\n    print(f\"New strides: {tiles.strides}\")\n    print(f\"Stride calculation:\")\n    print(f\"  - Move to next tile row: {matrix.strides[0]} × {tile_size} = {matrix.strides[0] * tile_size}\")\n    print(f\"  - Move to next tile col: {matrix.strides[1]} × {tile_size} = {matrix.strides[1] * tile_size}\")\n    print(f\"  - Within tile row: {matrix.strides[0]} (original)\")\n    print(f\"  - Within tile col: {matrix.strides[1]} (original)\")\n    \n    return tiles\n\n# Demonstrate simple tiling\ntiles = demonstrate_simple_tiling()\n\n# Show all tiles in tiled layout\nprint_windows_tiled(tiles, \"All 2×2 Tiles in Tiled Layout\")\n\n\nOriginal 6×6 Matrix:\n  1   2   3   4   5   6\n  7   8   9  10  11  12\n 13  14  15  16  17  18\n 19  20  21  22  23  24\n 25  26  27  28  29  30\n 31  32  33  34  35  36\n\nTiling into 3×3 tiles of size 2×2\nOriginal strides: (48, 8) (bytes per step)\nTiles shape: (3, 3, 2, 2)\nNew strides: (96, 16, 48, 8)\nStride calculation:\n  - Move to next tile row: 48 × 2 = 96\n  - Move to next tile col: 8 × 2 = 16\n  - Within tile row: 48 (original)\n  - Within tile col: 8 (original)\n\nAll 2×2 Tiles in Tiled Layout:\n  1   2 |   3   4 |   5   6\n  7   8 |   9  10 |  11  12\n------- + ------- + -------\n 13  14 |  15  16 |  17  18\n 19  20 |  21  22 |  23  24\n------- + ------- + -------\n 25  26 |  27  28 |  29  30\n 31  32 |  33  34 |  35  36\n\n\n\n\n\nThe key insight is understanding strides - how many bytes to skip to move to the next element in each dimension:\n\nOriginal matrix: shape=(6, 6), strides=(48, 8) (8 bytes per int64, 6 elements per row)\nTiled view: shape=(3, 3, 2, 2), strides=(96, 16, 48, 8)\n\nTo move to next tile row: skip 2 matrix rows = 48 × 2 = 96 bytes\nTo move to next tile col: skip 2 matrix cols = 8 × 2 = 16 bytes\n\nWithin tile: use original strides (48, 8)\n\n\n\n\n\n\nNow let’s see how to create overlapping windows - the foundation of convolution:\n\ndef demonstrate_overlapping_windows():\n    \"\"\"Demonstrate overlapping windows with as_strided.\"\"\"\n    from numpy.lib.stride_tricks import as_strided\n    \n    # Use our test image\n    image, _ = create_test_data()\n    print_matrix(image, \"6×6 Input Image\")\n    \n    # Extract 3x3 overlapping windows\n    K = 3  # kernel size\n    H, W = image.shape\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    print(f\"\\nExtracting {K}×{K} overlapping windows\")\n    print(f\"Output positions: {out_h}×{out_w} = {out_h * out_w} windows\")\n    print(f\"Original strides: {image.strides}\")\n    \n    # For overlapping windows, we move by 1 element (not tile_size)\n    # But within each window, we still use original strides\n    windows = as_strided(\n        image,\n        shape=(out_h, out_w, K, K),\n        strides=(image.strides[0], image.strides[1], image.strides[0], image.strides[1])\n    )\n    \n    print(f\"Windows shape: {windows.shape}\")\n    print(f\"New strides: {windows.strides}\")\n    print(f\"Stride meaning:\")\n    print(f\"  - Move to next window row: {image.strides[0]} (1 row down)\")\n    print(f\"  - Move to next window col: {image.strides[1]} (1 col right)\")\n    print(f\"  - Within window row: {image.strides[0]} (1 row down)\")\n    print(f\"  - Within window col: {image.strides[1]} (1 col right)\")\n    \n    return windows\n\n# Demonstrate overlapping windows\nwindows = demonstrate_overlapping_windows()\n\n# Show all overlapping windows in tiled layout\nprint_windows_tiled(windows, \"All 3×3 Overlapping Windows in Tiled Layout\")\n\nprint(f\"\\nNotice the overlap - adjacent windows share columns and rows!\")\n\n\n6×6 Input Image:\n  1   2   3   4   5   6\n  7   8   9  10  11  12\n 13  14  15  16  17  18\n 19  20  21  22  23  24\n 25  26  27  28  29  30\n 31  32  33  34  35  36\n\nExtracting 3×3 overlapping windows\nOutput positions: 4×4 = 16 windows\nOriginal strides: (48, 8)\nWindows shape: (4, 4, 3, 3)\nNew strides: (48, 8, 48, 8)\nStride meaning:\n  - Move to next window row: 48 (1 row down)\n  - Move to next window col: 8 (1 col right)\n  - Within window row: 48 (1 row down)\n  - Within window col: 8 (1 col right)\n\nAll 3×3 Overlapping Windows in Tiled Layout:\n  1   2   3 |   2   3   4 |   3   4   5 |   4   5   6\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n----------- + ----------- + ----------- + -----------\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n----------- + ----------- + ----------- + -----------\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n----------- + ----------- + ----------- + -----------\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n 31  32  33 |  32  33  34 |  33  34  35 |  34  35  36\n\n\nNotice the overlap - adjacent windows share columns and rows!\n\n\n\n\n\nNon-overlapping tiles: We skip by tile_size in strides: (stride[0] * tile_size, stride[1] * tile_size, ...)\nOverlapping windows: We skip by 1 in strides: (stride[0] * 1, stride[1] * 1, ...)\n\nThis creates sliding windows that overlap, which is exactly what we need for convolution!\n\n\n\n\nLet’s start with the most straightforward implementation using nested loops:\n\ndef naive_convolution_2d(image, kernel):\n    \"\"\"Reference implementation: naive 2D convolution with nested loops.\"\"\"\n    H, W = image.shape\n    K = kernel.shape[0]  # Assume square kernel\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    output = np.zeros((out_h, out_w))\n    \n    print(f\"Input shape: {image.shape}\")\n    print(f\"Kernel shape: {kernel.shape}\")\n    print(f\"Output shape: {output.shape}\")\n    \n    for i in range(out_h):\n        for j in range(out_w):\n            # Extract window\n            window = image[i:i+K, j:j+K]\n            # Apply convolution\n            output[i, j] = np.sum(window * kernel)\n    \n    return output\n\n# Run naive convolution\nreference_output = naive_convolution_2d(image, kernel)\nprint_matrix(reference_output, \"Naive Convolution Output\")\n\nInput shape: (6, 6)\nKernel shape: (3, 3)\nOutput shape: (4, 4)\n\nNaive Convolution Output:\n 26  32  38  44\n 62  68  74  80\n 98 104 110 116\n134 140 146 152\n\n\nThis implementation directly follows the mathematical definition of convolution. For each output position, we extract the corresponding window from the input image and compute the element-wise product with the kernel.\n\n\n\nNow let’s apply what we learned about overlapping windows to convolution. We need to extract all 3×3 windows for convolution:\n\ndef extract_windows_numpy(image, kernel_size=3):\n    \"\"\"Extract convolution windows using numpy as_strided.\"\"\"\n    from numpy.lib.stride_tricks import as_strided\n    \n    H, W = image.shape\n    K = kernel_size\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    # Use as_strided to create overlapping windows\n    windows = as_strided(\n        image,\n        shape=(out_h, out_w, K, K),\n        strides=(image.strides[0], image.strides[1], image.strides[0], image.strides[1])\n    )\n    \n    print(f\"Original image shape: {image.shape}\")\n    print(f\"Windows shape: {windows.shape}\")\n    print(f\"Memory view: 4D tensor [out_h, out_w, kernel_h, kernel_w]\")\n    \n    return windows\n\n# Extract windows\nwindows_numpy = extract_windows_numpy(image)\n\n# Show windows in tiled layout\nprint_windows_tiled(windows_numpy, \"All Windows in Tiled Layout\")\n\nOriginal image shape: (6, 6)\nWindows shape: (4, 4, 3, 3)\nMemory view: 4D tensor [out_h, out_w, kernel_h, kernel_w]\n\nAll Windows in Tiled Layout:\n  1   2   3 |   2   3   4 |   3   4   5 |   4   5   6\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n----------- + ----------- + ----------- + -----------\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n----------- + ----------- + ----------- + -----------\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n----------- + ----------- + ----------- + -----------\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n 31  32  33 |  32  33  34 |  33  34  35 |  34  35  36\n\n\n\nPerfect! We now have a 4D tensor [4, 4, 3, 3] containing all 16 convolution windows. Each [i, j, :, :] slice contains the window at output position (i, j).\n\n\n\nNow let’s achieve the same result using tensor descriptors, we have seen a similar results before when we learnt about the EmbedTransform that is behind make_naive_tensor_descriptor.\n\ndef extract_windows_tensor_descriptor(image, kernel_size=3):\n    \"\"\"Extract convolution windows using Tensor Descriptors.\"\"\"\n    H, W = image.shape\n    K = kernel_size\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    # Create tensor descriptor for 4D windows\n    window_lengths = [out_h, out_w, K, K]\n    window_strides = [W, 1, W, 1]  # Strides for overlapping windows\n    \n    windows_descriptor = make_naive_tensor_descriptor(window_lengths, window_strides)\n    \n    print(f\"Tensor descriptor shape: {windows_descriptor.get_lengths()}\")\n    print(f\"Element space size: {windows_descriptor.get_element_space_size()}\")\n    \n    # Extract windows using tensor descriptor\n    image_flat = image.flatten()\n    windows_td = np.zeros((out_h, out_w, K, K))\n    \n    for i in range(out_h):\n        for j in range(out_w):\n            for ki in range(K):\n                for kj in range(K):\n                    offset = windows_descriptor.calculate_offset([i, j, ki, kj])\n                    windows_td[i, j, ki, kj] = image_flat[offset]\n    \n    return windows_td\n\n# Extract windows using tensor descriptor\nwindows_td = extract_windows_tensor_descriptor(image)\n\n# Show all windows in tiled layout\nprint_windows_tiled(windows_td, \"All Windows in Tiled Layout (Tensor Descriptor)\")\n\nTensor descriptor shape: [4, 4, 3, 3]\nElement space size: 36\n\nAll Windows in Tiled Layout (Tensor Descriptor):\n  1   2   3 |   2   3   4 |   3   4   5 |   4   5   6\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n----------- + ----------- + ----------- + -----------\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n----------- + ----------- + ----------- + -----------\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n----------- + ----------- + ----------- + -----------\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n 31  32  33 |  32  33  34 |  33  34  35 |  34  35  36\n\n\n\nThe key insight is the stride pattern [W, 1, W, 1]:\n\nMoving one step in out_h direction requires jumping W elements (one row)\nMoving one step in out_w direction requires jumping 1 element (one column)\n\nMoving one step in kernel_h direction requires jumping W elements (one row)\nMoving one step in kernel_w direction requires jumping 1 element (one column)\n\n\n\nWe can see that we get the same results as we do in numpy approach.\n\n# Compare the two approaches\ndifference = np.linalg.norm(windows_numpy - windows_td)\nprint(f\"L2 norm of difference: {difference}\")\n\nif difference &lt; 1e-10:\n    print(\"✅ SUCCESS: Tensor descriptor windows identical to NumPy!\")\nelse:\n    print(\"❌ ERROR: Tensor descriptor windows differ from NumPy\")\n    print(f\"Max difference: {np.max(np.abs(windows_numpy - windows_td))}\")\n\nL2 norm of difference: 0.0\n✅ SUCCESS: Tensor descriptor windows identical to NumPy!\n\n\n\n\n\n\nThe next step is converting our 4D windows to a 2D matrix format suitable for matrix multiplication. This is called the “im2col” (image to column) transformation. This can be done by using reshape operator of numpy.\n\ndef im2col_numpy(windows):\n    \"\"\"Convert 4D windows to 2D im2col matrix using NumPy.\"\"\"\n    out_h, out_w, K, K = windows.shape\n    num_windows = out_h * out_w\n    patch_size = K * K\n    \n    # Reshape to 2D matrix\n    im2col_matrix = windows.reshape(num_windows, patch_size)\n    \n    print(f\"4D windows shape: {windows.shape}\")\n    print(f\"2D im2col shape: {im2col_matrix.shape}\")\n    print(f\"Transformation: [{out_h}, {out_w}, {K}, {K}] → [{num_windows}, {patch_size}]\")\n    \n    return im2col_matrix\n\n# Create im2col matrix\nim2col_numpy = im2col_numpy(windows_numpy)\n\n# Show the matrix structure\nprint(f\"\\nIm2col matrix (each row is a flattened window):\")\nout_h, out_w = 4, 4  # Our output dimensions\nfor i, row in enumerate(im2col_numpy):\n    win_i, win_j = i // out_w, i % out_w\n    print(f\"Row {i} (window [{win_i},{win_j}]): {' '.join(f'{val:3.0f}' for val in row)}\")\n\n4D windows shape: (4, 4, 3, 3)\n2D im2col shape: (16, 9)\nTransformation: [4, 4, 3, 3] → [16, 9]\n\nIm2col matrix (each row is a flattened window):\nRow 0 (window [0,0]):   1   2   3   7   8   9  13  14  15\nRow 1 (window [0,1]):   2   3   4   8   9  10  14  15  16\nRow 2 (window [0,2]):   3   4   5   9  10  11  15  16  17\nRow 3 (window [0,3]):   4   5   6  10  11  12  16  17  18\nRow 4 (window [1,0]):   7   8   9  13  14  15  19  20  21\nRow 5 (window [1,1]):   8   9  10  14  15  16  20  21  22\nRow 6 (window [1,2]):   9  10  11  15  16  17  21  22  23\nRow 7 (window [1,3]):  10  11  12  16  17  18  22  23  24\nRow 8 (window [2,0]):  13  14  15  19  20  21  25  26  27\nRow 9 (window [2,1]):  14  15  16  20  21  22  26  27  28\nRow 10 (window [2,2]):  15  16  17  21  22  23  27  28  29\nRow 11 (window [2,3]):  16  17  18  22  23  24  28  29  30\nRow 12 (window [3,0]):  19  20  21  25  26  27  31  32  33\nRow 13 (window [3,1]):  20  21  22  26  27  28  32  33  34\nRow 14 (window [3,2]):  21  22  23  27  28  29  33  34  35\nRow 15 (window [3,3]):  22  23  24  28  29  30  34  35  36\n\n\nEach row of the im2col matrix contains a flattened convolution window. This transformation allows us to compute all convolutions simultaneously using a single matrix multiplication.\n\n\n\nSince we already extracted windows using tensor descriptors, we can simply reshape them just like the NumPy version, let’s see how we can do it using the transformation pipelines.\n\n\nSince we already extracted the 4D windows using a tensor descriptor, the simplest way to get the im2col matrix is to just reshape the result, similar to how we handled the NumPy array.\n\ndef im2col_td_simple(windows_td):\n    \"\"\"Convert 4D tensor descriptor windows to 2D im2col matrix.\"\"\"\n    out_h, out_w, K, K = windows_td.shape\n    num_windows = out_h * out_w\n    patch_size = K * K\n    \n    # Reshape to 2D matrix\n    im2col_matrix = windows_td.reshape(num_windows, patch_size)\n    \n    print(f\"4D TD windows shape: {windows_td.shape}\")\n    print(f\"2D im2col (simple) shape: {im2col_matrix.shape}\")\n    \n    return im2col_matrix\n\n# Create im2col from tensor descriptor windows\nim2col_td_matrix = im2col_td_simple(windows_td)\n\n4D TD windows shape: (4, 4, 3, 3)\n2D im2col (simple) shape: (16, 9)\n\n\nPerfect! This is exactly the same as the NumPy approach - just reshape the 4D windows into a 2D matrix.\n\n\n\nHowever, tensor descriptors can also create the im2col layout directly without intermediate 4D windows. This is useful for GPU implementations:\n\nfrom pytensor.tensor_descriptor import make_merge_transform\n\ndef create_direct_im2col_descriptor(image, kernel_size=3):\n    \"\"\"Create im2col matrix directly using tensor descriptors.\"\"\"\n    H, W = image.shape\n    K = kernel_size\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    # Step 1: Create 4D windows descriptor\n    window_lengths = [out_h, out_w, K, K]\n    window_strides = [W, 1, W, 1]\n    windows_descriptor = make_naive_tensor_descriptor(window_lengths, window_strides)\n    \n    # Step 2: Apply merge transforms to create 2D im2col layout directly\n    merge_windows = make_merge_transform([out_h, out_w])  # Merge spatial output dimensions\n    merge_patch = make_merge_transform([K, K])  # Merge kernel dimensions\n    \n    im2col_descriptor = transform_tensor_descriptor( #\n        windows_descriptor,\n        transforms=[merge_windows, merge_patch],\n        lower_dimension_hidden_idss=[[0, 1], [2, 3]],\n        upper_dimension_hidden_idss=[[0], [1]]\n    )\n    \n    print(f\"Direct im2col descriptor shape: {im2col_descriptor.get_lengths()}\")\n    return im2col_descriptor\n\n# Create direct im2col descriptor\nim2col_descriptor = create_direct_im2col_descriptor(image)\n\n# This descriptor can directly compute offsets for the 2D im2col layout\nprint(f\"\\nExample: offset for window 0, patch element 0: {im2col_descriptor.calculate_offset([0, 0])}\")\nprint(f\"Example: offset for window 0, patch element 4: {im2col_descriptor.calculate_offset([0, 4])}\")\nprint(f\"Example: offset for window 1, patch element 0: {im2col_descriptor.calculate_offset([1, 0])}\")\n\n# Extract data using the direct descriptor\ndef extract_im2col_with_descriptor(image, descriptor):\n    \"\"\"Extract im2col matrix using tensor descriptor.\"\"\"\n    image_flat = image.flatten()\n    descriptor_shape = descriptor.get_lengths()\n    num_windows, patch_size = descriptor_shape\n    \n    im2col_matrix = np.zeros((num_windows, patch_size))\n    \n    for i in range(num_windows):\n        for j in range(patch_size):\n            offset = descriptor.calculate_offset([i, j])\n            im2col_matrix[i, j] = image_flat[offset]\n    \n    print(f\"Extracted im2col matrix using descriptor: {im2col_matrix.shape}\")\n    return im2col_matrix\n\n# Extract im2col matrix using tensor descriptor\nim2col_td_direct = extract_im2col_with_descriptor(image, im2col_descriptor)\n\n# Show the matrix structure\nprint(f\"\\nim2col_td_direct matrix (each row is a flattened window):\")\nout_h, out_w = 4, 4  # Our output dimensions\nfor i, row in enumerate(im2col_td_direct):\n    win_i, win_j = i // out_w, i % out_w\n    print(f\"Row {i} (window [{win_i},{win_j}]): {' '.join(f'{val:3.0f}' for val in row)}\")\n\nDirect im2col descriptor shape: [16, 9]\n\nExample: offset for window 0, patch element 0: 0\nExample: offset for window 0, patch element 4: 7\nExample: offset for window 1, patch element 0: 1\nExtracted im2col matrix using descriptor: (16, 9)\n\nim2col_td_direct matrix (each row is a flattened window):\nRow 0 (window [0,0]):   1   2   3   7   8   9  13  14  15\nRow 1 (window [0,1]):   2   3   4   8   9  10  14  15  16\nRow 2 (window [0,2]):   3   4   5   9  10  11  15  16  17\nRow 3 (window [0,3]):   4   5   6  10  11  12  16  17  18\nRow 4 (window [1,0]):   7   8   9  13  14  15  19  20  21\nRow 5 (window [1,1]):   8   9  10  14  15  16  20  21  22\nRow 6 (window [1,2]):   9  10  11  15  16  17  21  22  23\nRow 7 (window [1,3]):  10  11  12  16  17  18  22  23  24\nRow 8 (window [2,0]):  13  14  15  19  20  21  25  26  27\nRow 9 (window [2,1]):  14  15  16  20  21  22  26  27  28\nRow 10 (window [2,2]):  15  16  17  21  22  23  27  28  29\nRow 11 (window [2,3]):  16  17  18  22  23  24  28  29  30\nRow 12 (window [3,0]):  19  20  21  25  26  27  31  32  33\nRow 13 (window [3,1]):  20  21  22  26  27  28  32  33  34\nRow 14 (window [3,2]):  21  22  23  27  28  29  33  34  35\nRow 15 (window [3,3]):  22  23  24  28  29  30  34  35  36\n\n\n\n\n\n\nSimple reshape: Easy to understand, perfect for CPU implementations\nDirect tensor descriptor: Enables efficient GPU kernel generation where the hardware can directly compute memory addresses for the im2col layout without materializing intermediate 4D arrays\n\nThe advanced direct tensor descriptor approach uses two MergeTransform operations: 1. Merge spatial dimensions: [out_h, out_w] → num_windows 2. Merge kernel dimensions: [K, K] → patch_size\nThis transforms the 4D tensor [out_h, out_w, K, K] directly into a 2D matrix [num_windows, patch_size] without materializing the intermediate 4D array.\n\n\n\n\n# Compare NumPy approach with direct tensor descriptor approach\ndifference = np.linalg.norm(im2col_numpy - im2col_td_direct)\nprint(f\"L2 norm of difference (NumPy vs Tensor Descriptor): {difference}\")\n\nif difference &lt; 1e-10:\n    print(\"✅ SUCCESS: Tensor descriptor im2col identical to NumPy!\")\nelse:\n    print(\"❌ ERROR: Tensor descriptor im2col differs from NumPy\")\n    print(f\"Max difference: {np.max(np.abs(im2col_numpy - im2col_td_direct))}\")\n\n# Also verify that simple reshape gives same result\ndifference_simple = np.linalg.norm(im2col_numpy - im2col_td_matrix)\nprint(f\"\\nL2 norm of difference (NumPy vs Simple Reshape): {difference_simple}\")\nif difference_simple &lt; 1e-10:\n    print(\"✅ SUCCESS: Simple reshape approach also identical!\")\n\nL2 norm of difference (NumPy vs Tensor Descriptor): 0.0\n✅ SUCCESS: Tensor descriptor im2col identical to NumPy!\n\nL2 norm of difference (NumPy vs Simple Reshape): 0.0\n✅ SUCCESS: Simple reshape approach also identical!\n\n\n\n\n\n\nWith our im2col matrix ready, we can now perform convolution using simple matrix multiplication:\n\ndef convolution_with_im2col(im2col_matrix, kernel, out_shape):\n    \"\"\"Perform convolution using im2col matrix multiplication.\"\"\"\n    # Flatten kernel\n    kernel_flat = kernel.flatten()\n    \n    print(f\"Im2col matrix shape: {im2col_matrix.shape}\")\n    print(f\"Kernel flat shape: {kernel_flat.shape}\")\n    \n    # Matrix multiplication: each row of im2col with kernel\n    output_flat = im2col_matrix @ kernel_flat\n    \n    # Reshape to output dimensions\n    output = output_flat.reshape(out_shape)\n    \n    print(f\"Output flat shape: {output_flat.shape}\")\n    print(f\"Final output shape: {output.shape}\")\n    \n    return output\n\n# Perform convolution using im2col\nout_shape = reference_output.shape\nim2col_output = convolution_with_im2col(im2col_numpy, kernel, out_shape)\n\nprint_matrix(im2col_output, \"Convolution via Im2col\")\n\nIm2col matrix shape: (16, 9)\nKernel flat shape: (9,)\nOutput flat shape: (16,)\nFinal output shape: (4, 4)\n\nConvolution via Im2col:\n 26  32  38  44\n 62  68  74  80\n 98 104 110 116\n134 140 146 152\n\n\n\n\n\n# Verify that all methods produce the same result\ndifference = np.linalg.norm(reference_output - im2col_output)\nprint(f\"L2 norm difference (naive vs im2col): {difference}\")\n\nif difference &lt; 1e-10:\n    print(\"✅ SUCCESS: Im2col convolution matches naive reference!\")\nelse:\n    print(\"❌ ERROR: Im2col convolution differs from reference\")\n    print(f\"Max difference: {np.max(np.abs(reference_output - im2col_output))}\")\n\nL2 norm difference (naive vs im2col): 0.0\n✅ SUCCESS: Im2col convolution matches naive reference!\n\n\n\n\n\n\nReal-world deep learning scenarios involve multiple input and output channels. Let’s extend our approach:\n\ndef multi_channel_convolution():\n    \"\"\"Demonstrate multi-channel convolution.\"\"\"\n    # Create multi-channel input: 6x6x2 (2 input channels)\n    np.random.seed(123)\n    input_tensor = np.random.randint(0, 5, (6, 6, 2))\n    \n    # Create multi-channel filters: 3x3x2x3 (2 input, 3 output channels)\n    filters = np.random.randint(-1, 2, (3, 3, 2, 3))\n    \n    H, W, C_in = input_tensor.shape\n    K, K, C_in_filter, C_out = filters.shape\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    print(f\"Input shape: {input_tensor.shape}\")\n    print(f\"Filters shape: {filters.shape}\")\n    print(f\"Output shape: ({out_h}, {out_w}, {C_out})\")\n    \n    # Reference convolution with nested loops\n    reference_output = np.zeros((out_h, out_w, C_out))\n    for i in range(out_h):\n        for j in range(out_w):\n            for c_out in range(C_out):\n                window = input_tensor[i:i+K, j:j+K, :]  # [K, K, C_in]\n                reference_output[i, j, c_out] = np.sum(window * filters[:, :, :, c_out])\n    \n    # Im2col approach using direct as_strided (like the figure shows)\n    # Extract all channels at once using as_strided\n    from numpy.lib.stride_tricks import as_strided\n    \n    # Create 5D windows [out_h, out_w, K, K, C_in] directly\n    windows_5d = as_strided(\n        input_tensor,\n        shape=(out_h, out_w, K, K, C_in),\n        strides=(input_tensor.strides[0], input_tensor.strides[1], \n                input_tensor.strides[0], input_tensor.strides[1], input_tensor.strides[2])\n    )\n    \n    # Convert to im2col format: [num_windows, patch_size]\n    num_windows = out_h * out_w\n    patch_size = K * K * C_in\n    im2col_matrix = windows_5d.reshape(num_windows, patch_size)\n    \n    # Reshape filters and apply\n    filters_reshaped = filters.reshape(patch_size, C_out)\n    im2col_output_flat = im2col_matrix @ filters_reshaped\n    im2col_output = im2col_output_flat.reshape(out_h, out_w, C_out)\n    \n    print(f\"\\nIm2col matrix shape: {im2col_matrix.shape}\")\n    print(f\"Reshaped filters shape: {filters_reshaped.shape}\")\n    \n    # Compare results\n    difference = np.linalg.norm(reference_output - im2col_output)\n    print(f\"\\nL2 norm difference (reference vs im2col): {difference}\")\n    \n    if difference &lt; 1e-10:\n        print(\"✅ SUCCESS: Multi-channel im2col matches reference!\")\n    else:\n        print(\"❌ ERROR: Multi-channel results differ\")\n    \n    return reference_output, im2col_output\n\n# Run multi-channel demonstration\nmulti_channel_convolution()\n\nInput shape: (6, 6, 2)\nFilters shape: (3, 3, 2, 3)\nOutput shape: (4, 4, 3)\n\nIm2col matrix shape: (16, 18)\nReshaped filters shape: (18, 3)\n\nL2 norm difference (reference vs im2col): 0.0\n✅ SUCCESS: Multi-channel im2col matches reference!\n\n\n(array([[[  8.,   8.,  -9.],\n         [  7.,  14., -20.],\n         [ -1.,   6., -13.],\n         [  0.,   5., -13.]],\n \n        [[  4.,  22., -11.],\n         [  8.,   4., -10.],\n         [ 11.,   2., -14.],\n         [ 21.,  12., -16.]],\n \n        [[  6.,   5., -12.],\n         [ 14.,  13., -11.],\n         [  4.,  19., -16.],\n         [ 10.,   9., -14.]],\n \n        [[ 21.,   5., -15.],\n         [  8.,  10., -14.],\n         [ 10.,   8., -11.],\n         [  6.,  12., -16.]]]),\n array([[[  8,   8,  -9],\n         [  7,  14, -20],\n         [ -1,   6, -13],\n         [  0,   5, -13]],\n \n        [[  4,  22, -11],\n         [  8,   4, -10],\n         [ 11,   2, -14],\n         [ 21,  12, -16]],\n \n        [[  6,   5, -12],\n         [ 14,  13, -11],\n         [  4,  19, -16],\n         [ 10,   9, -14]],\n \n        [[ 21,   5, -15],\n         [  8,  10, -14],\n         [ 10,   8, -11],\n         [  6,  12, -16]]]))\n\n\nFor multi-channel convolution:\n\nInput: [H, W, C_in]\nFilters: [K, K, C_in, C_out]\nIm2col matrix: [num_windows, K×K×C_in]\nReshaped filters: [K×K×C_in, C_out]\nOutput: [out_h, out_w, C_out]\n\nThe same im2col principle applies, but now each window includes all input channels, and we can compute all output channels simultaneously.\n\n\n\nWe’ve demonstrated the complete evolution from naive convolution to optimized tensor descriptor-based implementation:\n\nNaive approach: Direct mathematical implementation with nested loops\nWindow extraction: Using as_strided to create efficient memory views\nTensor descriptors: Achieving the same with structured transformations\nIm2col transformation: Converting convolution to matrix multiplication\nMulti-channel extension: Scaling to realistic deep learning scenarios\n\n\n\n\nMemory efficiency: Tensor descriptors avoid data duplication by creating views\nParallelization: Im2col enables massive parallelization through matrix multiplication\nGeneralization: The tensor descriptor approach extends naturally to complex memory patterns\nGPU acceleration: These transformations form the foundation for efficient GPU kernels\n\nThe tensor descriptor system provides a unified framework for describing these transformations, making it possible to generate efficient code for various hardware architectures automatically. It is also important to note that the tensor descriptor machinary is implmented in compile time C++ code, therefore very efficient. This python implementation is just a simulator to demonstrate the concept.\n\n\n\n\n\n\nMethod\nMemory Usage\nParallelization\nGPU Suitability\n\n\n\n\nNaive loops\nLow\nPoor\nPoor\n\n\nAs_strided\nMedium\nGood\nLimited\n\n\nTensor descriptors\nMedium\nExcellent\nExcellent\n\n\nIm2col\nHigh\nExcellent\nExcellent\n\n\n\nTensor descriptors strike the optimal balance: they provide the parallelization benefits of im2col while maintaining the memory efficiency of strided operations, making them ideal for high-performance GPU implementations.",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#setup-and-test-data",
    "href": "concepts/02_convolution_example.html#setup-and-test-data",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "# Import all required modules for the page\nimport sys\nsys.path.insert(0, \"../pytensor\")\nfrom pytensor.tensor_descriptor import (\n    make_naive_tensor_descriptor,\n    make_naive_tensor_descriptor_packed,\n    make_naive_tensor_descriptor_aligned,\n    transform_tensor_descriptor,\n    PassThroughTransform,\n    UnmergeTransform,\n    MergeTransform, make_merge_transform\n)\n\n\nimport numpy as np\nfrom pytensor.tensor_descriptor import (\n    EmbedTransform, MergeTransform, MultiIndex,\n    make_naive_tensor_descriptor, transform_tensor_descriptor,\n    make_merge_transform\n)\n\ndef create_test_data():\n    \"\"\"Create test data for convolution examples.\"\"\"\n    # 6x6 input image with sequential numbers (easier to follow)\n    image = np.arange(1, 37).reshape(6, 6)\n    \n    # Random 3x3 kernel for more interesting output\n    np.random.seed(42)  # For reproducible results\n    kernel = np.random.randint(-2, 3, (3, 3))\n    \n    return image, kernel\n\ndef print_matrix(matrix, title=\"Matrix\"):\n    \"\"\"Print a matrix in a nice format.\"\"\"\n    if title:\n        print(f\"\\n{title}:\")\n    if len(matrix.shape) == 2:\n        for row in matrix:\n            print(\" \".join(f\"{val:3.0f}\" if abs(val - round(val)) &lt; 1e-10 else f\"{val:3.1f}\" \n                          for val in row))\n    else:\n        print(f\"Shape: {matrix.shape}\")\n        print(matrix)\n\n\ndef print_windows_tiled(windows, title=\"Windows Tiled View\"):\n    \"\"\"Print 4D windows tensor as a tiled 2D layout with spacing.\"\"\"\n    if title:\n        print(f\"\\n{title}:\")\n    \n    out_h, out_w, K, K = windows.shape\n    \n    # Create separator patterns\n    # Each number takes 3 chars, separated by spaces, so K numbers = 3*K + (K-1) chars\n    window_width = 3 * K + (K - 1)\n    row_sep = \"-\" * window_width\n    col_sep = \" | \"\n    \n    for window_row in range(out_h):\n        # Print each row of windows\n        for k_row in range(K):\n            line_parts = []\n            for window_col in range(out_w):\n                window_data = \" \".join(f\"{val:3.0f}\" for val in windows[window_row, window_col, k_row, :])\n                line_parts.append(window_data)\n            print(col_sep.join(line_parts))\n        \n        # Print horizontal separator between window rows (except after last row)\n        if window_row &lt; out_h - 1:\n            # Create separator that aligns with the | characters in content lines\n            # Content uses \" | \" so separator should use \" + \"\n            sep_parts = [row_sep] * out_w\n            sep_line = (\" + \").join(sep_parts)\n            print(sep_line)\n    \n    print()  # Empty line for spacing\n\n# Create our test data\nimage, kernel = create_test_data()\nprint_matrix(image, \"6×6 Input Image\")\nprint_matrix(kernel, \"3×3 Kernel (Edge Detection)\")\n\n\n6×6 Input Image:\n  1   2   3   4   5   6\n  7   8   9  10  11  12\n 13  14  15  16  17  18\n 19  20  21  22  23  24\n 25  26  27  28  29  30\n 31  32  33  34  35  36\n\n3×3 Kernel (Edge Detection):\n  1   2   0\n  2   2  -1\n  0   0   0",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#understanding-as_strided-simple-tiling-first",
    "href": "concepts/02_convolution_example.html#understanding-as_strided-simple-tiling-first",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Before diving into convolution, let’s understand how as_strided works with a simple example. We’ll start by tiling our matrix into non-overlapping blocks.\n\ndef demonstrate_simple_tiling():\n    \"\"\"Demonstrate simple tiling with as_strided (no overlap).\"\"\"\n    from numpy.lib.stride_tricks import as_strided\n    \n    # Create a simple 6x6 matrix\n    matrix = np.arange(1, 37).reshape(6, 6)\n    print_matrix(matrix, \"Original 6×6 Matrix\")\n    \n    # Tile into 2x2 blocks (no overlap)\n    tile_size = 2\n    matrix_h, matrix_w = matrix.shape\n    num_tiles_h = matrix_h // tile_size\n    num_tiles_w = matrix_w // tile_size\n    \n    print(f\"\\nTiling into {num_tiles_h}×{num_tiles_w} tiles of size {tile_size}×{tile_size}\")\n    print(f\"Original strides: {matrix.strides} (bytes per step)\")\n    \n    # Calculate new strides for tiling\n    # To move to next tile vertically: jump tile_size rows\n    # To move to next tile horizontally: jump tile_size columns  \n    # Within tile: use original strides\n    tiles = as_strided(\n        matrix,\n        shape=(num_tiles_h, num_tiles_w, tile_size, tile_size),\n        strides=(matrix.strides[0] * tile_size, matrix.strides[1] * tile_size, \n                matrix.strides[0], matrix.strides[1])\n    )\n    \n    print(f\"Tiles shape: {tiles.shape}\")\n    print(f\"New strides: {tiles.strides}\")\n    print(f\"Stride calculation:\")\n    print(f\"  - Move to next tile row: {matrix.strides[0]} × {tile_size} = {matrix.strides[0] * tile_size}\")\n    print(f\"  - Move to next tile col: {matrix.strides[1]} × {tile_size} = {matrix.strides[1] * tile_size}\")\n    print(f\"  - Within tile row: {matrix.strides[0]} (original)\")\n    print(f\"  - Within tile col: {matrix.strides[1]} (original)\")\n    \n    return tiles\n\n# Demonstrate simple tiling\ntiles = demonstrate_simple_tiling()\n\n# Show all tiles in tiled layout\nprint_windows_tiled(tiles, \"All 2×2 Tiles in Tiled Layout\")\n\n\nOriginal 6×6 Matrix:\n  1   2   3   4   5   6\n  7   8   9  10  11  12\n 13  14  15  16  17  18\n 19  20  21  22  23  24\n 25  26  27  28  29  30\n 31  32  33  34  35  36\n\nTiling into 3×3 tiles of size 2×2\nOriginal strides: (48, 8) (bytes per step)\nTiles shape: (3, 3, 2, 2)\nNew strides: (96, 16, 48, 8)\nStride calculation:\n  - Move to next tile row: 48 × 2 = 96\n  - Move to next tile col: 8 × 2 = 16\n  - Within tile row: 48 (original)\n  - Within tile col: 8 (original)\n\nAll 2×2 Tiles in Tiled Layout:\n  1   2 |   3   4 |   5   6\n  7   8 |   9  10 |  11  12\n------- + ------- + -------\n 13  14 |  15  16 |  17  18\n 19  20 |  21  22 |  23  24\n------- + ------- + -------\n 25  26 |  27  28 |  29  30\n 31  32 |  33  34 |  35  36\n\n\n\n\n\nThe key insight is understanding strides - how many bytes to skip to move to the next element in each dimension:\n\nOriginal matrix: shape=(6, 6), strides=(48, 8) (8 bytes per int64, 6 elements per row)\nTiled view: shape=(3, 3, 2, 2), strides=(96, 16, 48, 8)\n\nTo move to next tile row: skip 2 matrix rows = 48 × 2 = 96 bytes\nTo move to next tile col: skip 2 matrix cols = 8 × 2 = 16 bytes\n\nWithin tile: use original strides (48, 8)",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#overlapping-windows-with-as_strided",
    "href": "concepts/02_convolution_example.html#overlapping-windows-with-as_strided",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Now let’s see how to create overlapping windows - the foundation of convolution:\n\ndef demonstrate_overlapping_windows():\n    \"\"\"Demonstrate overlapping windows with as_strided.\"\"\"\n    from numpy.lib.stride_tricks import as_strided\n    \n    # Use our test image\n    image, _ = create_test_data()\n    print_matrix(image, \"6×6 Input Image\")\n    \n    # Extract 3x3 overlapping windows\n    K = 3  # kernel size\n    H, W = image.shape\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    print(f\"\\nExtracting {K}×{K} overlapping windows\")\n    print(f\"Output positions: {out_h}×{out_w} = {out_h * out_w} windows\")\n    print(f\"Original strides: {image.strides}\")\n    \n    # For overlapping windows, we move by 1 element (not tile_size)\n    # But within each window, we still use original strides\n    windows = as_strided(\n        image,\n        shape=(out_h, out_w, K, K),\n        strides=(image.strides[0], image.strides[1], image.strides[0], image.strides[1])\n    )\n    \n    print(f\"Windows shape: {windows.shape}\")\n    print(f\"New strides: {windows.strides}\")\n    print(f\"Stride meaning:\")\n    print(f\"  - Move to next window row: {image.strides[0]} (1 row down)\")\n    print(f\"  - Move to next window col: {image.strides[1]} (1 col right)\")\n    print(f\"  - Within window row: {image.strides[0]} (1 row down)\")\n    print(f\"  - Within window col: {image.strides[1]} (1 col right)\")\n    \n    return windows\n\n# Demonstrate overlapping windows\nwindows = demonstrate_overlapping_windows()\n\n# Show all overlapping windows in tiled layout\nprint_windows_tiled(windows, \"All 3×3 Overlapping Windows in Tiled Layout\")\n\nprint(f\"\\nNotice the overlap - adjacent windows share columns and rows!\")\n\n\n6×6 Input Image:\n  1   2   3   4   5   6\n  7   8   9  10  11  12\n 13  14  15  16  17  18\n 19  20  21  22  23  24\n 25  26  27  28  29  30\n 31  32  33  34  35  36\n\nExtracting 3×3 overlapping windows\nOutput positions: 4×4 = 16 windows\nOriginal strides: (48, 8)\nWindows shape: (4, 4, 3, 3)\nNew strides: (48, 8, 48, 8)\nStride meaning:\n  - Move to next window row: 48 (1 row down)\n  - Move to next window col: 8 (1 col right)\n  - Within window row: 48 (1 row down)\n  - Within window col: 8 (1 col right)\n\nAll 3×3 Overlapping Windows in Tiled Layout:\n  1   2   3 |   2   3   4 |   3   4   5 |   4   5   6\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n----------- + ----------- + ----------- + -----------\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n----------- + ----------- + ----------- + -----------\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n----------- + ----------- + ----------- + -----------\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n 31  32  33 |  32  33  34 |  33  34  35 |  34  35  36\n\n\nNotice the overlap - adjacent windows share columns and rows!\n\n\n\n\n\nNon-overlapping tiles: We skip by tile_size in strides: (stride[0] * tile_size, stride[1] * tile_size, ...)\nOverlapping windows: We skip by 1 in strides: (stride[0] * 1, stride[1] * 1, ...)\n\nThis creates sliding windows that overlap, which is exactly what we need for convolution!",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#naive-convolution-reference",
    "href": "concepts/02_convolution_example.html#naive-convolution-reference",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Let’s start with the most straightforward implementation using nested loops:\n\ndef naive_convolution_2d(image, kernel):\n    \"\"\"Reference implementation: naive 2D convolution with nested loops.\"\"\"\n    H, W = image.shape\n    K = kernel.shape[0]  # Assume square kernel\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    output = np.zeros((out_h, out_w))\n    \n    print(f\"Input shape: {image.shape}\")\n    print(f\"Kernel shape: {kernel.shape}\")\n    print(f\"Output shape: {output.shape}\")\n    \n    for i in range(out_h):\n        for j in range(out_w):\n            # Extract window\n            window = image[i:i+K, j:j+K]\n            # Apply convolution\n            output[i, j] = np.sum(window * kernel)\n    \n    return output\n\n# Run naive convolution\nreference_output = naive_convolution_2d(image, kernel)\nprint_matrix(reference_output, \"Naive Convolution Output\")\n\nInput shape: (6, 6)\nKernel shape: (3, 3)\nOutput shape: (4, 4)\n\nNaive Convolution Output:\n 26  32  38  44\n 62  68  74  80\n 98 104 110 116\n134 140 146 152\n\n\nThis implementation directly follows the mathematical definition of convolution. For each output position, we extract the corresponding window from the input image and compute the element-wise product with the kernel.",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#window-extraction-with-numpy-as_strided",
    "href": "concepts/02_convolution_example.html#window-extraction-with-numpy-as_strided",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Now let’s apply what we learned about overlapping windows to convolution. We need to extract all 3×3 windows for convolution:\n\ndef extract_windows_numpy(image, kernel_size=3):\n    \"\"\"Extract convolution windows using numpy as_strided.\"\"\"\n    from numpy.lib.stride_tricks import as_strided\n    \n    H, W = image.shape\n    K = kernel_size\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    # Use as_strided to create overlapping windows\n    windows = as_strided(\n        image,\n        shape=(out_h, out_w, K, K),\n        strides=(image.strides[0], image.strides[1], image.strides[0], image.strides[1])\n    )\n    \n    print(f\"Original image shape: {image.shape}\")\n    print(f\"Windows shape: {windows.shape}\")\n    print(f\"Memory view: 4D tensor [out_h, out_w, kernel_h, kernel_w]\")\n    \n    return windows\n\n# Extract windows\nwindows_numpy = extract_windows_numpy(image)\n\n# Show windows in tiled layout\nprint_windows_tiled(windows_numpy, \"All Windows in Tiled Layout\")\n\nOriginal image shape: (6, 6)\nWindows shape: (4, 4, 3, 3)\nMemory view: 4D tensor [out_h, out_w, kernel_h, kernel_w]\n\nAll Windows in Tiled Layout:\n  1   2   3 |   2   3   4 |   3   4   5 |   4   5   6\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n----------- + ----------- + ----------- + -----------\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n----------- + ----------- + ----------- + -----------\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n----------- + ----------- + ----------- + -----------\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n 31  32  33 |  32  33  34 |  33  34  35 |  34  35  36\n\n\n\nPerfect! We now have a 4D tensor [4, 4, 3, 3] containing all 16 convolution windows. Each [i, j, :, :] slice contains the window at output position (i, j).",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#window-extraction-with-tensor-descriptors",
    "href": "concepts/02_convolution_example.html#window-extraction-with-tensor-descriptors",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Now let’s achieve the same result using tensor descriptors, we have seen a similar results before when we learnt about the EmbedTransform that is behind make_naive_tensor_descriptor.\n\ndef extract_windows_tensor_descriptor(image, kernel_size=3):\n    \"\"\"Extract convolution windows using Tensor Descriptors.\"\"\"\n    H, W = image.shape\n    K = kernel_size\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    # Create tensor descriptor for 4D windows\n    window_lengths = [out_h, out_w, K, K]\n    window_strides = [W, 1, W, 1]  # Strides for overlapping windows\n    \n    windows_descriptor = make_naive_tensor_descriptor(window_lengths, window_strides)\n    \n    print(f\"Tensor descriptor shape: {windows_descriptor.get_lengths()}\")\n    print(f\"Element space size: {windows_descriptor.get_element_space_size()}\")\n    \n    # Extract windows using tensor descriptor\n    image_flat = image.flatten()\n    windows_td = np.zeros((out_h, out_w, K, K))\n    \n    for i in range(out_h):\n        for j in range(out_w):\n            for ki in range(K):\n                for kj in range(K):\n                    offset = windows_descriptor.calculate_offset([i, j, ki, kj])\n                    windows_td[i, j, ki, kj] = image_flat[offset]\n    \n    return windows_td\n\n# Extract windows using tensor descriptor\nwindows_td = extract_windows_tensor_descriptor(image)\n\n# Show all windows in tiled layout\nprint_windows_tiled(windows_td, \"All Windows in Tiled Layout (Tensor Descriptor)\")\n\nTensor descriptor shape: [4, 4, 3, 3]\nElement space size: 36\n\nAll Windows in Tiled Layout (Tensor Descriptor):\n  1   2   3 |   2   3   4 |   3   4   5 |   4   5   6\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n----------- + ----------- + ----------- + -----------\n  7   8   9 |   8   9  10 |   9  10  11 |  10  11  12\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n----------- + ----------- + ----------- + -----------\n 13  14  15 |  14  15  16 |  15  16  17 |  16  17  18\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n----------- + ----------- + ----------- + -----------\n 19  20  21 |  20  21  22 |  21  22  23 |  22  23  24\n 25  26  27 |  26  27  28 |  27  28  29 |  28  29  30\n 31  32  33 |  32  33  34 |  33  34  35 |  34  35  36\n\n\n\nThe key insight is the stride pattern [W, 1, W, 1]:\n\nMoving one step in out_h direction requires jumping W elements (one row)\nMoving one step in out_w direction requires jumping 1 element (one column)\n\nMoving one step in kernel_h direction requires jumping W elements (one row)\nMoving one step in kernel_w direction requires jumping 1 element (one column)\n\n\n\nWe can see that we get the same results as we do in numpy approach.\n\n# Compare the two approaches\ndifference = np.linalg.norm(windows_numpy - windows_td)\nprint(f\"L2 norm of difference: {difference}\")\n\nif difference &lt; 1e-10:\n    print(\"✅ SUCCESS: Tensor descriptor windows identical to NumPy!\")\nelse:\n    print(\"❌ ERROR: Tensor descriptor windows differ from NumPy\")\n    print(f\"Max difference: {np.max(np.abs(windows_numpy - windows_td))}\")\n\nL2 norm of difference: 0.0\n✅ SUCCESS: Tensor descriptor windows identical to NumPy!",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#im2col-transformation-with-numpy",
    "href": "concepts/02_convolution_example.html#im2col-transformation-with-numpy",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "The next step is converting our 4D windows to a 2D matrix format suitable for matrix multiplication. This is called the “im2col” (image to column) transformation. This can be done by using reshape operator of numpy.\n\ndef im2col_numpy(windows):\n    \"\"\"Convert 4D windows to 2D im2col matrix using NumPy.\"\"\"\n    out_h, out_w, K, K = windows.shape\n    num_windows = out_h * out_w\n    patch_size = K * K\n    \n    # Reshape to 2D matrix\n    im2col_matrix = windows.reshape(num_windows, patch_size)\n    \n    print(f\"4D windows shape: {windows.shape}\")\n    print(f\"2D im2col shape: {im2col_matrix.shape}\")\n    print(f\"Transformation: [{out_h}, {out_w}, {K}, {K}] → [{num_windows}, {patch_size}]\")\n    \n    return im2col_matrix\n\n# Create im2col matrix\nim2col_numpy = im2col_numpy(windows_numpy)\n\n# Show the matrix structure\nprint(f\"\\nIm2col matrix (each row is a flattened window):\")\nout_h, out_w = 4, 4  # Our output dimensions\nfor i, row in enumerate(im2col_numpy):\n    win_i, win_j = i // out_w, i % out_w\n    print(f\"Row {i} (window [{win_i},{win_j}]): {' '.join(f'{val:3.0f}' for val in row)}\")\n\n4D windows shape: (4, 4, 3, 3)\n2D im2col shape: (16, 9)\nTransformation: [4, 4, 3, 3] → [16, 9]\n\nIm2col matrix (each row is a flattened window):\nRow 0 (window [0,0]):   1   2   3   7   8   9  13  14  15\nRow 1 (window [0,1]):   2   3   4   8   9  10  14  15  16\nRow 2 (window [0,2]):   3   4   5   9  10  11  15  16  17\nRow 3 (window [0,3]):   4   5   6  10  11  12  16  17  18\nRow 4 (window [1,0]):   7   8   9  13  14  15  19  20  21\nRow 5 (window [1,1]):   8   9  10  14  15  16  20  21  22\nRow 6 (window [1,2]):   9  10  11  15  16  17  21  22  23\nRow 7 (window [1,3]):  10  11  12  16  17  18  22  23  24\nRow 8 (window [2,0]):  13  14  15  19  20  21  25  26  27\nRow 9 (window [2,1]):  14  15  16  20  21  22  26  27  28\nRow 10 (window [2,2]):  15  16  17  21  22  23  27  28  29\nRow 11 (window [2,3]):  16  17  18  22  23  24  28  29  30\nRow 12 (window [3,0]):  19  20  21  25  26  27  31  32  33\nRow 13 (window [3,1]):  20  21  22  26  27  28  32  33  34\nRow 14 (window [3,2]):  21  22  23  27  28  29  33  34  35\nRow 15 (window [3,3]):  22  23  24  28  29  30  34  35  36\n\n\nEach row of the im2col matrix contains a flattened convolution window. This transformation allows us to compute all convolutions simultaneously using a single matrix multiplication.",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#im2col-with-tensor-descriptors",
    "href": "concepts/02_convolution_example.html#im2col-with-tensor-descriptors",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Since we already extracted windows using tensor descriptors, we can simply reshape them just like the NumPy version, let’s see how we can do it using the transformation pipelines.\n\n\nSince we already extracted the 4D windows using a tensor descriptor, the simplest way to get the im2col matrix is to just reshape the result, similar to how we handled the NumPy array.\n\ndef im2col_td_simple(windows_td):\n    \"\"\"Convert 4D tensor descriptor windows to 2D im2col matrix.\"\"\"\n    out_h, out_w, K, K = windows_td.shape\n    num_windows = out_h * out_w\n    patch_size = K * K\n    \n    # Reshape to 2D matrix\n    im2col_matrix = windows_td.reshape(num_windows, patch_size)\n    \n    print(f\"4D TD windows shape: {windows_td.shape}\")\n    print(f\"2D im2col (simple) shape: {im2col_matrix.shape}\")\n    \n    return im2col_matrix\n\n# Create im2col from tensor descriptor windows\nim2col_td_matrix = im2col_td_simple(windows_td)\n\n4D TD windows shape: (4, 4, 3, 3)\n2D im2col (simple) shape: (16, 9)\n\n\nPerfect! This is exactly the same as the NumPy approach - just reshape the 4D windows into a 2D matrix.\n\n\n\nHowever, tensor descriptors can also create the im2col layout directly without intermediate 4D windows. This is useful for GPU implementations:\n\nfrom pytensor.tensor_descriptor import make_merge_transform\n\ndef create_direct_im2col_descriptor(image, kernel_size=3):\n    \"\"\"Create im2col matrix directly using tensor descriptors.\"\"\"\n    H, W = image.shape\n    K = kernel_size\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    # Step 1: Create 4D windows descriptor\n    window_lengths = [out_h, out_w, K, K]\n    window_strides = [W, 1, W, 1]\n    windows_descriptor = make_naive_tensor_descriptor(window_lengths, window_strides)\n    \n    # Step 2: Apply merge transforms to create 2D im2col layout directly\n    merge_windows = make_merge_transform([out_h, out_w])  # Merge spatial output dimensions\n    merge_patch = make_merge_transform([K, K])  # Merge kernel dimensions\n    \n    im2col_descriptor = transform_tensor_descriptor( #\n        windows_descriptor,\n        transforms=[merge_windows, merge_patch],\n        lower_dimension_hidden_idss=[[0, 1], [2, 3]],\n        upper_dimension_hidden_idss=[[0], [1]]\n    )\n    \n    print(f\"Direct im2col descriptor shape: {im2col_descriptor.get_lengths()}\")\n    return im2col_descriptor\n\n# Create direct im2col descriptor\nim2col_descriptor = create_direct_im2col_descriptor(image)\n\n# This descriptor can directly compute offsets for the 2D im2col layout\nprint(f\"\\nExample: offset for window 0, patch element 0: {im2col_descriptor.calculate_offset([0, 0])}\")\nprint(f\"Example: offset for window 0, patch element 4: {im2col_descriptor.calculate_offset([0, 4])}\")\nprint(f\"Example: offset for window 1, patch element 0: {im2col_descriptor.calculate_offset([1, 0])}\")\n\n# Extract data using the direct descriptor\ndef extract_im2col_with_descriptor(image, descriptor):\n    \"\"\"Extract im2col matrix using tensor descriptor.\"\"\"\n    image_flat = image.flatten()\n    descriptor_shape = descriptor.get_lengths()\n    num_windows, patch_size = descriptor_shape\n    \n    im2col_matrix = np.zeros((num_windows, patch_size))\n    \n    for i in range(num_windows):\n        for j in range(patch_size):\n            offset = descriptor.calculate_offset([i, j])\n            im2col_matrix[i, j] = image_flat[offset]\n    \n    print(f\"Extracted im2col matrix using descriptor: {im2col_matrix.shape}\")\n    return im2col_matrix\n\n# Extract im2col matrix using tensor descriptor\nim2col_td_direct = extract_im2col_with_descriptor(image, im2col_descriptor)\n\n# Show the matrix structure\nprint(f\"\\nim2col_td_direct matrix (each row is a flattened window):\")\nout_h, out_w = 4, 4  # Our output dimensions\nfor i, row in enumerate(im2col_td_direct):\n    win_i, win_j = i // out_w, i % out_w\n    print(f\"Row {i} (window [{win_i},{win_j}]): {' '.join(f'{val:3.0f}' for val in row)}\")\n\nDirect im2col descriptor shape: [16, 9]\n\nExample: offset for window 0, patch element 0: 0\nExample: offset for window 0, patch element 4: 7\nExample: offset for window 1, patch element 0: 1\nExtracted im2col matrix using descriptor: (16, 9)\n\nim2col_td_direct matrix (each row is a flattened window):\nRow 0 (window [0,0]):   1   2   3   7   8   9  13  14  15\nRow 1 (window [0,1]):   2   3   4   8   9  10  14  15  16\nRow 2 (window [0,2]):   3   4   5   9  10  11  15  16  17\nRow 3 (window [0,3]):   4   5   6  10  11  12  16  17  18\nRow 4 (window [1,0]):   7   8   9  13  14  15  19  20  21\nRow 5 (window [1,1]):   8   9  10  14  15  16  20  21  22\nRow 6 (window [1,2]):   9  10  11  15  16  17  21  22  23\nRow 7 (window [1,3]):  10  11  12  16  17  18  22  23  24\nRow 8 (window [2,0]):  13  14  15  19  20  21  25  26  27\nRow 9 (window [2,1]):  14  15  16  20  21  22  26  27  28\nRow 10 (window [2,2]):  15  16  17  21  22  23  27  28  29\nRow 11 (window [2,3]):  16  17  18  22  23  24  28  29  30\nRow 12 (window [3,0]):  19  20  21  25  26  27  31  32  33\nRow 13 (window [3,1]):  20  21  22  26  27  28  32  33  34\nRow 14 (window [3,2]):  21  22  23  27  28  29  33  34  35\nRow 15 (window [3,3]):  22  23  24  28  29  30  34  35  36\n\n\n\n\n\n\nSimple reshape: Easy to understand, perfect for CPU implementations\nDirect tensor descriptor: Enables efficient GPU kernel generation where the hardware can directly compute memory addresses for the im2col layout without materializing intermediate 4D arrays\n\nThe advanced direct tensor descriptor approach uses two MergeTransform operations: 1. Merge spatial dimensions: [out_h, out_w] → num_windows 2. Merge kernel dimensions: [K, K] → patch_size\nThis transforms the 4D tensor [out_h, out_w, K, K] directly into a 2D matrix [num_windows, patch_size] without materializing the intermediate 4D array.\n\n\n\n\n# Compare NumPy approach with direct tensor descriptor approach\ndifference = np.linalg.norm(im2col_numpy - im2col_td_direct)\nprint(f\"L2 norm of difference (NumPy vs Tensor Descriptor): {difference}\")\n\nif difference &lt; 1e-10:\n    print(\"✅ SUCCESS: Tensor descriptor im2col identical to NumPy!\")\nelse:\n    print(\"❌ ERROR: Tensor descriptor im2col differs from NumPy\")\n    print(f\"Max difference: {np.max(np.abs(im2col_numpy - im2col_td_direct))}\")\n\n# Also verify that simple reshape gives same result\ndifference_simple = np.linalg.norm(im2col_numpy - im2col_td_matrix)\nprint(f\"\\nL2 norm of difference (NumPy vs Simple Reshape): {difference_simple}\")\nif difference_simple &lt; 1e-10:\n    print(\"✅ SUCCESS: Simple reshape approach also identical!\")\n\nL2 norm of difference (NumPy vs Tensor Descriptor): 0.0\n✅ SUCCESS: Tensor descriptor im2col identical to NumPy!\n\nL2 norm of difference (NumPy vs Simple Reshape): 0.0\n✅ SUCCESS: Simple reshape approach also identical!",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#convolution-via-matrix-multiplication",
    "href": "concepts/02_convolution_example.html#convolution-via-matrix-multiplication",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "With our im2col matrix ready, we can now perform convolution using simple matrix multiplication:\n\ndef convolution_with_im2col(im2col_matrix, kernel, out_shape):\n    \"\"\"Perform convolution using im2col matrix multiplication.\"\"\"\n    # Flatten kernel\n    kernel_flat = kernel.flatten()\n    \n    print(f\"Im2col matrix shape: {im2col_matrix.shape}\")\n    print(f\"Kernel flat shape: {kernel_flat.shape}\")\n    \n    # Matrix multiplication: each row of im2col with kernel\n    output_flat = im2col_matrix @ kernel_flat\n    \n    # Reshape to output dimensions\n    output = output_flat.reshape(out_shape)\n    \n    print(f\"Output flat shape: {output_flat.shape}\")\n    print(f\"Final output shape: {output.shape}\")\n    \n    return output\n\n# Perform convolution using im2col\nout_shape = reference_output.shape\nim2col_output = convolution_with_im2col(im2col_numpy, kernel, out_shape)\n\nprint_matrix(im2col_output, \"Convolution via Im2col\")\n\nIm2col matrix shape: (16, 9)\nKernel flat shape: (9,)\nOutput flat shape: (16,)\nFinal output shape: (4, 4)\n\nConvolution via Im2col:\n 26  32  38  44\n 62  68  74  80\n 98 104 110 116\n134 140 146 152\n\n\n\n\n\n# Verify that all methods produce the same result\ndifference = np.linalg.norm(reference_output - im2col_output)\nprint(f\"L2 norm difference (naive vs im2col): {difference}\")\n\nif difference &lt; 1e-10:\n    print(\"✅ SUCCESS: Im2col convolution matches naive reference!\")\nelse:\n    print(\"❌ ERROR: Im2col convolution differs from reference\")\n    print(f\"Max difference: {np.max(np.abs(reference_output - im2col_output))}\")\n\nL2 norm difference (naive vs im2col): 0.0\n✅ SUCCESS: Im2col convolution matches naive reference!",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#multi-channel-convolution",
    "href": "concepts/02_convolution_example.html#multi-channel-convolution",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "Real-world deep learning scenarios involve multiple input and output channels. Let’s extend our approach:\n\ndef multi_channel_convolution():\n    \"\"\"Demonstrate multi-channel convolution.\"\"\"\n    # Create multi-channel input: 6x6x2 (2 input channels)\n    np.random.seed(123)\n    input_tensor = np.random.randint(0, 5, (6, 6, 2))\n    \n    # Create multi-channel filters: 3x3x2x3 (2 input, 3 output channels)\n    filters = np.random.randint(-1, 2, (3, 3, 2, 3))\n    \n    H, W, C_in = input_tensor.shape\n    K, K, C_in_filter, C_out = filters.shape\n    out_h, out_w = H - K + 1, W - K + 1\n    \n    print(f\"Input shape: {input_tensor.shape}\")\n    print(f\"Filters shape: {filters.shape}\")\n    print(f\"Output shape: ({out_h}, {out_w}, {C_out})\")\n    \n    # Reference convolution with nested loops\n    reference_output = np.zeros((out_h, out_w, C_out))\n    for i in range(out_h):\n        for j in range(out_w):\n            for c_out in range(C_out):\n                window = input_tensor[i:i+K, j:j+K, :]  # [K, K, C_in]\n                reference_output[i, j, c_out] = np.sum(window * filters[:, :, :, c_out])\n    \n    # Im2col approach using direct as_strided (like the figure shows)\n    # Extract all channels at once using as_strided\n    from numpy.lib.stride_tricks import as_strided\n    \n    # Create 5D windows [out_h, out_w, K, K, C_in] directly\n    windows_5d = as_strided(\n        input_tensor,\n        shape=(out_h, out_w, K, K, C_in),\n        strides=(input_tensor.strides[0], input_tensor.strides[1], \n                input_tensor.strides[0], input_tensor.strides[1], input_tensor.strides[2])\n    )\n    \n    # Convert to im2col format: [num_windows, patch_size]\n    num_windows = out_h * out_w\n    patch_size = K * K * C_in\n    im2col_matrix = windows_5d.reshape(num_windows, patch_size)\n    \n    # Reshape filters and apply\n    filters_reshaped = filters.reshape(patch_size, C_out)\n    im2col_output_flat = im2col_matrix @ filters_reshaped\n    im2col_output = im2col_output_flat.reshape(out_h, out_w, C_out)\n    \n    print(f\"\\nIm2col matrix shape: {im2col_matrix.shape}\")\n    print(f\"Reshaped filters shape: {filters_reshaped.shape}\")\n    \n    # Compare results\n    difference = np.linalg.norm(reference_output - im2col_output)\n    print(f\"\\nL2 norm difference (reference vs im2col): {difference}\")\n    \n    if difference &lt; 1e-10:\n        print(\"✅ SUCCESS: Multi-channel im2col matches reference!\")\n    else:\n        print(\"❌ ERROR: Multi-channel results differ\")\n    \n    return reference_output, im2col_output\n\n# Run multi-channel demonstration\nmulti_channel_convolution()\n\nInput shape: (6, 6, 2)\nFilters shape: (3, 3, 2, 3)\nOutput shape: (4, 4, 3)\n\nIm2col matrix shape: (16, 18)\nReshaped filters shape: (18, 3)\n\nL2 norm difference (reference vs im2col): 0.0\n✅ SUCCESS: Multi-channel im2col matches reference!\n\n\n(array([[[  8.,   8.,  -9.],\n         [  7.,  14., -20.],\n         [ -1.,   6., -13.],\n         [  0.,   5., -13.]],\n \n        [[  4.,  22., -11.],\n         [  8.,   4., -10.],\n         [ 11.,   2., -14.],\n         [ 21.,  12., -16.]],\n \n        [[  6.,   5., -12.],\n         [ 14.,  13., -11.],\n         [  4.,  19., -16.],\n         [ 10.,   9., -14.]],\n \n        [[ 21.,   5., -15.],\n         [  8.,  10., -14.],\n         [ 10.,   8., -11.],\n         [  6.,  12., -16.]]]),\n array([[[  8,   8,  -9],\n         [  7,  14, -20],\n         [ -1,   6, -13],\n         [  0,   5, -13]],\n \n        [[  4,  22, -11],\n         [  8,   4, -10],\n         [ 11,   2, -14],\n         [ 21,  12, -16]],\n \n        [[  6,   5, -12],\n         [ 14,  13, -11],\n         [  4,  19, -16],\n         [ 10,   9, -14]],\n \n        [[ 21,   5, -15],\n         [  8,  10, -14],\n         [ 10,   8, -11],\n         [  6,  12, -16]]]))\n\n\nFor multi-channel convolution:\n\nInput: [H, W, C_in]\nFilters: [K, K, C_in, C_out]\nIm2col matrix: [num_windows, K×K×C_in]\nReshaped filters: [K×K×C_in, C_out]\nOutput: [out_h, out_w, C_out]\n\nThe same im2col principle applies, but now each window includes all input channels, and we can compute all output channels simultaneously.",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/02_convolution_example.html#summary",
    "href": "concepts/02_convolution_example.html#summary",
    "title": "Convolution Implementation with Tensor Descriptors",
    "section": "",
    "text": "We’ve demonstrated the complete evolution from naive convolution to optimized tensor descriptor-based implementation:\n\nNaive approach: Direct mathematical implementation with nested loops\nWindow extraction: Using as_strided to create efficient memory views\nTensor descriptors: Achieving the same with structured transformations\nIm2col transformation: Converting convolution to matrix multiplication\nMulti-channel extension: Scaling to realistic deep learning scenarios\n\n\n\n\nMemory efficiency: Tensor descriptors avoid data duplication by creating views\nParallelization: Im2col enables massive parallelization through matrix multiplication\nGeneralization: The tensor descriptor approach extends naturally to complex memory patterns\nGPU acceleration: These transformations form the foundation for efficient GPU kernels\n\nThe tensor descriptor system provides a unified framework for describing these transformations, making it possible to generate efficient code for various hardware architectures automatically. It is also important to note that the tensor descriptor machinary is implmented in compile time C++ code, therefore very efficient. This python implementation is just a simulator to demonstrate the concept.\n\n\n\n\n\n\nMethod\nMemory Usage\nParallelization\nGPU Suitability\n\n\n\n\nNaive loops\nLow\nPoor\nPoor\n\n\nAs_strided\nMedium\nGood\nLimited\n\n\nTensor descriptors\nMedium\nExcellent\nExcellent\n\n\nIm2col\nHigh\nExcellent\nExcellent\n\n\n\nTensor descriptors strike the optimal balance: they provide the parallelization benefits of im2col while maintaining the memory efficiency of strided operations, making them ideal for high-performance GPU implementations.",
    "crumbs": [
      "Transformation Engine",
      "Convolution Implementation with Tensor Descriptors"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html",
    "href": "concepts/06_thread_mapping.html",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "",
    "text": "The final piece of the puzzle: how threads get their unique IDs and how that maps to specific data, connecting our mathematical abstractions to physical hardware.\nUp to this point, we’ve learned about encodings, transformations, and distributed tensors. But there’s one crucial question remaining: How do actual GPU threads know which data to process?\nThis is where thread mapping comes in - the bridge between our mathematical abstractions and the physical hardware that executes our code.",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#interactive-exploration",
    "href": "concepts/06_thread_mapping.html#interactive-exploration",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "🎮 Interactive Exploration",
    "text": "🎮 Interactive Exploration\nExplore thread mapping concepts interactively:\n🧵 Thread Visualization App - Visualize GPU thread coordinate mapping and access patterns. Understand how individual threads access distributed tensor data.",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#thread-identification-and-partition-indices",
    "href": "concepts/06_thread_mapping.html#thread-identification-and-partition-indices",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Thread Identification and Partition Indices",
    "text": "Thread Identification and Partition Indices\nBefore threads can process data, they need to know who they are and what work they’re responsible for.\n\nHardware Thread Identification\nIn GPU hardware, threads are organized hierarchically:\n\n\n\n\n\n\n\n\nThread Hierarchy Structure\nThe hardware organizes threads in a specific hierarchy:\n🔹 Block Level: Groups of warps working together - {warp_per_block_m}×{warp_per_block_n} warps per block - Shared memory and synchronization scope - Block-level coordination possible\n🔹 Warp Level: Groups of threads executing in lockstep - {thread_per_warp_m}×{thread_per_warp_n} threads per warp - SIMD execution (all threads execute same instruction) - Warp-level primitives (shuffle, vote, etc.)\n🔹 Thread Level: Individual execution units - {vector_m}×{vector_n} elements per thread - Independent register space - Vector operations on multiple elements\n\n\nThread ID Mapping\nEach thread gets a unique ID that maps to its position in the hierarchy:",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#thread-to-data-mapping",
    "href": "concepts/06_thread_mapping.html#thread-to-data-mapping",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Thread-to-Data Mapping",
    "text": "Thread-to-Data Mapping\nOnce threads know their IDs, they need to map those IDs to specific data elements.\n\nData Distribution Pattern\nThe RMSNorm operation distributes tensor data across threads in a structured pattern:\n\n\n\n\n\n\n\n\nThread Work Assignment\nEach thread is assigned a specific rectangular region of the tensor:",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#thread-cooperation-patterns",
    "href": "concepts/06_thread_mapping.html#thread-cooperation-patterns",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Thread Cooperation Patterns",
    "text": "Thread Cooperation Patterns\nThreads don’t work in isolation - they cooperate at different levels to achieve optimal performance.\n\nWarp-Level Cooperation\nThreads within a warp execute in lockstep (SIMD):\n🤝 Warp-Level Cooperation - Warps per block: {warp_per_block_m}×{warp_per_block_n} - Threads per warp: {thread_per_warp_m}×{thread_per_warp_n} - Cooperation pattern: Threads within a warp process adjacent data - Synchronization: Warp-level SIMD execution\n\n\nBlock-Level Cooperation\nThreads within a block can share data and synchronize:\n🏗️ Block-Level Cooperation - Shared memory: All threads in block can access shared memory - Synchronization: __syncthreads() barriers available - Data sharing: Threads can exchange intermediate results - Collective operations: Reduction, broadcast across block\n\n\nVector-Level Processing\nEach thread processes multiple elements efficiently:\n⚡ Vector-Level Processing - Elements per thread: {vector_m}×{vector_n} elements - Memory coalescing: Adjacent threads access adjacent memory - Vectorization: Hardware can combine multiple operations - Register efficiency: Multiple elements in registers",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#memory-access-patterns",
    "href": "concepts/06_thread_mapping.html#memory-access-patterns",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Memory Access Patterns",
    "text": "Memory Access Patterns\nThe thread mapping directly affects memory access efficiency.\n\nCoalesced Memory Access\n\n\n\n\n\n\n\n\nMemory Efficiency Benefits\nThe structured thread mapping provides several memory efficiency benefits:\n🎯 Memory Coalescing Benefits: - Adjacent access: Threads in same warp access adjacent memory locations - Cache efficiency: Related data loaded together into cache lines - Bandwidth utilization: Maximum memory bandwidth achieved - Reduced latency: Fewer memory transactions needed\n⚡ Performance Characteristics: - Predictable patterns: Access patterns known at compile time - Vectorization: Hardware can optimize vector operations - Reduced overhead: No complex address calculations at runtime - Scalability: Pattern scales efficiently with thread count",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#practical-thread-mapping-example",
    "href": "concepts/06_thread_mapping.html#practical-thread-mapping-example",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Practical Thread Mapping Example",
    "text": "Practical Thread Mapping Example\nLet’s see how thread mapping works in practice with a complete example:",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#testing-your-understanding",
    "href": "concepts/06_thread_mapping.html#testing-your-understanding",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify your understanding of thread mapping concepts:",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/06_thread_mapping.html#key-takeaways",
    "href": "concepts/06_thread_mapping.html#key-takeaways",
    "title": "Thread Mapping - Connecting to Hardware",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nThread mapping is the crucial bridge between mathematical abstractions and physical hardware execution:\n🎯 Thread Identification:\n\nHierarchical Organization: Threads organized in blocks → warps → threads → vectors\n\n✅ Each level has specific cooperation capabilities\n✅ Hardware provides efficient primitives at each level\n✅ Thread IDs map directly to data regions\n✅ Predictable and efficient execution patterns\n\nData Assignment: Each thread gets a specific rectangular region\n\n✅ Work distributed evenly across threads\n✅ Memory access patterns optimized for coalescing\n✅ Vector operations maximize throughput\n✅ Scalable across different hardware configurations\n\nCooperation Patterns: Threads cooperate at multiple levels\n\n✅ Warp-level SIMD execution for efficiency\n✅ Block-level shared memory and synchronization\n✅ Vector-level processing for maximum throughput\n✅ Hierarchical coordination for complex operations\n\n\n🚀 Performance Benefits:\n\nMemory Coalescing: Adjacent threads access adjacent memory for optimal bandwidth\nCache Efficiency: Related data loaded together, reducing memory latency\nVectorization: Hardware can optimize multiple operations per thread\nPredictable Patterns: Compile-time optimization of access patterns\n\n💡 Why This Matters:\nThread mapping connects all the previous concepts (encodings, transformations, distributions) to actual hardware execution. It’s the final piece that makes tile distribution practical for real-world GPU programming.\nThe RMSNorm example shows how a real operation uses these concepts to achieve optimal performance on modern GPU hardware. Every thread knows exactly what data to process, how to access it efficiently, and how to cooperate with other threads - all determined by the mathematical encoding we started with!\nThis completes the journey from basic memory concepts to hardware-optimized execution. You now understand the complete tile distribution system from mathematical foundations to practical implementation.",
    "crumbs": [
      "Thread Mapping",
      "Thread Mapping - Connecting to Hardware"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html",
    "href": "concepts/03_sweep_tile.html",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "",
    "text": "Sweep operations are the elegant way to iterate over distributed data. They complete the tile distribution workflow by providing clean, efficient iteration patterns that automatically handle all the complex indexing details.",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#overview",
    "href": "concepts/03_sweep_tile.html#overview",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "",
    "text": "Sweep operations are the elegant way to iterate over distributed data. They complete the tile distribution workflow by providing clean, efficient iteration patterns that automatically handle all the complex indexing details.",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#what-are-sweep-operations",
    "href": "concepts/03_sweep_tile.html#what-are-sweep-operations",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "What are Sweep Operations?",
    "text": "What are Sweep Operations?\nSweep operations are the final piece of the distributed computing puzzle:\nThe Challenge: You have distributed data loaded via TileWindow. Now you need to process every element. How do you iterate elegantly?\nThe Solution: Sweep operations provide clean iteration patterns that handle all the complex indexing automatically.\n🔄 The Complete GPU Workflow:\n\nTileDistribution: ‘Here’s how to divide work’\nTileWindow: ‘Here’s your data, loaded efficiently’\nSweep Operations: ‘Here’s how to process every element’\nYour code: ‘Thanks! does computation’\n\n🎯 Without Sweep Operations:\n\nManual nested loops over Y dimensions\nComplex index calculations\nEasy to miss elements or double-process\nDifferent code for different access patterns\n\n🎯 With Sweep Operations:\n\nElegant lambda-based iteration\nAutomatic handling of all elements\nSame pattern for any distribution\nCompiler-optimizable\n\nKey Insight: Sweep operations are like forEach() for distributed tensors. Give them a function, and they’ll call it for every element in the optimal order.",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#basic-sweep-operations",
    "href": "concepts/03_sweep_tile.html#basic-sweep-operations",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Basic Sweep Operations",
    "text": "Basic Sweep Operations\nLet’s start with the simplest sweep pattern:\n\n\n\n\n\n\nWhat happened? sweep_tensor_direct automatically iterated over all Y indices in the distributed tensor and called our function for each element. No manual loops, no missed elements!",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#sweep-with-computation",
    "href": "concepts/03_sweep_tile.html#sweep-with-computation",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Sweep with Computation",
    "text": "Sweep with Computation\nLet’s use sweep operations for actual computation:\n\n\n\n\n\n\nComputation Pattern: This is the classic pattern: sweep over input tensor, compute something, store in result tensor. The sweep handles all the iteration complexity automatically!",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#advanced-sweep-patterns",
    "href": "concepts/03_sweep_tile.html#advanced-sweep-patterns",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Advanced Sweep Patterns",
    "text": "Advanced Sweep Patterns\nLet’s explore more sophisticated sweep patterns:",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#using-tilesweeper-for-advanced-control",
    "href": "concepts/03_sweep_tile.html#using-tilesweeper-for-advanced-control",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Using TileSweeper for Advanced Control",
    "text": "Using TileSweeper for Advanced Control\nFor more control over the sweep process, we can use TileSweeper:",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#complete-tile-processing-workflow",
    "href": "concepts/03_sweep_tile.html#complete-tile-processing-workflow",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Complete Tile Processing Workflow",
    "text": "Complete Tile Processing Workflow\nLet’s demonstrate the complete workflow: load → sweep → compute → store:",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#sweep-pattern-comparison",
    "href": "concepts/03_sweep_tile.html#sweep-pattern-comparison",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Sweep Pattern Comparison",
    "text": "Sweep Pattern Comparison\nLet’s compare different ways to iterate over distributed data:",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#testing-your-understanding",
    "href": "concepts/03_sweep_tile.html#testing-your-understanding",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that sweep operations work correctly:",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/03_sweep_tile.html#key-takeaways",
    "href": "concepts/03_sweep_tile.html#key-takeaways",
    "title": "Sweep Tile - Elegant Iteration",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nSweep operations complete the tile distribution story with elegant iteration patterns:\n1. Elegant Iteration\n\n✅ Lambda-based processing functions\n✅ Automatic handling of all Y indices\n✅ No manual loops or complex indexing\n\n2. Error-Free Processing\n\n✅ Impossible to miss elements\n✅ No index calculation errors\n✅ Consistent iteration patterns\n\n3. Flexible Patterns\n\n✅ Simple element processing\n✅ Conditional operations\n✅ Accumulation and reduction\n✅ Complex computation workflows\n\n4. Performance Optimization\n\n✅ Compiler-friendly iteration patterns\n✅ Optimal memory access sequences\n✅ Hardware-aware processing\n\n5. Complete Workflow Integration\n\n✅ Seamless integration with TileDistribution\n✅ Perfect pairing with TileWindow\n✅ Enables complete load → sweep → compute → store patterns\n\nSweep operations are the final piece that makes distributed tensor processing both elegant and efficient. With TileDistribution, TileWindow, and Sweep operations, you have the complete toolkit for high-performance GPU computing!",
    "crumbs": [
      "Distribution API",
      "Sweep Tile - Elegant Iteration"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#overview",
    "href": "concepts/05_static_distributed_tensor.html#overview",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Overview",
    "text": "Overview\nNow that you understand how encodings create the transformation machinery, let’s examine the data structures that hold the actual computation data: Static Distributed Tensors.\nThese are the thread-local containers that hold each thread’s portion of the distributed computation. They’re “static” because their layout is determined at compile time for maximum performance.",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#what-is-a-static-distributed-tensor",
    "href": "concepts/05_static_distributed_tensor.html#what-is-a-static-distributed-tensor",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "What is a Static Distributed Tensor?",
    "text": "What is a Static Distributed Tensor?\nBefore diving into the implementation, let’s understand what problem these tensors solve:\nThe Challenge: Each thread needs to store and access its portion of the distributed data efficiently. The access patterns are known at compile time, so we can optimize the layout.\nThe Solution: Static Distributed Tensors are thread-local data containers with compile-time optimized layouts.\n🎯 Key Properties: - Each thread has its own StaticDistributedTensor - Contains only the data that thread needs - Layout optimized for the thread’s access patterns - Provides efficient element access via Y coordinates - Memory is organized according to tile distribution\n🔍 Comparison with Traditional Tensors: - Traditional tensor: Contains all data, shared access - Distributed tensor: Data split across threads - Static distributed tensor: Thread-local portion with compile-time optimized layout",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#tensor-creation-process",
    "href": "concepts/05_static_distributed_tensor.html#tensor-creation-process",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Tensor Creation Process",
    "text": "Tensor Creation Process\nStatic distributed tensors are created from tile distributions and provide the storage for thread-local computations:",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#thread-buffer-organization",
    "href": "concepts/05_static_distributed_tensor.html#thread-buffer-organization",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Thread Buffer Organization",
    "text": "Thread Buffer Organization\nEach thread’s buffer is organized to efficiently store the elements in its tile.\n📊 Buffer Layout Principles: - Contiguous memory for cache efficiency - Y coordinates provide logical indexing - Buffer positions provide physical indexing - Layout optimized for thread’s access patterns\n📝 Example: [2, 2] Thread Tile\nY coordinate to buffer position mapping: - Y=[0,0] → Buffer position 0 - Y=[0,1] → Buffer position 1 - Y=[1,0] → Buffer position 2 - Y=[1,1] → Buffer position 3\n🔄 Visual Layout:\nLogical (Y coordinates)    Physical (Buffer)\nY[0,0] Y[0,1]              Buffer[0] Buffer[1]\nY[1,0] Y[1,1]           →  Buffer[2] Buffer[3]",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#element-access-patterns",
    "href": "concepts/05_static_distributed_tensor.html#element-access-patterns",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Element Access Patterns",
    "text": "Element Access Patterns\nStatic distributed tensors provide efficient element access using Y coordinates.\n🎯 Access Methods: - get_element(y_indices): Read value at Y coordinate - set_element(y_indices, value): Write value at Y coordinate - Y coordinates are logical (within thread’s tile) - Internally maps to efficient buffer access\n📝 Element Access Example ([2, 2] tile):\nSetting values: - tensor.set_element([0, 0], 11) - tensor.set_element([0, 1], 12) - tensor.set_element([1, 0], 21) - tensor.set_element([1, 1], 22)\nReading values: - tensor.get_element([0, 0]) → 11 - tensor.get_element([0, 1]) → 12 - tensor.get_element([1, 0]) → 21 - tensor.get_element([1, 1]) → 22\n🚀 Performance Benefits: - Y coordinate lookup is O(1) - Buffer access is cache-friendly - No bounds checking needed (static layout) - Compiler can optimize access patterns",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#memory-layout-details",
    "href": "concepts/05_static_distributed_tensor.html#memory-layout-details",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Memory Layout Details",
    "text": "Memory Layout Details\nLet’s examine the internal memory organization in detail.\n🗃️ Example: [3, 2] tile (6 elements)\nMemory organization (row-major within tile):\n📊 Physical Memory Layout: - Address 0: Y=[0,0] → Value at position 0 - Address 1: Y=[0,1] → Value at position 1 - Address 2: Y=[1,0] → Value at position 2 - Address 3: Y=[1,1] → Value at position 3 - Address 4: Y=[2,0] → Value at position 4 - Address 5: Y=[2,1] → Value at position 5\n🔄 Address Calculation: For Y[y0, y1] in row-major layout:\naddress = y0 * width + y1\nwhere width = tile_size[1]\n📝 Example Calculations: - Y[0,0] → address 0 - Y[0,1] → address 1 - Y[1,0] → address 2 - Y[1,1] → address 3 - Y[2,0] → address 4 - Y[2,1] → address 5\n💡 Layout Benefits: - Sequential access patterns are cache-friendly - Address calculation is simple and fast - Memory utilization is optimal - Vectorization opportunities are maximized",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#thread-coordination",
    "href": "concepts/05_static_distributed_tensor.html#thread-coordination",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Thread Coordination",
    "text": "Thread Coordination\nStatic distributed tensors enable efficient thread coordination.\n🤝 Coordination Mechanisms: - Each thread has its own tensor instance - Threads coordinate through shared memory - Synchronization points ensure data consistency - Load balancing through work distribution\n📝 Example: [2, 2] threads, [2, 2] tiles\nThread coordination pattern: - Thread 0 (P=[0,0]): Has 4 elements, tensor size [2, 2], coordinates Y[0,0] to Y[1,1] - Thread 1 (P=[0,1]): Has 4 elements, tensor size [2, 2], coordinates Y[0,0] to Y[1,1] - Thread 2 (P=[1,0]): Has 4 elements, tensor size [2, 2], coordinates Y[0,0] to Y[1,1] - Thread 3 (P=[1,1]): Has 4 elements, tensor size [2, 2], coordinates Y[0,0] to Y[1,1]\n🔄 Coordination Benefits: - Each thread works independently on its tensor - No contention for shared data structures - Synchronization only at coordination points - Scales efficiently with thread count",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#practical-usage-patterns",
    "href": "concepts/05_static_distributed_tensor.html#practical-usage-patterns",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Practical Usage Patterns",
    "text": "Practical Usage Patterns\nStatic distributed tensors follow a common usage pattern in practice.\n🎯 Common Usage Pattern: 1. Create tensor from tile distribution 2. Load data into tensor (from global memory) 3. Perform computations on tensor elements 4. Store results back to global memory\n📝 Conceptual Example:\n# Step 1: Create tensor\ntensor = make_static_distributed_tensor(distribution, dtype)\n\n# Step 2: Load data\nfor y in all_y_coordinates:\n    value = load_from_global_memory(p_coord, y_coord)\n    tensor.set_element(y, value)\n\n# Step 3: Compute\nfor y in all_y_coordinates:\n    value = tensor.get_element(y)\n    result = compute_function(value)\n    tensor.set_element(y, result)\n\n# Step 4: Store\nfor y in all_y_coordinates:\n    value = tensor.get_element(y)\n    store_to_global_memory(p_coord, y_coord, value)\n💡 Pattern Benefits: - Clear separation of load/compute/store phases - Optimal memory access patterns - Easy to reason about and debug - Compiler can optimize each phase",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#testing-your-understanding",
    "href": "concepts/05_static_distributed_tensor.html#testing-your-understanding",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify your understanding of static distributed tensors:",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/05_static_distributed_tensor.html#key-takeaways",
    "href": "concepts/05_static_distributed_tensor.html#key-takeaways",
    "title": "Static Distributed Tensor - Thread-Local Data Containers",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nStatic distributed tensors are the efficient data containers that make tile distribution practical:\n🎯 Core Concepts:\n\nThread-Local Storage: Each thread has its own tensor\n\n✅ No contention between threads\n✅ Optimal memory access patterns\n✅ Independent computation capability\n✅ Efficient coordination mechanisms\n\nCompile-Time Optimization: Layout determined at compile time\n\n✅ No runtime overhead for layout decisions\n✅ Optimal memory organization\n✅ Maximum compiler optimization opportunities\n✅ Predictable performance characteristics\n\nEfficient Element Access: Y coordinates provide logical indexing\n\n✅ O(1) element access time\n✅ Cache-friendly memory patterns\n✅ No bounds checking overhead\n✅ Vectorization opportunities\n\n\n🔧 Implementation Benefits:\n\nMemory Efficiency: Only stores data the thread needs\nCache Performance: Contiguous memory layout optimized for access patterns\nScalability: Performance scales with thread count\nSimplicity: Clean programming model with logical coordinates\n\n💡 Why This Matters:\n\nPerformance: Optimal memory access patterns for GPU hardware\nProductivity: Easy to reason about and debug\nMaintainability: Clear separation between logical and physical layout\nExtensibility: Same pattern works for any tile distribution strategy\n\nStatic distributed tensors show how CK achieves both programming simplicity and maximum performance. The logical Y coordinate interface hides the complexity of optimal memory layout, giving you the best of both worlds!",
    "crumbs": [
      "Implementation Deep Dive",
      "Static Distributed Tensor - Thread-Local Data Containers"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html",
    "href": "concepts/02_transforms.html",
    "title": "Individual Transforms",
    "section": "",
    "text": "The transformation engine is built from individual transform types that each handle specific coordinate conversions. Understanding these building blocks is essential for mastering the tile distribution system.",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#interactive-exploration",
    "href": "concepts/02_transforms.html#interactive-exploration",
    "title": "Individual Transforms",
    "section": "🎮 Interactive Exploration",
    "text": "🎮 Interactive Exploration\nExplore transformation concepts interactively:\n🔄 Tensor Transform Visualizer - Explore tensor descriptor transformations with visual graphs and mathematical formulas. See how data layouts change through various transformations.",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#what-are-transforms",
    "href": "concepts/02_transforms.html#what-are-transforms",
    "title": "Individual Transforms",
    "section": "What Are Transforms?",
    "text": "What Are Transforms?\nEach transform type converts coordinates between different spaces:\n\nForward: Upper coordinates → Lower coordinates\n\nBackward: Lower coordinates → Upper coordinates\n\n🔄 The One-Way Street: Upper → Lower\nTransforms are your coordinate conversion tools! They bridge the gap between:\n\nUpper space: Logical coordinates (how you think about data)\n\nLower space: Physical coordinates (how data is actually stored)\n\n\n🧭 The Real Story: C++ vs Python\nIn C++ (the actual implementation):\n\nCalculateLowerIndex(upper): Upper → Lower (the core method)\nUpdateLowerIndex(...): Super-fast incremental updates (performance magic ⚡)\nCalculateUpperIndex(lower): ❌ NOT IMPLEMENTED!\n\nIn Python (convenience wrapper):\n\ncalculate_lower_index(upper): Upper → Lower (maps to C++)\ncalculate_upper_index(lower): Lower → Upper (Python adds this for educational and visualization purposes!)\nupdate_lower_index(...): Efficient incremental updates, only applyes transforms if the relevant dimension of the lower index has changed (maps to C++)\n\n\n\n🏷️ What’s in a Name?\nTransform names describe what they do, when we go from lower dimension to upper dimension. For example:\n\nEmbedTransform: Embeds converts a linear offset into multi-dimensional coords while considering strides\nUnmergeTransform: Unmerges linear offsets into multi-dimensional coords, strides in this transformation are calculated automatically based on lengths\nMergeTransform: Merges multiple dimensions into fewer dimensions\n\nReality check: C++ transforms are unidirectional - only upper → lower. Python makes them feel bidirectional, for educational and visualization purposes.",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#embedtransform-linear-memory-multi-dimensional",
    "href": "concepts/02_transforms.html#embedtransform-linear-memory-multi-dimensional",
    "title": "Individual Transforms",
    "section": "1. EmbedTransform: Linear Memory → Multi-dimensional",
    "text": "1. EmbedTransform: Linear Memory → Multi-dimensional\nEmbedTransform maps linear memory addresses to multi-dimensional coordinates using strides. Again the calculate_lower_index method is the reverse of the semantics meaning it returns a one dimensional index.\n\n\n\n\n\n\nKey Points: - Uses shape [2, 3] and strides [6, 1] for row-major layout - Each row advances by 6 elements, each column by 1 element - Essential for GPU memory coalescing",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#unmergetransform-linear-multi-dimensional",
    "href": "concepts/02_transforms.html#unmergetransform-linear-multi-dimensional",
    "title": "Individual Transforms",
    "section": "2. UnmergeTransform: Linear → Multi-dimensional",
    "text": "2. UnmergeTransform: Linear → Multi-dimensional\nUnmergeTransform unpacks linear indices to multi-dimensional coordinates. However, calculate_lower_index is the reverse of the semantics meaning it returns a one dimensional index.\n\n\n\n\n\n\nThe difference between UnmergeTransoform and EmbedTransform is that in UnmergeTransform strides are calculated from the lengths of the dimensions whereas in EmbedTransform strides are provided as an argument.\nKey Points: - Converts packed linear indices to structured coordinates - Uses row-major ordering: index = row * width + col - Critical for tensor reshaping operations",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#mergetransform-multi-dimensional-single-dimension",
    "href": "concepts/02_transforms.html#mergetransform-multi-dimensional-single-dimension",
    "title": "Individual Transforms",
    "section": "3. MergeTransform: Multi-dimensional → Single Dimension",
    "text": "3. MergeTransform: Multi-dimensional → Single Dimension\nMergeTransform collapses multiple dimensions into a single dimension. Like other transforms, the name describes how it convers lower dimensions to the upper dimension. The name’s semantic always come from when we go from physical to logical coordinates. In that sense, it merges the lower dimensions into the one upper dimension. However, calculate_lower_index is the reverse of the semantics meaning it returns a multi-dimensional index.\n\n\n\n\n\n\nKey Points: - Opposite of UnmergeTransform - Useful for flattening multi-dimensional arrays - Maintains element ordering",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#replicatetransform-data-replication",
    "href": "concepts/02_transforms.html#replicatetransform-data-replication",
    "title": "Individual Transforms",
    "section": "4. ReplicateTransform: Data Replication",
    "text": "4. ReplicateTransform: Data Replication\nReplicateTransform handles data replication across multiple processing elements. Basically, in C++ it is a no-op, meaning that it maps multiple upper coordinates to the same empty lower coordinate.\n\n\n\n\n\n\nKey Points: - Maps replica indices to empty coordinates - Used for broadcast operations - Essential for thread cooperation patterns",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#offsettransform-coordinate-offsetting",
    "href": "concepts/02_transforms.html#offsettransform-coordinate-offsetting",
    "title": "Individual Transforms",
    "section": "5. OffsetTransform: Coordinate Offsetting",
    "text": "5. OffsetTransform: Coordinate Offsetting\nOffsetTransform adds a constant offset to coordinates.\n\n\n\n\n\n\nKey Points: - Simple coordinate translation - Used for memory alignment and padding - Bidirectional operation (add/subtract)",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#passthroughtransform-identity-transformation",
    "href": "concepts/02_transforms.html#passthroughtransform-identity-transformation",
    "title": "Individual Transforms",
    "section": "6. PassThroughTransform: Identity Transformation",
    "text": "6. PassThroughTransform: Identity Transformation\nPassThroughTransform performs no transformation (identity function).\n\n\n\n\n\n\nKey Points: - Identity transformation (no coordinate change) - Used as placeholder in transformation chains - Maintains dimension structure",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#padtransform-tensor-padding",
    "href": "concepts/02_transforms.html#padtransform-tensor-padding",
    "title": "Individual Transforms",
    "section": "7. PadTransform: Tensor Padding",
    "text": "7. PadTransform: Tensor Padding\nPadTransform adds padding to tensor dimensions.\n\n\n\n\n\n\nKey Points: - Handles tensor padding for convolution operations - Manages boundary conditions - Critical for maintaining tensor shapes",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#testing-transform-operations",
    "href": "concepts/02_transforms.html#testing-transform-operations",
    "title": "Individual Transforms",
    "section": "Testing Transform Operations",
    "text": "Testing Transform Operations",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "concepts/02_transforms.html#key-takeaways",
    "href": "concepts/02_transforms.html#key-takeaways",
    "title": "Individual Transforms",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nEmbedTransform: Multi-dimensional → Linear (with strides)\nUnmergeTransform: Linear → Multi-dimensional (packed)\nMergeTransform: Multi-dimensional → Single dimension\nReplicateTransform: Handles data replication\nOffsetTransform: Adds constant offsets\nPassThroughTransform: Identity transformation\nPadTransform: Tensor padding operations\n\nEach transform has forward and backward operations, making them composable building blocks for complex tensor operations.\nNext: Learn how to chain these transforms using adaptors!",
    "crumbs": [
      "Transformation Engine",
      "Individual Transforms"
    ]
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#code-validation-strategy",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#code-validation-strategy",
    "title": "",
    "section": "Code Validation Strategy",
    "text": "Code Validation Strategy\nPre-Documentation Creation: All code examples MUST be validated before inclusion in documentation - Step 1: Write standalone Python scripts for each concept/example - Step 2: Test scripts independently with python script_name.py - Step 3: Verify output, fix any errors, ensure clean execution - Step 4: Only after successful validation, extract code snippets for .qmd files - Step 5: Test .qmd code blocks work in isolation (copy-paste test)"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#current-directory-structure",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#current-directory-structure",
    "title": "",
    "section": "Current Directory Structure",
    "text": "Current Directory Structure\ntile_distribution_documentation/validation_scripts/\n├── README.md                    # Testing instructions and overview\n├── requirements.txt             # Python dependencies for all scripts\n├── IMPLEMENTATION_GUIDE.md      # This file - detailed implementation guide\n├── common/                      # Shared utilities and helpers\n│   ├── __init__.py\n│   ├── test_utils.py           # Common testing functions\n│   └── visualization_helpers.py # Shared plotting/display code\n├── code_examples/               # Common utilities for scripts\n│   └── common_utils.py         # Shared helper functions\n├── part1_foundation/           # ✅ Memory → Tensors (Complete)\n│   ├── buffer_view_basics.py   # Raw memory buffer examples\n│   ├── tensor_view_basics.py   # Multi-dimensional tensor views\n│   └── validate_foundation.py  # Validation tests for part 1\n├── part2_transforms/           # ✅ Coordinate Transformation Engine (Complete)\n│   ├── coordinate_transforms.py     # Individual transforms (Merge, Unmerge, Replicate)\n│   ├── test_part2.py              # Validation tests for part 2\n│   └── validate_coordinate_transforms.py # Coordinate transform validation\n├── part3_distribution_api/     # ✅ High-Level Distribution APIs (Complete)\n│   ├── tile_distribution_basics.py # Basic distribution concepts\n│   ├── tile_window_basics.py       # make_tile_window examples\n│   ├── sweep_operations.py         # sweep_tile usage patterns\n│   └── validate_distribution_api.py # Validation tests for part 3\n├── part4_coordinate_systems/   # ✅ P, Y, X, R, D Spaces (Complete)\n│   └── coordinate_systems_basics.py # Complete coordinate system demonstration\n├── part5_internals/            # ✅ Distribution Encoding Internals (Complete)\n│   ├── encoding_internals.py       # TileDistributionEncoding deep dive\n│   └── static_distributed_tensor.py # StaticDistributedTensor implementation\n├── part6_thread_mapping/       # ✅ Hardware Thread Mapping (Complete)\n│   └── thread_mapping.py           # Thread cooperation and access patterns\n└── part7_advanced_topics/      # 🚧 Performance & Optimization (To be created)\n    ├── performance_optimization.py  # Memory coalescing, efficiency techniques\n    ├── debugging_techniques.py     # Access pattern visualization, profiling\n    └── custom_patterns.py          # Extension points, custom implementations"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#script-status-overview",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#script-status-overview",
    "title": "",
    "section": "Script Status Overview",
    "text": "Script Status Overview\n\n✅ Completed Parts\n\nPart 1: Foundation concepts (buffer views, tensor views)\nPart 2: Coordinate transformation engine (transforms, adaptors)\nPart 3: Distribution API (tile distribution, tile window, sweep operations)\nPart 4: Coordinate systems (P, Y, X, R, D spaces)\nPart 5: Internal implementation (encoding, static distributed tensor)\nPart 6: Thread mapping (hardware connection, cooperation patterns)\n\n\n\n🚧 Remaining Work\n\nPart 7: Advanced topics (performance optimization, debugging, custom patterns)"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#documentation-creation-strategy",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#documentation-creation-strategy",
    "title": "",
    "section": "Documentation Creation Strategy",
    "text": "Documentation Creation Strategy\n\nPhase 1: Complete Validation Scripts\n\nCreate Part 7 Scripts: Performance optimization, debugging techniques, custom patterns\nTest All Scripts: Ensure every script runs successfully\nUpdate Documentation: Fix any issues found during validation\n\n\n\nPhase 2: Create QMD Files\n\nExtract Working Code: Take validated examples from scripts\nCreate Concept Files: Build complete .qmd files with:\n\nConcept introduction\nWorking code examples (from validation scripts)\nInteractive elements\nPractical applications\n\n\n\n\nPhase 3: Integration and Testing\n\nTest QMD Files: Ensure all code blocks work in Quarto\nInteractive Integration: Link to Streamlit apps and visualizations\nFinal Validation: End-to-end testing of documentation"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#script-design-standards",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#script-design-standards",
    "title": "",
    "section": "Script Design Standards",
    "text": "Script Design Standards\n\nMinimalistic Script Design\n\nOne concept per script - No information overload\nClear progression: Headers → Brief intro → Code → Key insight → Summary\nCode-first approach: Show working example, then explain what it does\nEducational output: Print statements that teach, not just debug\nValidation focus - Scripts test what docs will show\n\n\n\nConversational Script Style\n\nDirect address: “You’ll see that…” “Let’s try this…” “Here’s what happens when you…”\nCollaborative tone: “We’re going to build…” “Now we can…” “This lets us…”\nPractical focus: “This is useful because…” “You’d use this when…” “In practice, you’ll find…”\nLearning journey: “First, let’s understand…” “Now that you know X, we can tackle Y…”\nEncouraging: “Don’t worry if this seems complex…” “You’re doing great!” “This will click soon…”\nReal-world context: “GPU programmers often need…” “In a real kernel, you’d…” “This pattern shows up in…”\n\n\n\nScript Structure Template\n#!/usr/bin/env python3\n\"\"\"\nScript Title - Brief Description\n\nShows how to [main concept]. This script demonstrates:\n1. Basic concept introduction\n2. Working examples\n3. Real-world applications\n4. Common pitfalls and solutions\n\"\"\"\n\nimport sys\nimport os\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'code_examples'))\n\nfrom common_utils import *\n# Import specific modules for this concept\n\ndef demonstrate_basic_concept():\n    \"\"\"Show the fundamental concept with simple examples.\"\"\"\n    print_step(1, \"Basic concept demonstration\")\n    # Implementation here\n    return result\n\ndef demonstrate_advanced_usage():\n    \"\"\"Show more complex usage patterns.\"\"\"\n    print_step(2, \"Advanced usage patterns\")\n    # Implementation here\n    return result\n\ndef test_concept_operations():\n    \"\"\"Test that the concept operations work correctly.\"\"\"\n    print_step(3, \"Testing operations\")\n    # Test implementations here\n    return all_tests_passed\n\ndef main():\n    \"\"\"Main function to run all demonstrations.\"\"\"\n    if not check_imports():\n        return False\n    \n    print_section(\"Script Title\")\n    \n    # Run demonstrations\n    result1 = demonstrate_basic_concept()\n    result2 = demonstrate_advanced_usage()\n    \n    # Run tests\n    all_tests_passed = test_concept_operations()\n    \n    print_section(\"Summary\")\n    print(f\"✅ Demonstrations completed\")\n    print(f\"✅ All tests passed: {all_tests_passed}\")\n    \n    return all_tests_passed\n\nif __name__ == \"__main__\":\n    success = run_script_safely(main, \"Script Title\")\n    sys.exit(0 if success else 1)"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#documentation-file-creation",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#documentation-file-creation",
    "title": "",
    "section": "Documentation File Creation",
    "text": "Documentation File Creation\n\nQMD File Structure Template\n---\ntitle: \"Part X: Concept Title\"\n---\n\n# Part X: Concept Title\n\n## Overview\n\nBrief introduction to the concept and its importance in the tile distribution system.\n\n**Learning Objectives:**\n- Understand [concept 1]\n- Master [concept 2]\n- See [concept 3] in practice\n\n## Key Concepts\n\n### Concept 1\nExplanation with working examples.\n\n```python\n# Working code example from validation scripts\n\n\nConcept 2\nExplanation with practical applications.\n# More working code examples"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#interactive-exploration",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#interactive-exploration",
    "title": "",
    "section": "Interactive Exploration",
    "text": "Interactive Exploration\n\nLink to relevant Streamlit app\nLink to specific visualization"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#practical-applications",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#practical-applications",
    "title": "",
    "section": "Practical Applications",
    "text": "Practical Applications\nReal-world usage patterns and performance considerations."
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#summary",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#summary",
    "title": "",
    "section": "Summary",
    "text": "Summary\nKey takeaways and connections to other concepts."
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#next-steps",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#next-steps",
    "title": "",
    "section": "Next Steps",
    "text": "Next Steps\nLink to the next part in the learning journey.\n\n## Validation Workflow\n\n```bash\n# Step 1: Test individual scripts\ncd tile_distribution_documentation/validation_scripts/part1_foundation/\npython buffer_view_basics.py\npython tensor_view_basics.py\n\n# Step 2: Run part-specific tests\npython validate_foundation.py\n\n# Step 3: Test all parts\ncd ../..\npython -m pytest validation_scripts/  # If we add pytest support\n\n# Step 4: Extract working code snippets for .qmd files\n# Only after all tests pass successfully"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#code-quality-standards",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#code-quality-standards",
    "title": "",
    "section": "Code Quality Standards",
    "text": "Code Quality Standards\n\nStandalone Execution: Each script runs without external dependencies\nClear Output: Print statements showing what each example demonstrates\nError Handling: Graceful failure with helpful error messages\nDocumentation: Inline comments explaining key concepts\nMinimal Dependencies: Only use libraries available in the main project"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#interactive-integration-strategy",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#interactive-integration-strategy",
    "title": "",
    "section": "Interactive Integration Strategy",
    "text": "Interactive Integration Strategy\n\nStreamlit Apps\n\napp.py: Tile Distribution Visualizer\n\nLink from Part 0 (motivation) and Part 3 (distribution API)\nPre-configured examples for each concept\n\ntensor_transform_app.py: Transformation Pipeline Explorer\n\nLink from Part 2 (transformation engine)\nVisual demonstration of transform chains\n\nthread_visualization_app.py: Thread Access Pattern Analyzer\n\nLink from Part 6 (thread mapping)\nThread-by-thread access pattern visualization\n\n\n\n\nManim Animations\n\nanimation/: Tile distribution encoding graph visualization\n\nEmbed in Part 5 (internals) for encoding explanation\nVisual representation of R, H, P, Y dimensions"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#success-criteria",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#success-criteria",
    "title": "",
    "section": "Success Criteria",
    "text": "Success Criteria\n\nScript Validation Success\n\nAll scripts run without errors\nClear educational output\nComprehensive concept coverage\nReal-world examples included\n\n\n\nDocumentation Creation Success\n\nComplete standalone documentation (no external dependencies)\nAll code examples work in QMD files\nInteractive elements properly integrated\nClear learning progression from Part 0 to Part 7\n\n\n\nQuality Assurance\n\nConcepts explained from first principles\nWorking examples for all APIs\nPerformance considerations included\nDebugging techniques demonstrated"
  },
  {
    "objectID": "validation_scripts/IMPLEMENTATION_GUIDE.html#current-priority",
    "href": "validation_scripts/IMPLEMENTATION_GUIDE.html#current-priority",
    "title": "",
    "section": "Current Priority",
    "text": "Current Priority\nImmediate: Create Part 7 advanced topics scripts Next: Begin QMD file creation using validated examples Future: Interactive integration and final testing\nThis guide ensures all documentation is built on a foundation of validated, working code examples."
  },
  {
    "objectID": "concepts/05_encoding_internals.html#overview",
    "href": "concepts/05_encoding_internals.html#overview",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "Overview",
    "text": "Overview\nNow that you understand the coordinate systems, it’s time to peek behind the curtain and see how the magic actually works. Encoding internals reveal how the mathematical specification creates the transformation components that implement the P+Y → X mappings.\nThis is where the abstract coordinate transformations become concrete, executable code.",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#what-is-tile-distribution-encoding",
    "href": "concepts/05_encoding_internals.html#what-is-tile-distribution-encoding",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "What is Tile Distribution Encoding?",
    "text": "What is Tile Distribution Encoding?\nBefore diving into the internals, let’s understand what we’re examining:\nThe Challenge: You have a mathematical specification (the encoding) that describes how threads should be organized and how work should be distributed. How does this specification become the actual transformation chains that map coordinates?\nThe Solution: The encoding contains all the mathematical relationships needed to automatically generate the transformation components:\n\n🎬 Visual Explanation\nThe following video visualizes how tile distribution encoding creates a graph structure, showing how nodes and edges are constructed from the encoding parameters:\n\n\nps_ys_to_xs_adaptor: Maps combined (P,Y) coordinates to X coordinates\nys_to_d_descriptor: Maps Y coordinates to linearized storage\nTransformation chains: Built automatically from encoding parameters",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#encoding-structure-deep-dive",
    "href": "concepts/05_encoding_internals.html#encoding-structure-deep-dive",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "Encoding Structure Deep Dive",
    "text": "Encoding Structure Deep Dive\nLet’s examine the structure of a tile distribution encoding:",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#parameter-breakdown",
    "href": "concepts/05_encoding_internals.html#parameter-breakdown",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "Parameter Breakdown",
    "text": "Parameter Breakdown\nEach parameter in the encoding controls a specific aspect of how threads and data are organized:\n\nrs_lengths (Replication Lengths)\n🔹 rs_lengths (Replication Lengths)\nControls data sharing across threads: - [] = no replication - [2] = each data element shared by 2 threads\n- [2,2] = 2x2 replication pattern\n📝 Examples: - [] → No replication - each thread has unique data - [2] → Linear replication - data shared by pairs - [2, 2] → 2D replication - data shared in 2x2 blocks\n\n\nhs_lengthss (Hierarchical Lengths)\n🔹 hs_lengthss (Hierarchical Lengths)\nDefines tile sizes per dimension: - [[2,2], [2,2]] = 2x2 tiles for both X dimensions - [[4,4], [4,4]] = 4x4 tiles for both X dimensions - Controls thread workload size\n📝 Tile Size Examples: - [[2, 2], [2, 2]] → 2x2 tiles (4 elements per thread) - [[4, 4], [4, 4]] → 4x4 tiles (16 elements per thread) - [[2, 4], [4, 2]] → 2x4 and 4x2 tiles (8 elements per thread)\n\n\nP→RH Mappings\n🔹 ps_to_rhss_major/minor (P→RH Mappings)\nMaps partition coordinates to RH space: - Controls which H dimensions each P dimension affects - major/minor specify different levels of the mapping\n📝 Conceptual Example: ps_to_rhss_major=[[1], [2]] means: - P dimension 0 maps to H dimension 1 - P dimension 1 maps to H dimension 2\nThis determines how thread coordinates affect tile placement.\n\n\nY→RH Mappings\n🔹 ys_to_rhs_major/minor (Y→RH Mappings)\nMaps Y coordinates to RH space: - Determines how logical Y coordinates map to hierarchical structure - Controls the internal organization of each thread’s tile\n📝 Example Mapping: ys_to_rhs_major=[1, 1, 2, 2] means: - Y[0] maps to H1 - Y[1] maps to H1\n- Y[2] maps to H2 - Y[3] maps to H2\nThis creates the internal structure of thread tiles.",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#from-encoding-to-tile-distribution",
    "href": "concepts/05_encoding_internals.html#from-encoding-to-tile-distribution",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "From Encoding to Tile Distribution",
    "text": "From Encoding to Tile Distribution\nThe magic happens when make_static_tile_distribution() transforms the mathematical encoding into runtime components:",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#the-py-x-transformation-chain",
    "href": "concepts/05_encoding_internals.html#the-py-x-transformation-chain",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "The P+Y → X Transformation Chain",
    "text": "The P+Y → X Transformation Chain\nThe heart of the system is the adaptor that implements the P+Y → X transformation.\n🔗 The P+Y → X Transformation Chain\nThe ps_ys_to_xs_adaptor implements a chain of transformations: 1. Start with P coordinates (which thread) 2. Add Y coordinates (which element in thread’s tile) 3. Apply replication transforms (R-space) 4. Apply hierarchical transforms (H-space) 5. Merge into final X coordinates\n💡 Why This Chain Works: - Each transform handles one aspect of the mapping - Transforms are composable and efficient - The chain is built automatically from encoding - Same pattern works for any distribution strategy\n📝 Conceptual Example: - Input: P=[1,0] + Y=[0,1] → Combined=[1,0,0,1] - Transform 1: Handle replication (none in this case) - Transform 2: Handle hierarchical structure - Transform 3: Merge to final coordinates - Output: X=[0,3] (final tensor position)",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#the-y-d-linearization",
    "href": "concepts/05_encoding_internals.html#the-y-d-linearization",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "The Y → D Linearization",
    "text": "The Y → D Linearization\nThe descriptor handles the linearization of Y coordinates to memory addresses.\n🗃️ The Y → D Linearization\nThe ys_to_d_descriptor handles memory layout within each thread: 1. Start with Y coordinates [y0, y1, y2, y3] 2. Apply thread’s local layout (usually row-major) 3. Compute linear offset within thread’s buffer 4. Result: D coordinate (memory address)\n📝 Example with [2, 2] tile: - Y=[0,0] → D=0 - Y=[0,1] → D=1 - Y=[1,0] → D=2 - Y=[1,1] → D=3\n💡 Why Separate from Adaptor: - Adaptor handles inter-thread coordination (P+Y → X) - Descriptor handles intra-thread layout (Y → D) - This separation enables different memory layouts - Each thread can have its own descriptor",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#practical-examples",
    "href": "concepts/05_encoding_internals.html#practical-examples",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "Practical Examples",
    "text": "Practical Examples\nDifferent encodings create different behaviors:\n🎯 Example 1: Simple 2x2 Distribution\nsimple_encoding = TileDistributionEncoding(\n    rs_lengths=[],\n    hs_lengthss=[[2], [2]],\n    ps_to_rhss_major=[[], []],\n    ps_to_rhss_minor=[[], []],\n    ys_to_rhs_major=[1, 2],\n    ys_to_rhs_minor=[0, 0]\n)\n\nNo replication\nSimple hierarchical structure\nDirect P→H mapping\nGood for basic matrix operations\n\n🎯 Example 2: With Replication\nreplicated_encoding = TileDistributionEncoding(\n    rs_lengths=[2],  # 2-way replication\n    hs_lengthss=[[2], [2]],\n    ps_to_rhss_major=[[], []],\n    ps_to_rhss_minor=[[], []],\n    ys_to_rhs_major=[1, 2],\n    ys_to_rhs_minor=[0, 0]\n)\n\n2-way replication for data sharing\nSame hierarchical structure\nGood for broadcast operations\nEnables thread cooperation",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#testing-your-understanding",
    "href": "concepts/05_encoding_internals.html#testing-your-understanding",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify your understanding of encoding internals:",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/05_encoding_internals.html#key-takeaways",
    "href": "concepts/05_encoding_internals.html#key-takeaways",
    "title": "Encoding Internals - The Internal Machinery",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nUnderstanding encoding internals reveals the elegant architecture behind tile distribution:\n🎯 The Mathematical Foundation:\n\nEncoding Structure: Mathematical specification of thread organization\n\n✅ rs_lengths control data replication\n✅ hs_lengthss define tile sizes\n✅ ps_to_rhss mappings control P→RH relationships\n✅ ys_to_rhs mappings control Y→RH relationships\n\nAutomatic Generation: From math to code\n\n✅ Encoding parameters drive component creation\n✅ Transformation chains built automatically\n✅ Performance optimizations applied automatically\n✅ Same pattern works for any distribution strategy\n\nComponent Architecture: Clean separation of concerns\n\n✅ ps_ys_to_xs_adaptor handles P+Y → X mapping\n✅ ys_to_d_descriptor handles Y → D linearization\n✅ Each component has a specific, well-defined role\n✅ Components compose to create complete system\n\n\n🔧 The Implementation Magic:\n\nComposable Transforms: Each transformation handles one aspect\nAutomatic Optimization: Compiler can optimize the generated chains\nFlexible Architecture: Same framework supports any distribution pattern\nPerformance Focus: Every design decision optimized for GPU efficiency\n\n💡 Why This Matters:\n\nAbstraction Power: Mathematical specification becomes executable code\nMaintainability: Changes to encoding automatically propagate\nPerformance: Optimized transformation chains for each use case\nExtensibility: New distribution patterns just need new encodings\n\nThe encoding internals show how CK achieves both mathematical elegance and practical performance. The same mathematical framework that makes the system easy to reason about also generates highly optimized code!",
    "crumbs": [
      "Implementation Deep Dive",
      "Encoding Internals - The Internal Machinery"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html",
    "href": "concepts/01_tensor_view.html",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "",
    "text": "TensorView adds multi-dimensional structure to raw memory. While BufferView provides linear access, TensorView enables coordinate-based access to matrices, tensors, and higher-dimensional data structures.",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#overview",
    "href": "concepts/01_tensor_view.html#overview",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "",
    "text": "TensorView adds multi-dimensional structure to raw memory. While BufferView provides linear access, TensorView enables coordinate-based access to matrices, tensors, and higher-dimensional data structures.",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#tensorview-creation",
    "href": "concepts/01_tensor_view.html#tensorview-creation",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "TensorView Creation",
    "text": "TensorView Creation\nLet’s create our first TensorView and see how it structures raw memory:",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#tensorview-properties",
    "href": "concepts/01_tensor_view.html#tensorview-properties",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "TensorView Properties",
    "text": "TensorView Properties\nNow let’s explore the properties and methods available on TensorView objects:",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#coordinate-access",
    "href": "concepts/01_tensor_view.html#coordinate-access",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Coordinate Access",
    "text": "Coordinate Access\nTensorView provides structured access using multi-dimensional coordinates:",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#packed-tensor-views",
    "href": "concepts/01_tensor_view.html#packed-tensor-views",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Packed Tensor Views",
    "text": "Packed Tensor Views\nPacked tensor views provide convenient ways to create common layouts:",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#different-memory-layouts",
    "href": "concepts/01_tensor_view.html#different-memory-layouts",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Different Memory Layouts",
    "text": "Different Memory Layouts\nThe same raw data can be interpreted in different ways depending on the tensor shape:",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#multi-dimensional-tensors",
    "href": "concepts/01_tensor_view.html#multi-dimensional-tensors",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Multi-Dimensional Tensors",
    "text": "Multi-Dimensional Tensors",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#testing-your-understanding",
    "href": "concepts/01_tensor_view.html#testing-your-understanding",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that TensorView operations work correctly:",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#key-concepts-demonstrated",
    "href": "concepts/01_tensor_view.html#key-concepts-demonstrated",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Key Concepts Demonstrated",
    "text": "Key Concepts Demonstrated\nThrough these examples, you’ve learned:\n\nMulti-Dimensional Structure: How TensorView adds shape to raw memory\nCoordinate Systems: Using MultiIndex for structured element access\nMemory Layouts: Different ways to interpret the same raw data\nTransformations: How to reshape and manipulate tensor views\nHigher Dimensions: Working with 3D, 4D, and higher-dimensional tensors",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#common-use-cases",
    "href": "concepts/01_tensor_view.html#common-use-cases",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Common Use Cases",
    "text": "Common Use Cases\nTensorView is used throughout Composable Kernels for:\n\nMatrix Operations: 2D tensor views for linear algebra\nConvolution: 4D tensor views for feature maps [batch, channels, height, width]\nSequence Processing: 3D tensor views for [batch, sequence, features]\nData Reshaping: Transforming data layouts for different operations",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#key-takeaways",
    "href": "concepts/01_tensor_view.html#key-takeaways",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nStructured Memory Access: TensorView provides multi-dimensional indexing on raw memory\nZero-Copy Operations: TensorView wraps existing BufferView data without copying\nFlexible Layouts: Supports row-major, column-major, and custom memory arrangements\nCoordinate Mapping: Provides efficient mapping from logical coordinates to memory addresses\nGPU-Optimized: Designed for efficient GPU memory access patterns",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#whats-next",
    "href": "concepts/01_tensor_view.html#whats-next",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "What’s Next",
    "text": "What’s Next\nTensorView provides structured access to multi-dimensional data. Next, learn about Tensor Adaptors which enable powerful transformations and coordinate mappings on top of TensorView.",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#next-steps",
    "href": "concepts/01_tensor_view.html#next-steps",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Next Steps",
    "text": "Next Steps\nContinue to Transforms to learn how to manipulate and transform tensor layouts.",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html",
    "href": "concepts/02_adaptors.html",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "",
    "text": "While individual transforms are powerful, TensorAdaptors let us chain multiple transforms together to create complex coordinate transformations. Think of adaptors as transformation pipelines that can reshape, reorder, and restructure tensors in sophisticated ways.\nTensorAdaptors are the bridge between individual transforms and the high-level tensor operations you’ll use in real applications.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#overview",
    "href": "concepts/02_adaptors.html#overview",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "",
    "text": "While individual transforms are powerful, TensorAdaptors let us chain multiple transforms together to create complex coordinate transformations. Think of adaptors as transformation pipelines that can reshape, reorder, and restructure tensors in sophisticated ways.\nTensorAdaptors are the bridge between individual transforms and the high-level tensor operations you’ll use in real applications.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#tensoradaptor-basics",
    "href": "concepts/02_adaptors.html#tensoradaptor-basics",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "TensorAdaptor Basics",
    "text": "TensorAdaptor Basics\nLet’s start by understanding what a TensorAdaptor is and how it works:\n\n\n\n\n\n\nThe most important method of a TensorAdaptor is calculate_bottom_index, which calculates the lower index from the upper index. It achives this by applying the transforms in reverse order and calling calculate_lower_index on each transform.\nLet’s go over some of the utility functions for creating tensor adaptors and see how they work in real life. We start with one of the simplest one.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#identity-adaptor-the-starting-point",
    "href": "concepts/02_adaptors.html#identity-adaptor-the-starting-point",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Identity Adaptor: The Starting Point",
    "text": "Identity Adaptor: The Starting Point\nThe identity adaptor is the simplest case - it passes coordinates through unchanged. This is often used as a starting point for building more complex adaptors.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#transpose-adaptor-dimension-reordering",
    "href": "concepts/02_adaptors.html#transpose-adaptor-dimension-reordering",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Transpose Adaptor: Dimension Reordering",
    "text": "Transpose Adaptor: Dimension Reordering\nThe transpose adaptor reorders tensor dimensions according to a permutation pattern.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#single-stage-adaptors-custom-transform-chains",
    "href": "concepts/02_adaptors.html#single-stage-adaptors-custom-transform-chains",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Single-Stage Adaptors: Custom Transform Chains",
    "text": "Single-Stage Adaptors: Custom Transform Chains\nYou can create custom adaptors by specifying exactly which transforms to use and how they connect, the API for that is called make_single_stage_tensor_adaptor:\n\n\n\n\n\n\nNow that we saw how we can create an adaptor, let’s see how we can combine a few of them together.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#chaining-adaptors-building-complex-transformations",
    "href": "concepts/02_adaptors.html#chaining-adaptors-building-complex-transformations",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Chaining Adaptors: Building Complex Transformations",
    "text": "Chaining Adaptors: Building Complex Transformations\nThe real power comes from chaining multiple adaptors together to create sophisticated transformations. Below we try some trivial example of combining merge and unmerge just to show how these transformations combine.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#multi-stage-chaining-complex-pipelines",
    "href": "concepts/02_adaptors.html#multi-stage-chaining-complex-pipelines",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Multi-Stage Chaining: Complex Pipelines",
    "text": "Multi-Stage Chaining: Complex Pipelines\nFor more complex transformations, you can chain multiple adaptors in sequence:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#transform-addition-extending-existing-adaptors",
    "href": "concepts/02_adaptors.html#transform-addition-extending-existing-adaptors",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Transform Addition: Extending Existing Adaptors",
    "text": "Transform Addition: Extending Existing Adaptors\nYou can add new transforms to existing adaptors using transform_tensor_adaptor. Important: The new_upper_dimension_new_top_idss parameter controls the final output dimensions of the adaptor.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#practical-example-matrix-transpose-with-padding",
    "href": "concepts/02_adaptors.html#practical-example-matrix-transpose-with-padding",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Practical Example: Matrix Transpose with Padding",
    "text": "Practical Example: Matrix Transpose with Padding\nLet’s create a practical example that combines multiple transforms:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#testing-your-understanding",
    "href": "concepts/02_adaptors.html#testing-your-understanding",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that our adaptor operations work correctly:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#summary",
    "href": "concepts/02_adaptors.html#summary",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Summary",
    "text": "Summary\nTensorAdaptors are the coordination layer that makes complex tensor operations possible:\n\nIdentity Adaptor: Starting point for building transformations\nTranspose Adaptor: Dimension reordering with permutation patterns\nSingle-Stage Adaptors: Custom transform chains with precise control\nChained Adaptors: Complex multi-stage transformation pipelines\nTransform Addition: Extending existing adaptors with new transforms\nAdvanced Examples: Complex nested transforms with flattening behavior\nGPU Block Descriptors: Real-world GPU memory layout patterns\nC++ Equivalents: True working equivalent of complex nested C++ transforms\n\nKey concepts: - Bottom/Top Dimensions: Input and output coordinate spaces - Hidden Dimensions: Internal coordinate mappings between transforms - Transform Chains: Sequential application of multiple transforms - Coordinate Transformation: Bidirectional mapping between coordinate spaces - Nested Transforms: Complex multi-level transformation hierarchies\n\nBreakthrough Discovery\nWe successfully created the true C++ equivalent of complex nested transforms:\n# C++ nested transform equivalent\ncpp_equivalent = make_single_stage_tensor_adaptor(\n    transforms=[\n        UnmergeTransform([A, B, C]),  # Merges A,B,C dimensions  \n        PassThroughTransform(D)       # Passes through D dimension\n    ],\n    lower_dimension_old_top_idss=[[0], [1]],          # Transform inputs\n    upper_dimension_new_top_idss=[[0, 1, 2], [3]]     # Transform outputs\n)\nKey insights: - Transform direction: Names refer to lower→higher, but calculate_lower_index() goes higher→lower - UnmergeTransform: Performs merging when used with calculate_lower_index() - Parameter mapping: Controls the coordinate flow between dimensions - Mathematical equivalence: Exact same results as C++ nested structure\nTensorAdaptors bridge the gap between low-level transforms and high-level tensor operations, providing the flexibility to create sophisticated data layouts and access patterns that are essential for efficient GPU computing.\nNext, we’ll see how TensorAdaptors are combined with element space information to create complete TensorDescriptors.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html",
    "href": "concepts/02_descriptors.html",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "",
    "text": "TensorDescriptor is the complete specification for a tensor in memory. It combines TensorAdaptor (the transformation pipeline) with element space information (how much memory is needed). Think of it as the complete blueprint that tells you everything about how a tensor is laid out in memory.\nTensorDescriptor is what you’ll actually use in real applications - it provides the complete interface for creating, accessing, and manipulating tensors.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#overview",
    "href": "concepts/02_descriptors.html#overview",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Overview",
    "text": "Overview\nA TensorDescriptor is the complete blueprint for a tensor. It combines a shape, stride information, and a series of transformations into a single object that defines exactly how a tensor’s data is laid out in memory. This guide will walk you through creating tensors, from basic layouts to complex, transformed views.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#tensordescriptor-vs-tensoradaptor",
    "href": "concepts/02_descriptors.html#tensordescriptor-vs-tensoradaptor",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "TensorDescriptor vs TensorAdaptor",
    "text": "TensorDescriptor vs TensorAdaptor\nLet’s start by understanding how TensorDescriptor extends TensorAdaptor:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#naive-tensor-descriptor-custom-strides",
    "href": "concepts/02_descriptors.html#naive-tensor-descriptor-custom-strides",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Naive Tensor Descriptor: Custom Strides",
    "text": "Naive Tensor Descriptor: Custom Strides\nThe most flexible way to create tensors is with custom strides, allowing you to control exactly how data is laid out in memory:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#packed-tensor-descriptor-row-major-layout",
    "href": "concepts/02_descriptors.html#packed-tensor-descriptor-row-major-layout",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Packed Tensor Descriptor: Row-Major Layout",
    "text": "Packed Tensor Descriptor: Row-Major Layout\nFor most applications, packed (row-major) layout is what you want - it’s memory efficient with no padding:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#multi-dimensional-descriptors",
    "href": "concepts/02_descriptors.html#multi-dimensional-descriptors",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Multi-Dimensional Descriptors",
    "text": "Multi-Dimensional Descriptors\nTensorDescriptor works with any number of dimensions:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#aligned-tensor-descriptor-memory-alignment",
    "href": "concepts/02_descriptors.html#aligned-tensor-descriptor-memory-alignment",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Aligned Tensor Descriptor: Memory Alignment",
    "text": "Aligned Tensor Descriptor: Memory Alignment\nFor GPU performance, you often need memory-aligned layouts:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#transform-tensor-descriptor-adding-transformations",
    "href": "concepts/02_descriptors.html#transform-tensor-descriptor-adding-transformations",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Transform Tensor Descriptor: Adding Transformations",
    "text": "Transform Tensor Descriptor: Adding Transformations\nYou can add transformations to existing descriptors to create more complex layouts:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#descriptor-properties-and-methods",
    "href": "concepts/02_descriptors.html#descriptor-properties-and-methods",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Descriptor Properties and Methods",
    "text": "Descriptor Properties and Methods\nLet’s explore the key properties and methods available on TensorDescriptor:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#performance-considerations",
    "href": "concepts/02_descriptors.html#performance-considerations",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Performance Considerations",
    "text": "Performance Considerations\nDifferent descriptor types have different performance characteristics:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#testing-your-understanding",
    "href": "concepts/02_descriptors.html#testing-your-understanding",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that tensor descriptors work correctly:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#summary",
    "href": "concepts/02_descriptors.html#summary",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Summary",
    "text": "Summary\n\nTensorDescriptor is a Pipeline: It describes transformations from a 1D buffer to a logical tensor view.\nmake_naive... Creates the First Stage: It sets up the initial transform from a buffer to a simple packed layout.\ntransform_tensor_descriptor Adds New Stages: It allows you to build complex views by adding transforms to the pipeline.\nHandle All Input Dimensions: When transforming, you must provide a new transform for each logical dimension of the input descriptor to avoid losing data.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html",
    "href": "concepts/03_tile_window.html",
    "title": "Tile Window - Data Access Gateway",
    "section": "",
    "text": "TileWindow is the bridge between TileDistribution (work assignment) and actual data access. It provides a windowed view into tensors with distribution-aware access patterns, handling all the complex memory access details automatically.",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#overview",
    "href": "concepts/03_tile_window.html#overview",
    "title": "Tile Window - Data Access Gateway",
    "section": "",
    "text": "TileWindow is the bridge between TileDistribution (work assignment) and actual data access. It provides a windowed view into tensors with distribution-aware access patterns, handling all the complex memory access details automatically.",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#what-is-a-tilewindow",
    "href": "concepts/03_tile_window.html#what-is-a-tilewindow",
    "title": "Tile Window - Data Access Gateway",
    "section": "What is a TileWindow?",
    "text": "What is a TileWindow?\nTileWindow is the missing piece between distribution and data access:\nThe Problem: TileDistribution tells threads WHERE to work, but how do they actually ACCESS the data?\nThe Solution: TileWindow provides a smart window into memory with distribution-aware access patterns.\n🪟 Think of TileWindow as: - A smart window into a large tensor - Knows about thread distribution - Handles memory access patterns automatically - Provides load/store operations\n🔄 The Complete Flow:\n\nTileDistribution: ‘Thread 5, you handle coordinates [2,3]’\nTileWindow: ‘Here’s the data at [2,3], loaded efficiently’\nYour code: ‘Thanks! does computation’\nTileWindow: ‘I’ll store your result back optimally’\n\nKey Insight: TileWindow is like a smart cache manager. It knows which thread needs what data, and it loads/stores everything with optimal memory access patterns.",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#creating-a-tilewindow",
    "href": "concepts/03_tile_window.html#creating-a-tilewindow",
    "title": "Tile Window - Data Access Gateway",
    "section": "Creating a TileWindow",
    "text": "Creating a TileWindow\nLet’s create a TileWindow step by step:\n\n\n\n\n\n\nWhat just happened? We created a 2×2 window starting at position [1,1] in our 4×4 matrix. The window knows about our tile distribution, so it can load data efficiently for each thread.",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#loading-data-with-tilewindow",
    "href": "concepts/03_tile_window.html#loading-data-with-tilewindow",
    "title": "Tile Window - Data Access Gateway",
    "section": "Loading Data with TileWindow",
    "text": "Loading Data with TileWindow\nNow let’s see how TileWindow loads data into distributed tensors:\n\n\n\n\n\n\nLoading Magic: TileWindow’s load() method automatically creates a distributed tensor AND figures out which memory locations each thread needs, loading them with optimal access patterns according to our tile distribution! No manual tensor creation needed!",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#computing-on-distributed-data",
    "href": "concepts/03_tile_window.html#computing-on-distributed-data",
    "title": "Tile Window - Data Access Gateway",
    "section": "Computing on Distributed Data",
    "text": "Computing on Distributed Data\nOnce data is loaded, we can perform computations with an optimized pattern:\n\n\n\n\n\n\nOptimized Pattern: No intermediate tensor needed! We load input, compute results, and store directly to output window. This saves memory and is more efficient than creating separate intermediate tensors.",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#the-complete-load-compute-store-pattern",
    "href": "concepts/03_tile_window.html#the-complete-load-compute-store-pattern",
    "title": "Tile Window - Data Access Gateway",
    "section": "The Complete Load-Compute-Store Pattern",
    "text": "The Complete Load-Compute-Store Pattern\nLet’s demonstrate the complete optimized pattern in a single function. Notice how we avoid creating intermediate tensors by computing and storing directly:",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#window-properties-and-flexibility",
    "href": "concepts/03_tile_window.html#window-properties-and-flexibility",
    "title": "Tile Window - Data Access Gateway",
    "section": "Window Properties and Flexibility",
    "text": "Window Properties and Flexibility\nTileWindow provides flexible windowing capabilities:",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#testing-your-understanding",
    "href": "concepts/03_tile_window.html#testing-your-understanding",
    "title": "Tile Window - Data Access Gateway",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that TileWindow operations work correctly:",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/03_tile_window.html#key-takeaways",
    "href": "concepts/03_tile_window.html#key-takeaways",
    "title": "Tile Window - Data Access Gateway",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nTileWindow is the essential bridge between distribution and data access:\n1. Smart Data Access - ✅ Provides windowed views into large tensors - ✅ Handles distribution-aware memory access - ✅ Optimizes load/store operations automatically\n2. Seamless Integration - ✅ Works perfectly with TileDistribution - ✅ Bridges tensor views and distributed computation - ✅ Enables efficient thread cooperation\n3. Flexible Windowing - ✅ Supports arbitrary window sizes and positions - ✅ Handles different tensor layouts - ✅ Adapts to various access patterns\n4. Optimized Workflow - ✅ load() automatically creates distributed tensors - ✅ Compute and store directly - no intermediate tensors needed - ✅ More efficient than traditional load→compute→store pattern\n5. Two Loading Methods - ✅ load() for convenience (automatically creates tensor) - ✅ load_into(tensor) for control (when you need specific tensor setup)\nTileWindow completes the data access story. Next, we’ll learn about sweep operations - the elegant way to iterate over all distributed data elements!",
    "crumbs": [
      "Distribution API",
      "Tile Window - Data Access Gateway"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html",
    "href": "concepts/02_coordinate_movement.html",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "Now that you understand transforms, adaptors, and descriptors, it’s time to learn advanced coordinate operations, and how they are used to navigate through complex tensor layouts. Basically, there are two main operations:\n\nmake_tensor_coordinate: Create a tensor coordinate from a descriptor and an index\nmake_tensor_adaptor_coordinate: Create a tensor adaptor coordinate from an adaptor and an index\nmove_tensor_coordinate: Move a tensor coordinate through a descriptor with a given offset\nmove_tensor_adaptor_coordinate: Move a tensor adaptor coordinate through an adaptor with a given offset\n\nThese operations are basically applying the transforms to the coordinates, that are top dimensions of the descriptor or adaptor, and return the new coordinates. tensor_coordinate and tensor_adaptor_coordinate are the classes that are used to cache the applications of the transforms to the top dimensions coordinates. It stores the results of the applications of the transforms to the top dimensions coordinates.\n\n\nThis builds on everything we’ve learned:\n\nMultiIndex: Basic coordinates\nTransforms: Individual coordinate mappings\n\nAdaptors: Transform chains\nDescriptors: Complete tensor specifications\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTensorCoordinate works with TensorDescriptor to provide descriptor-aware coordinate navigation:\n\n\n\n\n\n\n\n\n\nTensorAdaptorCoordinate works with adaptors to track coordinates through transformation chains:\n\n\n\n\n\n\n\n\n\nmove_tensor_coordinate is the key function for navigating tensor layouts. It updates coordinates efficiently through descriptor-defined transformations by applying the transforms to the top dimensions coordinates if necessary. It recrusively checks and updates the coordinates that are affected by the higher level transforms. If they are unchanged, no transform operation is propagated to the lower level coordinates.\n\n\n\n\n\n\n\n\n\nThe real power shows when moving through complex adaptor transformations:\n\n\n\n\n\n\n\n\n\nThese coordinate operations are used everywhere in real applications:\n\n\n\n\n\n\n\n\n\nOne key insight: move_tensor_coordinate is much more efficient than recreating coordinates:\n\n\n\n\n\n\n\n\n\nReal applications use sophisticated movement patterns:\n\n\n\n\n\n\n\n\n\nLet’s test your understanding of advanced coordinate operations:\n\n\n\n\n\n\n\n\n\nAdvanced coordinate operations are the bridge between mathematical transforms and practical tensor manipulation:\n1. TensorCoordinate: Descriptor-aware navigation\n\nTracks the position of a tensor in a descriptor\nProvides linear offset for memory access (bottom index)\nEnables descriptor-validated operations\n\n2. TensorAdaptorCoordinate: Adaptor-aware tracking\n\nTracks coordinates through transformation chains\nHandles complex multi-stage transformations\nEnables efficient pipeline navigation\n\n3. move_tensor_coordinate: Efficient navigation\n\nUpdates coordinates without full recalculation\nEssential for high-performance operations\nUsed by all tile and distribution operations\n\n4. Real-world applications:\n\nTile window positioning and traversal\nThread coordinate mapping and distribution\nMemory layout navigation and optimization\n\nThese operations form the foundation for all advanced tensor operations in the system. Master them, and you’re ready for the Distribution API!",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#prerequisites",
    "href": "concepts/02_coordinate_movement.html#prerequisites",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "This builds on everything we’ve learned:\n\nMultiIndex: Basic coordinates\nTransforms: Individual coordinate mappings\n\nAdaptors: Transform chains\nDescriptors: Complete tensor specifications",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#tensorcoordinate-descriptor-aware-coordinates",
    "href": "concepts/02_coordinate_movement.html#tensorcoordinate-descriptor-aware-coordinates",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "TensorCoordinate works with TensorDescriptor to provide descriptor-aware coordinate navigation:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#tensoradaptorcoordinate-adaptor-aware-coordinates",
    "href": "concepts/02_coordinate_movement.html#tensoradaptorcoordinate-adaptor-aware-coordinates",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "TensorAdaptorCoordinate works with adaptors to track coordinates through transformation chains:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#the-power-of-move_tensor_coordinate",
    "href": "concepts/02_coordinate_movement.html#the-power-of-move_tensor_coordinate",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "move_tensor_coordinate is the key function for navigating tensor layouts. It updates coordinates efficiently through descriptor-defined transformations by applying the transforms to the top dimensions coordinates if necessary. It recrusively checks and updates the coordinates that are affected by the higher level transforms. If they are unchanged, no transform operation is propagated to the lower level coordinates.",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#movement-through-complex-transformations",
    "href": "concepts/02_coordinate_movement.html#movement-through-complex-transformations",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "The real power shows when moving through complex adaptor transformations:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#practical-applications",
    "href": "concepts/02_coordinate_movement.html#practical-applications",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "These coordinate operations are used everywhere in real applications:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#understanding-movement-efficiency",
    "href": "concepts/02_coordinate_movement.html#understanding-movement-efficiency",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "One key insight: move_tensor_coordinate is much more efficient than recreating coordinates:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#advanced-movement-patterns",
    "href": "concepts/02_coordinate_movement.html#advanced-movement-patterns",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "Real applications use sophisticated movement patterns:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#testing-your-understanding",
    "href": "concepts/02_coordinate_movement.html#testing-your-understanding",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "Let’s test your understanding of advanced coordinate operations:",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/02_coordinate_movement.html#key-takeaways",
    "href": "concepts/02_coordinate_movement.html#key-takeaways",
    "title": "Advanced Coordinate Operations",
    "section": "",
    "text": "Advanced coordinate operations are the bridge between mathematical transforms and practical tensor manipulation:\n1. TensorCoordinate: Descriptor-aware navigation\n\nTracks the position of a tensor in a descriptor\nProvides linear offset for memory access (bottom index)\nEnables descriptor-validated operations\n\n2. TensorAdaptorCoordinate: Adaptor-aware tracking\n\nTracks coordinates through transformation chains\nHandles complex multi-stage transformations\nEnables efficient pipeline navigation\n\n3. move_tensor_coordinate: Efficient navigation\n\nUpdates coordinates without full recalculation\nEssential for high-performance operations\nUsed by all tile and distribution operations\n\n4. Real-world applications:\n\nTile window positioning and traversal\nThread coordinate mapping and distribution\nMemory layout navigation and optimization\n\nThese operations form the foundation for all advanced tensor operations in the system. Master them, and you’re ready for the Distribution API!",
    "crumbs": [
      "Transformation Engine",
      "Advanced Coordinate Operations"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html",
    "href": "concepts/01_buffer_view.html",
    "title": "Buffer Views - Raw Memory Access",
    "section": "",
    "text": "BufferView provides structured access to raw memory regions for GPU kernels. It handles different memory address spaces (global, shared, register) with support for vectorized operations.",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#overview",
    "href": "concepts/01_buffer_view.html#overview",
    "title": "Buffer Views - Raw Memory Access",
    "section": "",
    "text": "BufferView provides structured access to raw memory regions for GPU kernels. It handles different memory address spaces (global, shared, register) with support for vectorized operations.",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#bufferview-creation",
    "href": "concepts/01_buffer_view.html#bufferview-creation",
    "title": "Buffer Views - Raw Memory Access",
    "section": "BufferView Creation",
    "text": "BufferView Creation\nLet’s start by creating and examining BufferView objects:",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#bufferview-properties",
    "href": "concepts/01_buffer_view.html#bufferview-properties",
    "title": "Buffer Views - Raw Memory Access",
    "section": "BufferView Properties",
    "text": "BufferView Properties\nNow let’s explore the properties and methods available on BufferView objects:",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#data-access",
    "href": "concepts/01_buffer_view.html#data-access",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Data Access",
    "text": "Data Access\nBufferView provides structured access to the underlying memory:",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#address-spaces",
    "href": "concepts/01_buffer_view.html#address-spaces",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Address Spaces",
    "text": "Address Spaces\nDifferent memory types have different performance characteristics:",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#buffer-coherence",
    "href": "concepts/01_buffer_view.html#buffer-coherence",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Buffer Coherence",
    "text": "Buffer Coherence\nMemory coherence is crucial for multi-threaded GPU operations:",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#testing-your-understanding",
    "href": "concepts/01_buffer_view.html#testing-your-understanding",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify that BufferView operations work correctly:",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#common-use-cases",
    "href": "concepts/01_buffer_view.html#common-use-cases",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Common Use Cases",
    "text": "Common Use Cases\nBufferView is used throughout Composable Kernels for:\n\nGlobal Memory Access: Reading input tensors from GPU global memory\nShared Memory Management: Organizing data in fast shared memory\nRegister Management: Handling data in GPU registers (VGPR)\nInter-thread Communication: Coordinating data between GPU threads",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#key-takeaways",
    "href": "concepts/01_buffer_view.html#key-takeaways",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nRaw Memory Foundation: BufferView provides the base layer for all tensor operations\nAddress Space Awareness: Different memory types (global, shared, register) require different handling\nCoherence Management: GPU memory coherence is handled automatically\nZero-Copy Operations: BufferView wraps existing memory without copying\nGPU-Optimized: Designed specifically for GPU memory access patterns",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#whats-next",
    "href": "concepts/01_buffer_view.html#whats-next",
    "title": "Buffer Views - Raw Memory Access",
    "section": "What’s Next",
    "text": "What’s Next\nBufferView provides the foundation for raw memory access. Next, learn about TensorView which adds multi-dimensional structure and coordinate systems on top of BufferView.",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#next-steps",
    "href": "concepts/01_buffer_view.html#next-steps",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Next Steps",
    "text": "Next Steps\nContinue to Tensor Views to learn about multi-dimensional tensor structures built on BufferView.",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#overview",
    "href": "concepts/04_coordinate_systems.html#overview",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Overview",
    "text": "Overview\nNow that you understand the APIs and basic transformations, it’s time to learn the mathematical foundation that makes it all work: the coordinate system.\nTile distribution uses five interconnected coordinate spaces to map from thread identification all the way to memory addresses. Understanding these coordinate spaces is the key to mastering tile distribution.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#the-five-coordinate-spaces",
    "href": "concepts/04_coordinate_systems.html#the-five-coordinate-spaces",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "The Five Coordinate Spaces",
    "text": "The Five Coordinate Spaces\nBefore diving into code, let’s understand what problem these coordinate spaces solve:\nThe Challenge: You have an 8×8 matrix and 4 GPU threads. Each thread needs to know:\n\nWhich thread am I? (Thread identification)\n\nWhat work should I do? (Work assignment)\nWhere is my data in the tensor? (Physical location)\nHow do I share data with other threads? (Cooperation)\nWhat’s the memory address? (Hardware access)\n\nThe Solution: Five coordinate spaces that transform from logical to physical:\n📐 The Five Coordinate Spaces:\n\n🔹 P-space (Partition): Thread identification\n\nthread_x, thread_y, warp_id, block_id\nMaps to: which thread is doing the work\n\n🔹 Y-space (Logical Tile): Element within thread’s work\n\ny0, y1, y2, y3 (logical coordinates)\nMaps to: which element within the thread’s tile\n\n🔹 X-space (Physical Tensor): Actual tensor coordinates\n\nx0, x1 (physical matrix coordinates)\n\nMaps to: actual position in the tensor\n\n🔹 R-space (Replication): Data sharing across threads\n\nr0, r1 (replication coordinates)\nMaps to: shared data across multiple threads\n\n🔹 D-space (Linearized Storage): Memory layout\n\nd (single linear index)\nMaps to: actual memory address",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#p-space-partition-coordinates",
    "href": "concepts/04_coordinate_systems.html#p-space-partition-coordinates",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "P-space: Partition Coordinates",
    "text": "P-space: Partition Coordinates\nP-space identifies which thread is doing the work. Each thread gets a unique P coordinate.\n\n\n\n\n\n\nKey Insight: P-space gives each thread a unique identity. In real GPU kernels, these come from hardware intrinsics like threadIdx.x, blockIdx.y, etc.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#y-space-logical-tile-coordinates",
    "href": "concepts/04_coordinate_systems.html#y-space-logical-tile-coordinates",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Y-space: Logical Tile Coordinates",
    "text": "Y-space: Logical Tile Coordinates\nY-space defines what work each thread does. Each thread processes a “tile” of elements.\n\n\n\n\n\n\nKey Insight: Y-space defines the structure of work within each thread. Every thread has the same Y-space structure, but processes different data.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#x-space-physical-tensor-coordinates",
    "href": "concepts/04_coordinate_systems.html#x-space-physical-tensor-coordinates",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "X-space: Physical Tensor Coordinates",
    "text": "X-space: Physical Tensor Coordinates\nX-space gives the actual position in the tensor. This is where the data lives.\n\n\n\n\n\n\nKey Insight: X-space represents the actual tensor coordinates that users think about. This is the “physical reality” of where data lives.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#the-core-transformation-p-y-x",
    "href": "concepts/04_coordinate_systems.html#the-core-transformation-p-y-x",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "The Core Transformation: P + Y → X",
    "text": "The Core Transformation: P + Y → X\nThis is the heart of tile distribution: combining thread identity (P) with logical work coordinates (Y) to get physical tensor coordinates (X).\n\n\n\n\n\n\nKey Insight: The P+Y→X transformation is what makes tile distribution work. It automatically maps logical thread work to physical tensor locations.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#r-space-replication-coordinates",
    "href": "concepts/04_coordinate_systems.html#r-space-replication-coordinates",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "R-space: Replication Coordinates",
    "text": "R-space: Replication Coordinates\nR-space handles data that needs to be shared across threads, useful for broadcast operations and reductions.\n\n\n\n\n\n\nKey Insight: R-space enables thread cooperation by managing data that needs to be shared or replicated across multiple threads.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#d-space-linearized-storage",
    "href": "concepts/04_coordinate_systems.html#d-space-linearized-storage",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "D-space: Linearized Storage",
    "text": "D-space: Linearized Storage\nD-space is the final step - converting 2D coordinates to linear memory addresses for efficient access.\n\n\n\n\n\n\nKey Insight: D-space handles the final step of converting logical coordinates to actual memory addresses that the hardware can access.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#complete-pipeline-py-x-d",
    "href": "concepts/04_coordinate_systems.html#complete-pipeline-py-x-d",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Complete Pipeline: P+Y → X → D",
    "text": "Complete Pipeline: P+Y → X → D\nLet’s trace a complete example from thread identification all the way to memory access.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#practical-example-matrix-multiplication",
    "href": "concepts/04_coordinate_systems.html#practical-example-matrix-multiplication",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Practical Example: Matrix Multiplication",
    "text": "Practical Example: Matrix Multiplication\nLet’s see how coordinate spaces work in a real matrix multiplication kernel.",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#real-tile-distribution-example-rmsnorm",
    "href": "concepts/04_coordinate_systems.html#real-tile-distribution-example-rmsnorm",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Real Tile Distribution Example: RMSNorm",
    "text": "Real Tile Distribution Example: RMSNorm\nLet’s see how these coordinate spaces work with a production CK tile distribution - RMSNorm:",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#testing-your-understanding",
    "href": "concepts/04_coordinate_systems.html#testing-your-understanding",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Testing Your Understanding",
    "text": "Testing Your Understanding\nLet’s verify your understanding of coordinate systems:",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/04_coordinate_systems.html#key-takeaways",
    "href": "concepts/04_coordinate_systems.html#key-takeaways",
    "title": "Coordinate Systems - The Mathematical Foundation",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nUnderstanding coordinate systems is crucial for mastering tile distribution:\n🎯 The Five Coordinate Spaces:\n\nP-space (Partition): Thread identification\n\n✅ Each thread gets unique coordinates\n✅ Maps to hardware thread IDs\n✅ Foundation for work distribution\n\nY-space (Logical Tile): Per-thread work structure\n\n✅ Defines what each thread processes\n✅ Same structure for all threads\n✅ Logical organization of computation\n\nX-space (Physical Tensor): Actual data locations\n\n✅ Real tensor coordinates users understand\n✅ Where data actually lives\n✅ Target of P+Y transformation\n\nR-space (Replication): Data sharing\n\n✅ Enables thread cooperation\n✅ Handles broadcast and reduction\n✅ Manages shared data\n\nD-space (Linearized Storage): Memory addresses\n\n✅ Final hardware-level addresses\n✅ Enables efficient memory access\n✅ Hardware interface layer\n\n\n🔄 The Core Transformation: P + Y → X → D\n\n✅ Maps thread work to physical memory\n✅ Enables automatic memory coalescing\n✅ Provides predictable access patterns\n✅ Foundation for GPU performance\n\n💡 Why This Matters:\n\n✅ Automatic thread cooperation\n✅ Optimal memory access patterns\n✅ Hardware-agnostic programming\n✅ Predictable performance characteristics\n\nThese coordinate systems are the mathematical foundation that makes tile distribution both powerful and elegant. Master them, and you’ll understand how CK achieves its remarkable performance!",
    "crumbs": [
      "Coordinate Systems",
      "Coordinate Systems - The Mathematical Foundation"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#c-equivalent-complex-nested-transforms",
    "href": "concepts/02_adaptors.html#c-equivalent-complex-nested-transforms",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "C++ Equivalent: Complex Nested Transforms",
    "text": "C++ Equivalent: Complex Nested Transforms\nThe real power of TensorAdaptors becomes clear when we see how they correspond to complex C++ tensor operations. Here’s the true working equivalent of complex nested C++ transforms:\n\n\n\n\n\n\nThis implementation successfully creates the exact Python equivalent of the complex nested C++ transform pattern, with full mathematical equivalence and working coordinate transformations.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#advanced-examples-complex-nested-transforms",
    "href": "concepts/02_adaptors.html#advanced-examples-complex-nested-transforms",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Advanced Examples: Complex Nested Transforms",
    "text": "Advanced Examples: Complex Nested Transforms\nNow let’s explore more sophisticated examples that demonstrate the real power of TensorAdaptors in complex scenarios:",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/02_adaptors.html#real-world-gpu-examples-specialized-block-descriptors",
    "href": "concepts/02_adaptors.html#real-world-gpu-examples-specialized-block-descriptors",
    "title": "Tensor Adaptors - Chaining Transformations",
    "section": "Real-World GPU Examples: Specialized Block Descriptors",
    "text": "Real-World GPU Examples: Specialized Block Descriptors\nThese examples show how TensorAdaptors are used in real GPU computing scenarios with complex memory layouts:\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Concepts Summary\nThe examples above demonstrate several key advanced concepts:\nComplex Nested Transforms: The nested merge example shows how sophisticated hierarchical transformations are automatically flattened by the tensor descriptor system. This is crucial for GPU kernels that need to combine multiple levels of data organization.\nReal-World GPU Memory Layouts: The K LDS (Local Data Store) block descriptor example demonstrates how TensorAdaptors handle the complex memory hierarchies found in actual GPU computing: - Double buffering for overlapping computation and memory access - Vectorization factors for efficient SIMD operations\n- Packing factors for optimal memory bandwidth utilization - Block-level organization for thread cooperation patterns\nDimension Conservation: The arithmetic sequence transform shows how dimensions can be split and merged while preserving the total number of elements - a fundamental requirement for correct tensor operations.\nThese patterns are essential for: - GEMM operations (matrix multiplication kernels) - Convolution implementations (deep learning kernels) - Memory coalescing (efficient GPU memory access) - Thread block coordination (cooperative GPU algorithms)",
    "crumbs": [
      "Transformation Engine",
      "Tensor Adaptors - Chaining Transformations"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#basic-creation-and-element-access",
    "href": "concepts/01_tensor_view.html#basic-creation-and-element-access",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Basic Creation and Element Access",
    "text": "Basic Creation and Element Access\n\n\n\n\n\n\n\nElement Access Methods\n\n\n\n\n\n\n\n\nElement Modification",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#vectorized-operations",
    "href": "concepts/01_tensor_view.html#vectorized-operations",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#tiled-views",
    "href": "concepts/01_tensor_view.html#tiled-views",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Tiled Views",
    "text": "Tiled Views\nBehind the scenes, make_naive_tensor_view uses an EmbedTransform, which we explain in detail in the next chapter. In the meantime, we can get a taste of the power of these transformations through the tensor_descriptor of each tensor view. For example, just by providing additional dimensions for tile lengths, we can convert a tensor to a tiled tensor.",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#overlapping-windows",
    "href": "concepts/01_tensor_view.html#overlapping-windows",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Overlapping Windows",
    "text": "Overlapping Windows\nWhen using make_naive_tensor_view, we can additionally provide strides parameters. These strides enable us to create overlapping tile views of our data.",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/01_tensor_view.html#key-features",
    "href": "concepts/01_tensor_view.html#key-features",
    "title": "Tensor Views - Multi-Dimensional Structure",
    "section": "Key Features",
    "text": "Key Features\n\nCoordinate Access: Multi-dimensional indexing with tensor[i, j, k] syntax\nVectorized Operations: Read/write multiple elements efficiently\nLayout Flexibility: Same data can be viewed as different tensor shapes\nMemory Views: Zero-copy operations on existing BufferView data\nTiling Support: Extract overlapping and non-overlapping windows\nHigher Dimensions: Support for tensors of any dimensionality",
    "crumbs": [
      "Foundation",
      "Tensor Views - Multi-Dimensional Structure"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#creating-basic-tensor-layouts",
    "href": "concepts/02_descriptors.html#creating-basic-tensor-layouts",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Creating Basic Tensor Layouts",
    "text": "Creating Basic Tensor Layouts\nYou can create descriptors for several common memory layouts.\n\n1. Custom Strides\nThe most fundamental way to define a tensor is with custom strides. This gives you full control over how many elements to “jump” in memory to move to the next item along each dimension. This is useful for creating padded layouts.\n\n\n\n\n\n\n\n\n2. Packed (Row-Major) Layout\nFor most cases, a tightly packed, row-major layout is sufficient. The strides are calculated automatically, leaving no unused space between elements.\n\n\n\n\n\n\n\n\n3. Aligned Layout\nFor GPU performance, memory layouts often need to be aligned. This function creates a row-major layout but ensures that each row’s starting address is a multiple of a given alignment value, adding padding if necessary.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#the-pipeline-concept",
    "href": "concepts/02_descriptors.html#the-pipeline-concept",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "The Pipeline Concept",
    "text": "The Pipeline Concept\nIt’s useful to think of every TensorDescriptor as a transformation pipeline. The functions above (make_naive...) create the first stage of this pipeline: they define the initial transformation that takes a simple, one-dimensional block of memory and presents it as a logical, multi-dimensional tensor view.\nThe power of the library comes from adding more stages to this pipeline to create increasingly complex layouts.\n\nThe Initial Pipeline Stage: A Closer Look\nLet’s inspect the pipeline of a simple packed descriptor to see this first stage in action.\n\n\n\n\n\n\nAs the output shows, creating a simple [3, 4] tensor sets up a pipeline with a single transform.\n\nLower IDs (Inputs): [[0]]: This means the transform takes one input: the raw, one-dimensional memory buffer, which is always at hidden dimension ID 0.\nUpper IDs (Outputs): [[1, 2]]: This means the transform produces two outputs, which are assigned to hidden dimension IDs 1 and 2. These become the logical dimensions 0 and 1 that you interact with when you access the tensor.\n\nUnderstanding this initial stage is key to seeing how transform_tensor_descriptor later adds new stages that take these output dimensions (1 and 2) as their inputs.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#advanced-layouts-a-step-by-step-transformation",
    "href": "concepts/02_descriptors.html#advanced-layouts-a-step-by-step-transformation",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Advanced Layouts: A Step-by-Step Transformation",
    "text": "Advanced Layouts: A Step-by-Step Transformation\nThe transform_tensor_descriptor function adds new stages to an existing descriptor’s pipeline. Let’s walk through this with a detailed example, mirroring the process of a debug script.\n\nGoal: Transform a [2, 6] Tensor into a [2, 2, 3] View\nWe will reinterpret a 2D tensor with shape [2, 6] as a 3D tensor with shape [2, 2, 3], without changing the underlying 12-element memory buffer.\n\nStep 1: Define and Analyze the Base Descriptor\nFirst, we create the [2, 6] base descriptor. As we established, this creates an initial pipeline stage.\n\n\n\n\n\n\n\n\nStep 2: Define the New Transformation Stage\nTo get from [2, 6] to [2, 2, 3], we must add a new transform for each of the base descriptor’s logical dimensions.\n\nFor logical dimension 0 (length 2): We want to preserve it, so we’ll use a PassThroughTransform.\nFor logical dimension 1 (length 6): We want to split it, so we’ll use an UnmergeTransform([2, 3]).\n\nWe wire this new stage into the pipeline using the lower and upper ID parameters, which operate on the logical dimensions of their respective descriptors (input and output).\n\n\nStep 3: Apply Transformation and Analyze the Result\nNow we apply the transform and inspect the final, complete pipeline.\n\n\n\n\n\n\n\n\n\nAnalysis of the Final Pipeline\nThe final debug output shows the full story of our three-stage pipeline:\n\nTransform [0] (The Base UnmergeTransform):\n\nLower hidden IDs: [[0]]: Takes the raw memory buffer as input.\nUpper hidden IDs: [[1, 2]]: Produces the two original logical dimensions, backed by hidden IDs 1 and 2.\n\nTransform [1] (Our New PassThroughTransform):\n\nLower hidden IDs: [[1]]: Correctly takes hidden ID 1 as its input. This is because we specified input logical dimension 0, which was backed by hidden ID 1.\nUpper hidden IDs: [[3]]: Produces a new output, hidden ID 3.\n\nTransform [2] (Our New UnmergeTransform):\n\nLower hidden IDs: [[2]]: Correctly takes hidden ID 2 as its input, as it was wired from logical dimension 1.\nUpper hidden IDs: [[4, 5]]: Splits its input into two new outputs, hidden IDs 4 and 5.\n\nFinal Result: The Top dimension hidden IDs of the final descriptor are [3, 4, 5]. These are the outputs of our new transforms, and they now back the final logical dimensions 0, 1, 2 of the [2, 2, 3] tensor.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/02_descriptors.html#real-world-gpu-example-5d-to-3d-block-transformation",
    "href": "concepts/02_descriptors.html#real-world-gpu-example-5d-to-3d-block-transformation",
    "title": "Tensor Descriptors - Complete Tensor Specifications",
    "section": "Real-World GPU Example: 5D to 3D Block Transformation",
    "text": "Real-World GPU Example: 5D to 3D Block Transformation\nThese concepts are critical in GPU programming. This example transforms a 5D tensor representing a GPU thread block’s workload into a simpler 3D view using MergeTransform.\n\nThe logic is the same: we start with a 5D descriptor and apply new transforms (PassThrough and Merge) to its logical dimensions to produce a new 3D descriptor.",
    "crumbs": [
      "Transformation Engine",
      "Tensor Descriptors - Complete Tensor Specifications"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#basic-creation",
    "href": "concepts/01_buffer_view.html#basic-creation",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Basic Creation",
    "text": "Basic Creation",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#get-operations",
    "href": "concepts/01_buffer_view.html#get-operations",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Get Operations",
    "text": "Get Operations\n\nScalar Access\n\n\n\n\n\n\n\n\nVector Access",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#set-operations",
    "href": "concepts/01_buffer_view.html#set-operations",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Set Operations",
    "text": "Set Operations\n\nScalar Writes\n\n\n\n\n\n\n\n\nVector Writes",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#update-operations",
    "href": "concepts/01_buffer_view.html#update-operations",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Update Operations",
    "text": "Update Operations\n\nMemory Operation Types\n\n\n\n\n\n\n\n\nVector Updates",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  },
  {
    "objectID": "concepts/01_buffer_view.html#key-features",
    "href": "concepts/01_buffer_view.html#key-features",
    "title": "Buffer Views - Raw Memory Access",
    "section": "Key Features",
    "text": "Key Features\n\nVectorized Operations: Read/write multiple elements with vector_size parameter\nValidity Checking: is_valid_element controls whether operations execute\nBounds Checking: Automatic handling of out-of-bounds access\nMultiple Operations: SET, ADD, ATOMIC_ADD, ATOMIC_MAX support\nAddress Space Aware: Optimized for different GPU memory types",
    "crumbs": [
      "Foundation",
      "Buffer Views - Raw Memory Access"
    ]
  }
]