---
title: "Buffer Views - Raw Memory Access"
format: 
  live-html:
    mermaid:
      theme: default
---

## Overview

BufferView provides structured access to raw memory regions for GPU kernels. It handles different memory address spaces (global, shared, register) with support for vectorized operations.

### BufferView Architecture

```{=html}
<div class="mermaid">
graph TB
    subgraph "GPU Memory Hierarchy"
        VGPR["Vector General Purpose Registers<br/>256 KB | 1 cycle | ~100 TB/s"]
        LDS["Local Data Share<br/>64 KB | ~20 cycles | ~15 TB/s"]
        L1["L1 Cache<br/>16 KB | ~80 cycles | ~5 TB/s"]
        L2["L2 Cache<br/>4 MB | ~200 cycles | ~2 TB/s"]
        GM["Global Memory<br/>16+ GB | ~400 cycles | ~1 TB/s"]
    end
    
    subgraph "BufferView Operations"
        Read["Read Operations<br/>get(offset)<br/>get&lt;T,N&gt;(offset)"]
        Write["Write Operations<br/>update(offset, value)<br/>update&lt;T,N&gt;(offset, vec)"]
        Atomic["Atomic Operations<br/>atomic_add(offset, value)<br/>atomic_max(offset, value)"]
    end
    
    VGPR --> Read
    LDS --> Read
    L1 --> Read
    L2 --> Read
    GM --> Read
    
    Read --> Write
    Write --> Atomic
    
    style VGPR fill:#10b981,stroke:#047857,stroke-width:2px
    style LDS fill:#f59e0b,stroke:#d97706,stroke-width:2px
    style L1 fill:#3b82f6,stroke:#1d4ed8,stroke-width:2px
    style L2 fill:#8b5cf6,stroke:#6d28d9,stroke-width:2px
    style GM fill:#ef4444,stroke:#b91c1c,stroke-width:2px
    
    style Read fill:#dbeafe,stroke:#3b82f6,stroke-width:2px
    style Write fill:#d1fae5,stroke:#10b981,stroke-width:2px
    style Atomic fill:#fed7aa,stroke:#f59e0b,stroke-width:2px
</div>
```

- Handles out-of-bounds access safely with configurable invalid values
- Supports both scalar and vector data types
- Implements AMD GPU-specific optimizations (buffer addressing, atomic operations)
- Manages memory coherence and caching policies

```{pyodide}
#| echo: false
#| output: false
#| autorun: true

# Auto-install pythonck package
import micropip
await micropip.install("https://raw.githubusercontent.com/ghamarian/pythonck/master/documentation/pythonck-0.1.0-py3-none-any.whl")
```

## Basic Creation

Out-of-Bounds Handling:

- Zero Value Mode: Returns numerical zero for invalid accesses
- Custom Value Mode: Returns user-specified invalid value


```{pyodide}
#| echo: true
#| output: true

from pytensor.buffer_view import (
    BufferView, AddressSpaceEnum, MemoryOperationEnum, make_buffer_view
)
import numpy as np

# Create data and buffer view
data = np.array([1, 2, 3, 4, 5, 6, 7, 8], dtype=np.float32)
buffer_view = make_buffer_view(data, len(data), AddressSpaceEnum.GLOBAL)

print(f"Buffer size: {buffer_view.buffer_size}")
print(f"Address space: {buffer_view.address_space.name}")
print(f"Data: {data}")
```

### C++ Implementation Reference

**File**: `include/ck_tile/core/tensor/buffer_view.hpp`

```cpp
#include <ck_tile/core/tensor/buffer_view.hpp>
#include <ck_tile/core/numeric/integral_constant.hpp>

// Create buffer view in C++
__device__ void example_buffer_creation()
{
    // Static array in global memory
    float data[8] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f};
    constexpr index_t buffer_size = 8;

    // Create buffer view for global memory
    // Template parameters: <AddressSpace>
    auto buffer_view = make_buffer_view<address_space_enum::global>(
        data,        // pointer to data
        buffer_size  // number of elements
    );

    // Alternative: Create with explicit type
    using buffer_t = buffer_view<float*, address_space_enum::global>;
    buffer_t explicit_buffer{data, number<buffer_size>{}};

    // Access properties at compile time
    constexpr auto size = buffer_view.get_buffer_size();
    constexpr auto space = buffer_view.get_address_space();

    // The buffer_view type encodes:
    // - Data type (float)
    // - Address space (global memory)
    // - Size (known at compile time for optimization)
    static_assert(size == 8, "Buffer size should be 8");
    static_assert(space == address_space_enum::global, "Should be global memory");
}
```

### Zero Value Mode
```cpp
// Basic buffer view creation with automatic zero for invalid elements
void basic_creation_example() {
    // Create data array
    constexpr size_t buffer_size = 8;
    float data[buffer_size] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f};
    
    // Create global memory buffer view
    auto buffer_view = make_buffer_view<address_space_enum::global>(data, buffer_size);
}
```

### Custom Value Mode
```cpp
void custom_invalid_value_example() {
    constexpr size_t buffer_size = 8;
    float data[buffer_size] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f};
    float custom_invalid = 13.0f;
    
    // Create buffer view with custom invalid value
    auto buffer_view = make_buffer_view<address_space_enum::global>(
        data, buffer_size, custom_invalid);
}
```

## Get Operations

### Scalar Access

```{pyodide}
#| echo: true
#| output: true

print("üîç Scalar Get Operations")


### Python vs C++ Key Differences

#### 1. **Compile-Time vs Runtime**
- **C++**: BufferView uses template metaprogramming with compile-time constants
  - Size is encoded in the type: `number<8>{}`
  - Address space is a template parameter
  - Enables aggressive compiler optimizations
- **Python**: Everything is runtime
  - Size is a regular integer
  - Address space is an enum value
  - Designed for learning and experimentation

#### 2. **Memory Management**
- **C++**: Direct pointer to GPU memory
  - No memory allocation - uses existing memory
  - Pointer arithmetic for addressing
  - Zero-copy access to device memory
- **Python**: NumPy array simulation
  - Uses host memory to simulate GPU memory
  - Python manages memory lifetime
  - Educational approximation of GPU behavior

#### 3. **Type System**
- **C++**: Strong compile-time typing
  ```cpp
  buffer_view<float*, address_space_enum::global>  // Type encodes everything
  ```
- **Python**: Dynamic typing with runtime checks
  ```python
  BufferView  # Generic class, properties stored as members
  ```

## Get Operations

### Understanding BufferView Indexing

```{=html}
<div class="mermaid">
flowchart LR
    subgraph "Input Parameters"
        Offset["Offset<br/>(e.g., 5)"]
        ValidFlag["Valid Flag<br/>(optional)"]
    end
    
    subgraph "Processing"
        BoundsCheck{{"Bounds Check<br/>offset < buffer_size?"}}
        FlagCheck{{"Flag Check<br/>valid_flag == True?"}}
        Access["Access Memory<br/>buffer[offset]"]
    end
    
    subgraph "Output"
        ValidResult["Valid Result<br/>Return value"]
        Invalid["Invalid Result<br/>Return 0 or default"]
    end
    
    Offset --> BoundsCheck
    ValidFlag --> FlagCheck
    
    BoundsCheck -->|Yes| FlagCheck
    BoundsCheck -->|No| Invalid
    
    FlagCheck -->|Yes| Access
    FlagCheck -->|No| Invalid
    
    Access --> ValidResult
    
    style Offset fill:#e0e7ff,stroke:#4338ca,stroke-width:2px
    style ValidFlag fill:#e0e7ff,stroke:#4338ca,stroke-width:2px
    style ValidResult fill:#d1fae5,stroke:#10b981,stroke-width:2px
    style Invalid fill:#fee2e2,stroke:#ef4444,stroke-width:2px
</div>
```

```{pyodide}
#| echo: true
#| output: true

# Basic get operation
value = buffer_view.get(2)
print(f"Value at index 2: {value}")

# Get with bounds checking
try:
    value = buffer_view.get(10)  # Out of bounds
except IndexError as e:
    print(f"Error: {e}")

# Get with valid flag
value_with_flag = buffer_view.get(3, valid_flag=True)
print(f"Value at index 3 (with flag): {value_with_flag}")

# Invalid flag returns default
value_invalid = buffer_view.get(3, valid_flag=False)
print(f"Value with invalid flag: {value_invalid}")
```

### C++ Get Operations

```cpp
__device__ void example_get_operations()
{
    // Create buffer view
    float data[8] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f};
    auto buffer = make_buffer_view<address_space_enum::global>(data, 8);

    // Simple get - compile-time bounds checking when possible
    float value1 = buffer.get(number<2>{});  // Compile-time index
    float value2 = buffer.get(threadIdx.x);   // Runtime index

    // Get with valid flag - branchless conditional access
    bool valid_flag = (threadIdx.x < 4);
    float value3 = buffer.get(threadIdx.x, valid_flag);
    // Returns data[threadIdx.x] if valid_flag && in_bounds, else 0

    // Get with coordinate (multi-dimensional access)
    auto coord = make_tuple(number<1>{}, threadIdx.x);
    float value4 = buffer.get(coord);  // Flattened multi-D access

    // Template-based get for vectorization
    auto vec4 = buffer.template get<float4>(number<0>{});
    // Loads 4 floats in a single instruction
}
```

## Vectorized Operations

### Scalar vs Vectorized Memory Access

```{=html}
<div class="mermaid">
graph LR
    subgraph "Scalar Access (4 instructions)"
        S1["Load float[0]"] --> R1["Register 1"]
        S2["Load float[1]"] --> R2["Register 2"]
        S3["Load float[2]"] --> R3["Register 3"]
        S4["Load float[3]"] --> R4["Register 4"]
    end
    
    subgraph "Vectorized Access (1 instruction)"
        V1["Load float4[0]"] --> VR["Vector Register<br/>(4 floats)"]
    end
    
    subgraph "Performance Impact"
        Perf["4x fewer instructions<br/>Better memory bandwidth<br/>Reduced latency"]
    end
    
    R1 & R2 & R3 & R4 --> Perf
    VR --> Perf
    
    style S1 fill:#fee2e2,stroke:#ef4444,stroke-width:2px
    style S2 fill:#fee2e2,stroke:#ef4444,stroke-width:2px
    style S3 fill:#fee2e2,stroke:#ef4444,stroke-width:2px
    style S4 fill:#fee2e2,stroke:#ef4444,stroke-width:2px
    style V1 fill:#d1fae5,stroke:#10b981,stroke-width:2px
    style Perf fill:#fef3c7,stroke:#f59e0b,stroke-width:2px
</div>
```

```{pyodide}
#| echo: true
#| output: true

import numpy as np

# Scalar vs Vectorized Operations
data = np.arange(16, dtype=np.float32)
buffer_view = make_buffer_view(data, len(data), AddressSpaceEnum.GLOBAL)

# Scalar access (4 separate operations)
print("Scalar access:")
for i in range(4):
    value = buffer_view.get(i)
    print(f"  Load {i}: {value}")

# Vectorized access (single operation)
print("\nVectorized access:")
vec4 = buffer_view.get_vectorized(0, 4)  # Get 4 elements at once
print(f"  Load float4: {vec4}")

# Performance comparison
print("\nPerformance Impact:")
print("  Scalar: 4 memory transactions")
print("  Vectorized: 1 memory transaction")
print("  Speedup: ~4x for memory-bound operations")
```

## Update Operations

```{pyodide}
#| echo: true
#| output: true

# Create a writable buffer
data = np.array([10, 20, 30, 40, 50], dtype=np.float32)
buffer_view = make_buffer_view(data, len(data), AddressSpaceEnum.GLOBAL)

print("Original data:", data)

# Basic update
buffer_view.update(2, 99.0)
print("After update(2, 99.0):", data)

# Update with valid flag
buffer_view.update(3, 88.0, valid_flag=True)
print("After update(3, 88.0, valid_flag=True):", data)

# Invalid flag - no update
buffer_view.update(4, 77.0, valid_flag=False)
print("After update(4, 77.0, valid_flag=False):", data)

# Vectorized update
vec_data = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)
buffer_view.update_vectorized(0, vec_data)
print("After vectorized update:", data)
```

## Atomic Operations

### Atomic vs Non-Atomic Operations

```{=html}
<div class="mermaid">
graph TB
    subgraph "Non-Atomic Operation (Race Condition)"
        NA1["Thread 1: Read value (10)"] --> NA2["Thread 1: Add 5 (15)"]
        NA3["Thread 2: Read value (10)"] --> NA4["Thread 2: Add 3 (13)"]
        NA2 --> NA5["Thread 1: Write 15"]
        NA4 --> NA6["Thread 2: Write 13"]
        NA5 & NA6 --> NA7["Final value: 13 ‚ùå<br/>(Lost update from Thread 1)"]
    end
    
    subgraph "Atomic Operation (Thread-Safe)"
        A1["Thread 1: atomic_add(5)"] --> A2["Hardware ensures<br/>serialization"]
        A3["Thread 2: atomic_add(3)"] --> A2
        A2 --> A4["Final value: 18 ‚úì<br/>(Both updates applied)"]
    end
    
    style NA7 fill:#fee2e2,stroke:#ef4444,stroke-width:2px
    style A4 fill:#d1fae5,stroke:#10b981,stroke-width:2px
</div>
```

```{pyodide}
#| echo: true
#| output: true

# Demonstrate atomic operations
data = np.array([100, 200, 300], dtype=np.float32)
buffer_view = make_buffer_view(data, len(data), AddressSpaceEnum.GLOBAL)

print("Initial data:", data)

# Atomic add
old_value = buffer_view.atomic_add(0, 50)
print(f"atomic_add(0, 50) - old value: {old_value}, new data: {data}")

# Atomic max
old_value = buffer_view.atomic_max(1, 250)
print(f"atomic_max(1, 250) - old value: {old_value}, new data: {data}")

# Atomic operations with valid flag
old_value = buffer_view.atomic_add(2, 100, valid_flag=True)
print(f"atomic_add(2, 100, valid_flag=True) - old value: {old_value}, new data: {data}")
```

### C++ Atomic Operations

```cpp
__device__ void example_atomic_operations()
{
    // Shared memory for workgroup-level reductions
    __shared__ float shared_sum[256];
    auto shared_buffer = make_buffer_view<address_space_enum::lds>(
        shared_sum, 256
    );

    // Initialize shared memory
    if (threadIdx.x < 256) {
        shared_buffer.update(threadIdx.x, 0.0f);
    }
    __syncthreads();

    // Each thread atomically adds to shared memory
    float my_value = float(threadIdx.x);
    float old = shared_buffer.atomic_add(0, my_value);
    
    // Atomic max for finding maximum value
    shared_buffer.atomic_max(1, my_value);
    
    __syncthreads();
    
    // Thread 0 reads the results
    if (threadIdx.x == 0) {
        float sum = shared_buffer.get(0);
        float max = shared_buffer.get(1);
        // sum contains sum of all thread indices
        // max contains the maximum thread index
    }
}
```

## Address Space Usage Patterns

```{=html}
<div class="mermaid">
flowchart TB
    subgraph "Compute Flow"
        GM1["Global Memory<br/>Input Data"] --> LDS["LDS<br/>Tile Cache"]
        LDS --> VGPR["VGPR<br/>Working Set"]
        VGPR --> Compute["Compute<br/>Operations"]
        Compute --> VGPR
        VGPR --> LDS2["LDS<br/>Reduction"]
        LDS2 --> GM2["Global Memory<br/>Output Data"]
    end
    
    subgraph "Usage Pattern"
        P1["1. Load tile from Global ‚Üí LDS"]
        P2["2. Load working set LDS ‚Üí VGPR"]
        P3["3. Compute in VGPR"]
        P4["4. Store results VGPR ‚Üí LDS"]
        P5["5. Reduce in LDS"]
        P6["6. Write final LDS ‚Üí Global"]
    end
    
    P1 --> P2 --> P3 --> P4 --> P5 --> P6
    
    style GM1 fill:#fee2e2,stroke:#ef4444,stroke-width:2px
    style LDS fill:#fed7aa,stroke:#f59e0b,stroke-width:2px
    style VGPR fill:#d1fae5,stroke:#10b981,stroke-width:2px
    style Compute fill:#e0e7ff,stroke:#4338ca,stroke-width:2px
</div>
```

## Summary

BufferView provides:
- **Unified Interface**: Same API for all memory spaces
- **Type Safety**: Address space encoded in type (C++)
- **Performance**: Vectorized operations and optimal access patterns
- **Flexibility**: Support for runtime bounds checking and conditional access
- **Atomic Operations**: Thread-safe updates for parallel algorithms

The abstraction hides the complexity of different memory spaces while exposing the operations needed for high-performance GPU computing.